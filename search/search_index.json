{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Copilot Studio Gems \ud83d\udc8e","text":"Practical, Evaluated Patterns for Building AI Agents in Microsoft Copilot Studio <p>S\u00e9bastien Brochet</p> <p>First Edition \u2014 February 2026</p>"},{"location":"#what-is-this-book","title":"What is this book?","text":"<p>Copilot Studio Gems is a curated collection of 26 evaluated patterns for building production-quality AI agents in Microsoft Copilot Studio.</p> <p>Inspired by Game Programming Gems and the Gang of Four Design Patterns \u2014 each Gem addresses a recurring challenge by evaluating multiple implementation approaches with honest trade-off analysis.</p>"},{"location":"#what-makes-it-different","title":"What makes it different?","text":"<p>Microsoft Learn documents what features exist. Blogs show one way to solve a problem.</p> <p>This book evaluates which approach is best for your specific context.</p> <p>Every Gem follows the same structure:</p> <pre><code>The Problem  \u2192  Ideal Outcome  \u2192  Multiple Approaches (with code)\n    \u2192  Comparison Matrix  \u2192  Recommendation  \u2192  Platform Gotchas\n</code></pre> <p>Minimum 2 approaches per Gem. Real YAML / Power Fx / JSON code. Platform gotchas from production experience.</p>"},{"location":"#the-collection-at-a-glance","title":"The Collection at a Glance","text":"Part Theme Gems What You'll Learn I State &amp; Context 001, 011, 017 Persistence, session memory, multi-tenant config II Personalization 002, 005, 020 Persona adaptation, language, instruction lifecycle III Conversation UX 006, 010, 021, 025, 027 Forms, handoff, disambiguation, embedding, compliance IV Security 007, 022 Role gating, sensitive data protection V Integration 009, 014, 015, 018, 023, 028 APIs, events, CRUD, MCP, Fabric, SharePoint VI Knowledge &amp; Perf 008, 012, 026 Document optimization, cost control, Azure AI Search VII Observability 003, 004, 013, 016 Progress tracing, debug mode, testing, analytics Start Reading \u2192"},{"location":"appendices/about-author/","title":"About the Author","text":"<p>S\u00e9bastien Brochet is a technical professional specializing in AI agent development within the Microsoft ecosystem.</p> <p>With experience spanning enterprise agent architectures, multi-agent orchestration patterns, and comprehensive technical documentation, S\u00e9bastien has built production Copilot Studio agents for global organizations \u2014 discovering the patterns, gotchas, and trade-offs documented in this book through real-world deployment.</p> <p>His approach to technical knowledge: evaluate, don't just demonstrate. Every pattern should show multiple approaches with honest trade-offs \u2014 because the right answer depends on your context, not the author's preference.</p>"},{"location":"appendices/about-author/#connect","title":"Connect","text":"<ul> <li>LinkedIn: linkedin.com/in/sebastienbrochet</li> <li>GitHub: github.com/sebbrochet/copilotstudiogems</li> </ul>"},{"location":"appendices/about-author/#acknowledgments","title":"Acknowledgments","text":"<p>This book was shaped by:</p> <ul> <li>Game Programming Gems (Mark DeLoura) \u2014 for the \"gem\" format: self-contained, practical, expert-written solutions to recurring problems.</li> <li>Design Patterns (Gamma, Helm, Johnson, Vlissides) \u2014 for the principle that patterns should evaluate trade-offs, not prescribe one way.</li> <li>The Copilot Studio community \u2014 for the questions, bugs, workarounds, and shared discoveries that informed these patterns.</li> <li>Microsoft Learn documentation \u2014 the foundation that every Gem builds upon and extends.</li> </ul> <p>First Edition \u2014 February 2026</p>"},{"location":"appendices/decision-frameworks/","title":"Appendix D: Decision Frameworks","text":"<p>All decision flowcharts and comparison matrices from the Gems, consolidated for quick reference.</p>"},{"location":"appendices/decision-frameworks/#connector-selection-gem-023","title":"Connector Selection (GEM-023)","text":"<pre><code>Does a prebuilt MCP connector exist?\n  \u251c\u2500\u2500 YES \u2192 Use MCP prebuilt (3 clicks)\n  \u2514\u2500\u2500 NO \u2192 Do you control the API?\n            \u251c\u2500\u2500 YES \u2192 Multiple agents? \u2192 YES \u2192 Build MCP server\n            \u2502                          \u2192 NO  \u2192 Governance needed?\n            \u2502                                   \u251c\u2500\u2500 YES \u2192 Custom Connector\n            \u2502                                   \u2514\u2500\u2500 NO  \u2192 HTTP Node\n            \u2514\u2500\u2500 NO \u2192 OpenAPI spec available?\n                     \u251c\u2500\u2500 YES \u2192 Custom Connector\n                     \u2514\u2500\u2500 NO  \u2192 HTTP Node\n</code></pre>"},{"location":"appendices/decision-frameworks/#knowledge-source-selection-gem-008-gem-026","title":"Knowledge Source Selection (GEM-008 + GEM-026)","text":"<pre><code>Content in SharePoint, &lt; 500 files?\n  \u251c\u2500\u2500 YES \u2192 Search quality OK after format optimization?\n  \u2502          \u251c\u2500\u2500 YES \u2192 SharePoint Native \u2705\n  \u2502          \u2514\u2500\u2500 NO  \u2192 Need filtering or custom chunking? \u2192 Azure AI Search\n  \u2514\u2500\u2500 NO \u2192 Content in databases/APIs/multiple sources? \u2192 Azure AI Search\n           Content in Fabric (warehouse/lakehouse/PBI)?  \u2192 Fabric Data Agent (GEM-028)\n</code></pre>"},{"location":"appendices/decision-frameworks/#state-persistence-gem-001","title":"State Persistence (GEM-001)","text":"<pre><code>Org has Dataverse license?\n  \u251c\u2500\u2500 YES \u2192 Dataverse (production-grade)\n  \u2514\u2500\u2500 NO \u2192 Prototyping? \u2192 SharePoint List (zero licensing friction)\n           Need max performance? \u2192 External HTTP API\n</code></pre>"},{"location":"appendices/decision-frameworks/#debug-mode-gem-004","title":"Debug Mode (GEM-004)","text":"<pre><code>Development/UAT  \u2192  Keyword Inline (instant, in-chat)\nProduction       \u2192  App Insights (silent, persistent, queryable)\nStakeholder demo \u2192  Adaptive Card Panel (visual, polished)\n</code></pre>"},{"location":"appendices/decision-frameworks/#persona-adaptation-gem-002","title":"Persona Adaptation (GEM-002)","text":"<pre><code>Tone-only adaptation (3-5 personas)?    \u2192 Branched Instructions\nDifferent knowledge per persona?         \u2192 Multi-Agent Routing\nQuery-specific adaptation needed?        \u2192 Dynamic Prompt Tool\n</code></pre>"},{"location":"appendices/decision-frameworks/#multi-language-gem-005","title":"Multi-Language (GEM-005)","text":"<pre><code>IT maintains Entra profiles well?  \u2192 Graph API detection + persist\nQuick deploy, no infrastructure?   \u2192 LLM auto-detect from input + persist\nRegulatory language requirement?   \u2192 Explicit user choice\n</code></pre>"},{"location":"appendices/decision-frameworks/#form-collection-gem-006","title":"Form Collection (GEM-006)","text":"<pre><code>1-2 fields          \u2192 Sequential Questions\n3-6 fields          \u2192 Adaptive Card\n3-6 + validation    \u2192 Card + sequential correction (Hybrid)\n7+ fields           \u2192 Split into 2 cards\n</code></pre>"},{"location":"appendices/decision-frameworks/#handoff-to-human-gem-010","title":"Handoff to Human (GEM-010)","text":"<pre><code>Internal/enterprise   \u2192 LLM Summary (email/Teams async)\nTeams-centric org     \u2192 Context Card to Teams channel\nCustomer-facing       \u2192 Omnichannel live transfer\n</code></pre>"},{"location":"appendices/decision-frameworks/#regulated-flows-gem-027","title":"Regulated Flows (GEM-027)","text":"<pre><code>3-5 steps, simple consent     \u2192 Fully Manual topic\n5-7 steps, user needs help    \u2192 Hybrid (deterministic + generative clarification)\n7+ steps, multi-session       \u2192 State Machine with Power Automate\n</code></pre>"},{"location":"appendices/decision-frameworks/#proactive-messages-gem-014","title":"Proactive Messages (GEM-014)","text":"<pre><code>Event-driven automation   \u2192 Platform Triggers (GA, recommended)\nSimple Teams notification \u2192 PA + Teams Card\nIn-conversation follow-up \u2192 Bot Framework API\n</code></pre>"},{"location":"appendices/decision-frameworks/#cost-control-gem-012","title":"Cost Control (GEM-012)","text":"<pre><code>Immediate savings       \u2192 Response length capping (instructions)\nUnderstand costs        \u2192 App Insights token tracking\nHard limit (safety net) \u2192 Turn counter (30-40 max)\n</code></pre>"},{"location":"appendices/decision-frameworks/#testing-gem-013","title":"Testing (GEM-013)","text":"<pre><code>Development      \u2192 Manual test script (20 cases)\nPre-production   \u2192 Automated keyword matching (30 cases, daily)\nProduction gate  \u2192 LLM-as-Judge scoring (15 cases, per deploy)\n</code></pre>"},{"location":"appendices/gem-template/","title":"Appendix A: Gem Template","text":"<p>Use this template when contributing a new Gem to the collection. Every Gem MUST follow this structure.</p> <pre><code># Gem [NNN]: [Concise Title]\n\n*[One-line elevator pitch describing the pattern]*\n\n## Classification\n\n| Attribute | Value |\n|---|---|\n| **Category** | [Context &amp; State \u00b7 Personalization \u00b7 Observability \u00b7 Security \u00b7 UX \u00b7 Integration \u00b7 Performance] |\n| **Complexity** | [\u2b50 \u00b7 \u2b50\u2b50 \u00b7 \u2b50\u2b50\u2b50 \u00b7 \u2b50\u2b50\u2b50\u2b50 \u00b7 \u2b50\u2b50\u2b50\u2b50\u2b50] |\n| **Channels** | [All \u00b7 Web Chat \u00b7 M365 Copilot \u00b7 Teams \u00b7 channel-specific notes] |\n| **Prerequisite Gems** | [Gem NNN, Gem NNN] or None |\n\n## The Problem\n[2-3 paragraphs: WHY this matters, what happens if ignored, real-world scenario]\n\n## The Ideal Outcome\n[Acceptance criteria as checkboxes]\n\n## Approaches\n\n### Approach A: [Name]\n**Summary**: [One sentence]\n**Technique**: [Copilot Studio capabilities used]\n\n#### How It Works\n[Architecture diagram + explanation]\n\n#### Implementation\n[Step-by-step with code blocks]\n\n#### Evaluation\n[Table: criteria \u00d7 \ud83d\udfe2\ud83d\udfe1\ud83d\udd34 ratings]\n\n#### Limitations\n[Bullet list]\n\n---\n### Approach B: [Name]\n[Same structure]\n\n---\n\n## Comparison Matrix\n[Side-by-side table across all approaches]\n\n## Recommended Approach\n[Opinionated default + \"choose differently when...\"]\n\n## Platform Gotchas\n[WARNING/NOTE callouts]\n\n## Related Gems\n[Cross-references with relationship description]\n\n## References\n[Microsoft Learn links]\n\n---\n*Gem [NNN] | Author: [name] | Created: [date] | Last Validated: [date]*\n</code></pre>"},{"location":"appendices/gem-template/#quality-checklist","title":"Quality Checklist","text":"<p>Before publishing a Gem, verify:</p> <ul> <li>[ ] Minimum 2 approaches evaluated</li> <li>[ ] All code blocks are valid (YAML, Power Fx, JSON)</li> <li>[ ] Comparison Matrix includes all approaches</li> <li>[ ] Recommended Approach includes \"choose differently when...\" escape hatches</li> <li>[ ] Platform Gotchas section present (even if \"None identified\")</li> <li>[ ] Related Gems cross-reference at least 2 other Gems</li> <li>[ ] References include Microsoft Learn links</li> <li>[ ] Adaptive Card JSON targets schema 1.5 (Teams compatibility)</li> <li>[ ] Last Validated date is set</li> </ul>"},{"location":"appendices/glossary/","title":"Glossary","text":"<p>Key terms used throughout this book.</p> Term Definition A2A (Agent2Agent) Open protocol for inter-agent communication. Copilot Studio supports connecting to A2A agents (preview). Adaptive Card A JSON-based UI card format for rendering interactive content (forms, buttons, images) in chat channels. Schema 1.5 for Teams, 1.6 for Web Chat. Agent Instructions The system prompt (Markdown text in <code>GptComponentMetadata.instructions</code>) that defines the agent's personality, capabilities, and behavioral rules. Azure AI Search Microsoft's enterprise search service supporting full-text, vector, and hybrid search. Used as an advanced knowledge source in Copilot Studio (GA since May 2025). Child Agent A specialist agent connected to and invoked by a main (orchestrator) agent. Routes based on name, description, and orchestrator instructions. ConversationStart A topic trigger (<code>OnConversationStart</code>) that fires when a new conversation begins. Does not fire in M365 Copilot. Custom Connector A Power Platform connector created from an OpenAPI specification. Reusable across agents, flows, and Power Apps. Dataverse Microsoft's enterprise data platform (part of Power Platform). Used for state persistence, configuration, and business data storage. Direct Line Bot Framework API for programmatic communication with a bot/agent. Used for custom Web Chat implementations and automated testing. Environment Variable A Power Platform configuration value (<code>Env.Name</code>) that can differ between environments (dev/test/prod). Used for URLs, API keys, and tenant-specific settings. Fabric Data Agent A Microsoft Fabric agent that translates natural language into SQL/DAX/KQL queries against warehouses, lakehouses, and semantic models. Consumable as a connected agent in Copilot Studio (preview). Generative Orchestration The AI-driven mode where the LLM automatically selects topics, tools, and agents based on user intent and available descriptions. Required for MCP tools. Global Variable A conversation-scoped variable (<code>Global.Name</code>) that persists across topic switches within one conversation. Resets between conversations. Integrated Vectorization An Azure AI Search feature that automatically chunks, embeds, and indexes content using a specified embedding model. Recommended for Copilot Studio connections. KQL (Kusto Query Language) Microsoft's query language for Azure Data Explorer, Application Insights, and Fabric KQL databases. LogCustomTelemetryEvent A Copilot Studio node that sends custom events to Application Insights for monitoring and analytics. MCP (Model Context Protocol) An open standard for connecting AI agents to external tools and data sources. Copilot Studio supports MCP servers (GA) with prebuilt connectors for Dataverse, Outlook, GitHub, etc. OnError A topic trigger that fires when an error occurs during conversation processing. Used for standardized error handling. OnToolSelected A topic trigger used for child agent/tool definitions. Fires when the orchestrator routes to this agent. OData A REST protocol for querying and manipulating data. Used in Dataverse and Azure AI Search APIs. Power Fx The expression language used in Copilot Studio for conditions, calculations, and variable manipulation. Similar to Excel formulas. Prompt Tool A Copilot Studio tool that executes an LLM prompt with defined inputs and outputs. Used for classification, summarization, and dynamic instruction generation. RLS (Row-Level Security) A data security mechanism that restricts which data rows a user can see, based on their identity. Applied in Dataverse and Power BI. Semantic Ranker An Azure AI Search feature that re-ranks initial search results using a deep learning model. Improves precision. Requires Standard tier. SearchAndSummarizeContent A Copilot Studio node that searches knowledge sources and generates a grounded answer using an LLM. The primary generative answers mechanism. SendActivity A Copilot Studio node that displays a message (text, card, or attachment) to the user. Topic A discrete conversation flow in Copilot Studio, triggered by user intent (trigger phrases), events, or system conditions. Trigger Phrases Natural language examples that train the agent's NLU model to recognize when a specific topic should activate. VS Code Extension The <code>ms-CopilotStudio.vscode-copilotstudio</code> extension for editing agent YAML files locally with IntelliSense, then syncing to Copilot Studio."},{"location":"appendices/gotchas-compendium/","title":"Appendix C: Gotchas Compendium","text":"<p>Every Platform Gotcha from every Gem, consolidated and cross-referenced. Check here before deploying.</p>"},{"location":"appendices/gotchas-compendium/#channel-limitations","title":"Channel Limitations","text":"Gotcha Severity Source Gem ConversationStart topic does NOT fire in M365 Copilot. Use agent instructions instead. \ud83d\udd34 Critical GEM-001, 004, 005, 007, 014, 017 M365 Copilot does NOT support proactive messaging. Plan around Teams. \ud83d\udd34 Critical GEM-014 M365 Copilot does NOT support Fabric Data Agent connections. \ud83d\udfe1 Medium GEM-028 M365 Copilot does NOT support Omnichannel handoff. \ud83d\udfe1 Medium GEM-010 <code>System.Conversation.InTestMode</code> is always <code>false</code> outside Test Canvas. \ud83d\udfe1 Medium GEM-004 Adaptive Card <code>Action.ShowCard</code> rendering varies by channel. Test in target channel. \ud83d\udfe1 Medium GEM-003, 004, 006 M365 Copilot may batch rapidly-sent sequential messages. \ud83d\udfe1 Low GEM-003"},{"location":"appendices/gotchas-compendium/#knowledge-search","title":"Knowledge &amp; Search","text":"Gotcha Severity Source Gem PDF tables break SharePoint knowledge retrieval. Use Word (.docx). \ud83d\udd34 Critical GEM-008 <code>SearchAndSummarizeContent</code> does NOT return document URLs. \ud83d\udfe1 Medium GEM-018 SharePoint indexing has a delay (5-30 min) after upload. \ud83d\udfe1 Medium GEM-008 SharePoint file limit: 7 MB without M365 Copilot license. \ud83d\udfe1 Medium GEM-008 Max 500 knowledge objects per agent. \ud83d\udfe1 Medium GEM-026 Azure AI Search VNet indexes not supported by Copilot Studio. \ud83d\udfe1 Medium GEM-026 Only ONE vector index per Azure AI Search connection. \ud83d\udfe1 Medium GEM-026"},{"location":"appendices/gotchas-compendium/#security-data","title":"Security &amp; Data","text":"Gotcha Severity Source Gem LLM instruction-based gating is NOT a security boundary. Add hard <code>ConditionGroup</code> checks. \ud83d\udd34 Critical GEM-007, 015, 022 Platform logs capture raw user messages (including PII). \ud83d\udd34 Critical GEM-022 Never expose Direct Line secrets in client-side code. \ud83d\udd34 Critical GEM-025 <code>System.User.Id</code> format varies by channel. Test in target channel. \ud83d\udfe1 Medium GEM-001"},{"location":"appendices/gotchas-compendium/#integration","title":"Integration","text":"Gotcha Severity Source Gem MCP requires Generative Orchestration. Manual topics can't call MCP tools. \ud83d\udfe1 Medium GEM-023 MCP SSE transport deprecated after August 2025. Use Streamable HTTP. \ud83d\udfe1 Medium GEM-023 Power Automate flow failures may not return to agent gracefully. Check for blank outputs. \ud83d\udfe1 Medium GEM-009 HttpRequest default timeout may be 30+ seconds. Set explicit timeouts (5-10s). \ud83d\udfe1 Medium GEM-009 Power Automate flow runs count against quota. Plan licensing. \ud83d\udfe1 Medium GEM-001, 012, 015"},{"location":"appendices/gotchas-compendium/#agent-instructions","title":"Agent Instructions","text":"Gotcha Severity Source Gem Instructions degrade past ~3,000-4,000 words. Modularize (GEM-020). \ud83d\udfe1 Medium GEM-002, 020 Generative orchestration routes by description, not rules. Write clear descriptions. \ud83d\udfe1 Medium GEM-002, 021 <code>alwaysPrompt: true</code> required for mandatory questions in regulated flows. \ud83d\udfe1 Medium GEM-027 <code>startBehavior: CancelOtherTopics</code> essential for regulated flows. \ud83d\udfe1 Medium GEM-027"},{"location":"appendices/gotchas-compendium/#cost-performance","title":"Cost &amp; Performance","text":"Gotcha Severity Source Gem Copilot Studio doesn't expose actual token counts. Estimation only. \ud83d\udfe1 Medium GEM-012 Application Insights has ~2-5 min ingestion delay. Not real-time. \ud83d\udfe1 Low GEM-004, 016 CSAT survey response rates drop after first week. Show selectively. \ud83d\udfe1 Low GEM-016 Global variables reset between conversations. That's why GEM-001 exists. \ud83d\udfe1 Low GEM-001, 004"},{"location":"appendices/platform-reference/","title":"Appendix B: Platform Quick Reference","text":"<p>A condensed reference for the Copilot Studio constructs used throughout this book.</p>"},{"location":"appendices/platform-reference/#yaml-node-types","title":"YAML Node Types","text":"Node Kind Purpose Key Properties <code>SendActivity</code> Display message to user <code>activity.text[]</code>, <code>activity.speak[]</code> <code>Question</code> Collect user input <code>variable</code>, <code>prompt</code>, <code>entity</code>, <code>choiceOptions</code> <code>ConditionGroup</code> Branching logic <code>conditions[].condition</code>, <code>elseActions[]</code> <code>SetVariable</code> Set or calculate a variable <code>variable</code>, <code>value</code> (Power Fx expression) <code>SearchAndSummarizeContent</code> Generative answers from knowledge <code>variable</code>, <code>userInput</code>, <code>customInstructions</code> <code>HttpRequest</code> Call external REST API <code>method</code>, <code>url</code>, <code>headers</code>, <code>body</code>, <code>timeout</code> <code>InvokeFlow</code> Call Power Automate flow <code>flowId</code>, <code>inputs</code>, <code>outputVariable</code> <code>InvokePrompt</code> Call a Prompt Tool <code>promptId</code>, <code>inputs</code>, <code>outputVariable</code> <code>LogCustomTelemetryEvent</code> Log to Application Insights <code>eventName</code>, <code>properties</code> <code>AdaptiveCardPrompt</code> Display card and capture response <code>card</code>, <code>outputVariable</code> <code>GotoTopic</code> Redirect to another topic <code>topicId</code> <code>EndDialog</code> End conversation <code>clearTopicQueue</code> <code>CancelAllDialogs</code> Cancel all active topics \u2014"},{"location":"appendices/platform-reference/#variable-scopes","title":"Variable Scopes","text":"Scope Syntax Lifetime Use For Topic <code>Topic.Name</code> Current topic only Temporary data within a flow Global <code>Global.Name</code> Entire conversation Cross-topic data (user role, language, debug flag) System <code>System.*</code> Platform-provided <code>System.User.Id</code>, <code>System.Activity.Text</code>, <code>System.Conversation.Id</code> Environment <code>Env.Name</code> Environment-scoped API keys, URLs, tenant config"},{"location":"appendices/platform-reference/#dialog-trigger-types","title":"Dialog Trigger Types","text":"Trigger Kind Fires When Common Use <code>OnConversationStart</code> Conversation begins Greeting, context loading (\u26a0\ufe0f not in M365 Copilot) <code>OnRecognizedIntent</code> User message matches trigger phrases Topic routing <code>OnUnknownIntent</code> No topic match Fallback / generative answers <code>OnEscalate</code> Escalation requested Human handoff <code>OnError</code> Error occurs Error handling and logging <code>OnToolSelected</code> Agent/tool invocation Child agent definitions <code>OnScheduledTrigger</code> Scheduled event fires Proactive / autonomous agent"},{"location":"appendices/platform-reference/#power-fx-quick-reference","title":"Power Fx Quick Reference","text":"<pre><code>// String operations\nConcatenate(\"Hello, \", Global.UserName)\nContains(Lower(System.Activity.Text), \"urgent\")\nLen(Topic.Description)\nLower(text), Upper(text), Trim(text)\n\n// Conditional\nIf(IsBlank(Global.UserRole), \"User\", Global.UserRole)\nIf(Global.DebugMode, \"Debug ON\", \"Debug OFF\")\n\n// Date/Time\nText(Now(), DateTimeFormat.UTC)\nDateAdd(Now(), -90, TimeUnit.Days)\n\n// Type conversion\nValue(\"42\")          // String \u2192 Number\nText(123)            // Number \u2192 String\n</code></pre>"},{"location":"appendices/platform-reference/#channel-compatibility-matrix","title":"Channel Compatibility Matrix","text":"Feature Test Canvas Teams Web Chat M365 Copilot ConversationStart topic \u2705 \u2705 \u2705 \u274c Adaptive Cards (1.5) \u2705 \u2705 \u2705 \u2705 (rendering varies) Action.ShowCard (collapsible) \u2705 \u2705 \u2705 \ud83d\udfe1 Action.Submit \u2705 \u2705 \u2705 \ud83d\udfe1 Proactive messages N/A \u2705 \ud83d\udfe1 \u274c Omnichannel handoff N/A \u2705 \u2705 \u274c System.Conversation.InTestMode \u2705 (true) \u274c (false) \u274c (false) \u274c (false) MCP tools \u2705 \u2705 \u2705 \u2705 Event triggers N/A \u2705 \u2705 \u2705 Fabric Data Agent \u2705 \u2705 \u2705 \u274c"},{"location":"appendices/platform-reference/#adaptive-card-schema-limits","title":"Adaptive Card Schema Limits","text":"Channel Max Schema Key Restrictions Web Chat 1.6 Most features supported Teams 1.5 No <code>Action.Execute</code>. <code>Action.ShowCard</code> supported. M365 Copilot 1.5 Submit behavior may vary. Test thoroughly."},{"location":"front-matter/foreword/","title":"Foreword","text":""},{"location":"front-matter/foreword/#why-this-book-exists","title":"Why This Book Exists","text":"<p>I've been building AI agents with Microsoft Copilot Studio for enterprise clients \u2014 the kind of agents that serve thousands of employees across multiple countries, languages, and departments. Along the way, I kept hitting the same pattern:</p> <p>The documentation tells you what features exist. But it doesn't tell you which approach to use.</p> <p>\"How should I persist user context across sessions?\" Three viable approaches, each with different licensing, performance, and maintenance trade-offs. No guidance on which to choose.</p> <p>\"How do I debug my agent in M365 Copilot, where the Test Canvas doesn't exist?\" A real problem with no official solution.</p> <p>\"My knowledge source has 500 documents but the agent can't find answers.\" A format and chunking problem that took me hours to diagnose \u2014 and that Gem 008 now saves others from repeating.</p> <p>These aren't feature questions. They're design decision questions. And they deserve the same rigor that software engineering has given to design patterns.</p>"},{"location":"front-matter/foreword/#the-inspiration","title":"The Inspiration","text":"<p>Two books shaped how I think about recurring technical problems:</p> <p>Game Programming Gems (Mark DeLoura, 2000-2009): A series of books where each \"gem\" is a self-contained, practical solution to a specific game development challenge. Written by practitioners, for practitioners. No theory without code.</p> <p>Design Patterns (Gang of Four, 1994): The foundational catalog of reusable solutions to recurring software design problems. Each pattern evaluates trade-offs \u2014 when to use it, when not to use it, and what alternatives exist.</p> <p>Copilot Studio Gems applies this philosophy to AI agent development. Each Gem is:</p> <ul> <li>Focused: One recurring challenge, thoroughly explored.</li> <li>Multi-approach: At least 2 implementation strategies, evaluated against objective criteria.</li> <li>Honest: Limitations, gotchas, and \"when NOT to use this\" are first-class content.</li> <li>Code-complete: Working YAML, Power Fx, and JSON that you can implement today.</li> </ul>"},{"location":"front-matter/foreword/#who-this-book-is-for","title":"Who This Book Is For","text":"<ul> <li>Copilot Studio makers building production agents who need to make informed design decisions, not just follow tutorials.</li> <li>Solution architects evaluating implementation approaches for enterprise agent deployments.</li> <li>Pro developers using the VS Code Extension for YAML-first development who want structured patterns.</li> <li>Anyone who's ever searched \"Copilot Studio best practices\" and found only feature documentation.</li> </ul>"},{"location":"front-matter/foreword/#how-this-book-was-built","title":"How This Book Was Built","text":"<p>Every Gem in this collection originates from real project experience \u2014 patterns discovered, gotchas suffered, and trade-offs evaluated on production agents. The domain expertise was captured in a structured knowledge bank alongside platform research using Microsoft Learn documentation.</p> <p>The Gems were authored iteratively: the first 4 established the template, feedback refined the format, and subsequent Gems were evaluated for viability before writing. Backlog evaluation ensured each Gem earned its place \u2014 some ideas were deferred because they lacked sufficient trade-off richness.</p> <p>The platform evolves fast. Each Gem records when it was last validated. If you're reading this after a major Copilot Studio release, check the \"Last Validated\" dates and verify code samples against the current platform.</p>"},{"location":"front-matter/foreword/#a-living-document","title":"A Living Document","text":"<p>Copilot Studio evolves continuously. New features emerge, old limitations disappear, and yesterday's workaround becomes tomorrow's built-in feature.</p> <p>This book is designed to evolve with the platform. The web version is updated as Gems are revised. The platform gotchas section of each Gem tracks known issues \u2014 and notes when gotchas become obsolete.</p> <p>If you find that a Gem's guidance no longer applies, or if you've discovered a pattern worth sharing, the contribution guide in Appendix A provides the template.</p> <p>S\u00e9bastien Brochet February 2026</p> <p>This work is licensed under CC BY-NC-SA 4.0.</p>"},{"location":"front-matter/how-to-read/","title":"How to Read This Book","text":""},{"location":"front-matter/how-to-read/#the-gem-format","title":"The Gem Format","text":"<p>Every Gem in this book follows the same structure. Once you've read one, you know how to read them all.</p> Section What It Contains When to Read Classification Category, complexity, channel support, prerequisites Scan first \u2014 does this Gem match your situation? The Problem Why this matters, what happens if you don't solve it Read if you're not sure whether this Gem applies to you The Ideal Outcome Acceptance criteria \u2014 what success looks like Use as your evaluation rubric Approaches (2-4) Each with: How It Works, Implementation (code), Evaluation, Limitations Read the approaches relevant to your constraints Comparison Matrix Side-by-side across all approaches Quick visual decision \u2014 scan the \"Best When...\" row Recommended Approach Opinionated default + alternatives Start here if you want a fast answer Platform Gotchas Channel limitations, undocumented behaviors Read before deploying \u2014 saves hours of debugging Related Gems Cross-references Follow the thread to connected patterns"},{"location":"front-matter/how-to-read/#rating-system","title":"Rating System","text":""},{"location":"front-matter/how-to-read/#per-approach-evaluation","title":"Per-Approach Evaluation","text":"Symbol Meaning \ud83d\udfe2 Good \u2014 works well, minimal friction, low risk \ud83d\udfe1 Acceptable \u2014 works with caveats, extra steps, or partial support \ud83d\udd34 Poor \u2014 significant limitations, high effort, or unreliable"},{"location":"front-matter/how-to-read/#complexity-scale","title":"Complexity Scale","text":"Rating What It Means Typical Effort \u2b50 Configuration only, no code 15-30 minutes \u2b50\u2b50 Basic YAML editing, simple Power Fx 1-2 hours \u2b50\u2b50\u2b50 Multiple components, Power Automate Half day \u2b50\u2b50\u2b50\u2b50 Custom connectors, multi-agent coordination 1-2 days \u2b50\u2b50\u2b50\u2b50\u2b50 Deep platform expertise, significant architecture 2+ days"},{"location":"front-matter/how-to-read/#three-ways-to-read-this-book","title":"Three Ways to Read This Book","text":""},{"location":"front-matter/how-to-read/#path-1-cover-to-cover","title":"Path 1: Cover to Cover","text":"<p>Follow the Parts in order. Each Part builds on the previous:</p> <pre><code>Part I (State)  \u2192  Part II (Personalization)  \u2192  Part III (UX)  \u2192\nPart IV (Security)  \u2192  Part V (Integration)  \u2192  Part VI (Knowledge)  \u2192\nPart VII (Observability)\n</code></pre> <p>This path gives you the most complete understanding. Part I's state patterns are referenced by almost every subsequent Gem.</p>"},{"location":"front-matter/how-to-read/#path-2-jump-to-your-problem","title":"Path 2: Jump to Your Problem","text":"<p>Find the Gem matching your current challenge:</p> Your Problem Start With \"Users have to re-introduce themselves every session\" GEM-001 (Part I) \"I can't debug my agent in M365 Copilot\" GEM-004 (Part VII) \"My agent responds in the wrong language\" GEM-005 (Part II) \"Collecting 5 fields takes 10 messages\" GEM-006 (Part III) \"My agent can't find answers in the knowledge base\" GEM-008 (Part VI) \"What happens when my API is down?\" GEM-009 (Part V) \"I need to connect to an MCP server\" GEM-023 (Part V) \"Users type passwords into the chat\" GEM-022 (Part IV) \"I need deterministic flows for compliance\" GEM-027 (Part III)"},{"location":"front-matter/how-to-read/#path-3-by-role","title":"Path 3: By Role","text":"Your Role Focus On Maker (low-code) Parts I, II, III \u2014 state, personalization, UX. Start with GEM-001, GEM-002, GEM-006. Solution Architect Parts IV, V, VI \u2014 security, integration, knowledge design. Start with GEM-007, GEM-023, GEM-026. Pro Developer Parts V, VII \u2014 integration patterns, testing, analytics. Start with GEM-015, GEM-025, GEM-013. Production Ops Parts VI, VII \u2014 cost control, monitoring, testing. Start with GEM-012, GEM-004, GEM-016."},{"location":"front-matter/how-to-read/#complete-gem-catalog","title":"Complete Gem Catalog","text":"# Gem Category Complexity Part 001 Persisting User Context Across Sessions Context &amp; State \u2b50\u2b50\u2b50 I 002 Persona-Adaptive Agent Instructions Personalization \u2b50\u2b50\u2b50 II 003 Tracing Agent Progress Before Response Observability \u2b50\u2b50\u2013\u2b50\u2b50\u2b50 VII 004 Debug Mode for M365 Copilot Channel Observability \u2b50\u2b50\u2b50 VII 005 Multi-Language Agent Response Personalization \u2b50\u2b50\u2b50 II 006 Adaptive Cards as Multi-Field Forms UX \u2b50\u2b50\u2b50 III 007 Role-Based Feature Gating Security \u2b50\u2b50\u2b50 IV 008 Knowledge Source Optimization Performance \u2b50\u2b50 VI 009 Graceful Degradation and Fallback Chains Integration \u2b50\u2b50\u2b50 V 010 Agent-to-Human Handoff with Context UX \u2b50\u2b50\u2b50\u2013\u2b50\u2b50\u2b50\u2b50 III 011 Conversation Memory Within a Session Context &amp; State \u2b50\u2b50\u2013\u2b50\u2b50\u2b50 I 012 Cost Estimation and Token Budget Management Performance \u2b50\u2b50\u2b50 VI 013 Testing Strategies for Multi-Agent Architectures Observability \u2b50\u2b50\u2b50\u2013\u2b50\u2b50\u2b50\u2b50 VII 014 Proactive Agent Messages and Event-Driven Conversations Integration \u2b50\u2b50\u2b50\u2b50 V 015 Dataverse CRUD Operations Patterns Integration \u2b50\u2b50\u2b50 V 016 Conversation Analytics and Quality Measurement Observability \u2b50\u2b50\u2013\u2b50\u2b50\u2b50 VII 017 Multi-Tenant Agent Configuration Context &amp; State \u2b50\u2b50\u2b50\u2b50 I 018 SharePoint Document Retrieval and Display Integration \u2b50\u2b50\u2b50 V 020 Agent Instructions as Living Documents Personalization \u2b50\u2b50\u2b50\u2b50 II 021 Conversation Branching and Disambiguation UX \u2b50\u2b50\u2b50 III 022 Secure Data Handling in Conversations Security \u2b50\u2b50\u2b50\u2b50 IV 023 MCP Connector Integration Patterns Integration \u2b50\u2b50\u2b50 V 024 Multi-Agent Composition and Connected Agent Patterns Integration \u2b50\u2b50\u2b50\u2b50 V 025 Custom Canvas and Embedded Agent UX UX \u2b50\u2b50\u2013\u2b50\u2b50\u2b50\u2b50 III 026 Azure AI Search Advanced Integration Performance \u2b50\u2b50\u2b50\u2013\u2b50\u2b50\u2b50\u2b50 VI 027 Deterministic Flows for Regulated Workflows UX \u2b50\u2b50\u2b50\u2b50 III 028 Grounding Agents in Enterprise Analytics Data Integration \u2b50\u2b50\u2b50\u2013\u2b50\u2b50\u2b50\u2b50 V"},{"location":"front-matter/how-to-read/#prerequisites","title":"Prerequisites","text":"<p>This book assumes you have:</p> <ul> <li>Basic familiarity with Microsoft Copilot Studio (created at least one agent)</li> <li>A Power Platform environment with Copilot Studio access</li> <li>For code samples: VS Code with the Copilot Studio Extension</li> </ul> <p>No specific programming language expertise is required, though familiarity with YAML, JSON, and basic Power Fx helps.</p>"},{"location":"front-matter/how-to-read/#platform-version","title":"Platform Version","text":"<p>This book was written and validated against Copilot Studio as of February 2026. Each Gem includes a \"Last Validated\" date. If you're reading this after a major platform update:</p> <ol> <li>Check the Gem's validation date</li> <li>Verify code samples against the current platform</li> <li>Check Microsoft Learn for feature changes</li> <li>The web version of this book is updated more frequently than print</li> </ol>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/","title":"Gem 001: Persisting User Context Across Sessions","text":"<p>Remember who your users are and what they've done \u2014 even after the conversation ends.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#classification","title":"Classification","text":"Attribute Value Category Context &amp; State Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 Power Automate or HTTP integration required) Channels All (with caveats for initialization \u2014 see Platform Gotchas) Prerequisite Gems None"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#the-problem","title":"The Problem","text":"<p>Copilot Studio conversations are stateless by default. Every time a user starts a new conversation, the agent has amnesia. Global variables, topic variables, conversation history \u2014 everything resets to empty.</p> <p>This creates a frustrating experience for users who interact with the agent repeatedly:</p> <ul> <li>Repetitive questions: \"What department are you in?\" \u2014 asked every single session, even though the user answered it last week.</li> <li>Lost preferences: A user configured the agent to respond in French, but the next conversation defaults back to English.</li> <li>No continuity: \"Last time I asked about the refund status for order #12345\" \u2014 the agent has no idea what \"last time\" refers to.</li> <li>Cold-start routing: In multi-agent architectures, the orchestrator must re-detect the user's region or role every session (via Graph API or questions), even if it was already established yesterday.</li> </ul> <p>The fundamental challenge is that Copilot Studio has no built-in persistence mechanism between conversations. Global variables live only within a single conversation session. Once the session ends, everything is gone.</p> <p>You need to build your own persistence layer \u2014 and the way you do it depends on your infrastructure, licensing, and performance requirements.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A persistence mechanism that gives the agent memory across conversation sessions:</p> <ul> <li>[ ] Cross-session recall: Data stored in conversation N is available in conversation N+1 for the same user</li> <li>[ ] Automatic loading: User context is loaded at conversation start without the user needing to do anything</li> <li>[ ] Selective persistence: The builder controls which data is persisted (not everything \u2014 just what matters)</li> <li>[ ] User-scoped: Each user's context is isolated from other users</li> <li>[ ] Read and write: Context can be both loaded at start and updated during conversation</li> <li>[ ] Reasonable latency: Context loading adds &lt;3 seconds to conversation start</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#approach-a-dataverse-table-via-power-automate","title":"Approach A: Dataverse Table via Power Automate","text":"<p>Summary: Store user context as rows in a Dataverse table, with a Power Automate flow that reads at conversation start and writes at key moments. Technique: Dataverse custom table, two Power Automate cloud flows (Read + Write), global variables for in-conversation access.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#how-it-works","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;&lt;br/&gt;Global.UserLang&lt;br/&gt;Global.UserRegion&lt;br/&gt;Global.LastTopic\"] -- \"ReadContext /&lt;br/&gt;WriteContext\" --&gt; B[\"&lt;b&gt;Power Automate&lt;/b&gt;&lt;br/&gt;ReadContext /&lt;br/&gt;WriteContext\"]\n    B -- \"Lookup / Upsert\" --&gt; C[\"&lt;b&gt;Dataverse&lt;/b&gt;&lt;br/&gt;Table: UserContext\"]\n    C -. \"Stored fields\" .-&gt; B\n    B -. \"Global variables\" .-&gt; A</code></pre> <p>At conversation start, the agent calls a \"ReadContext\" flow that looks up the user by their <code>System.User.Id</code> (or email) in the Dataverse table. The flow returns stored fields \u2014 preferred language, region, last topic, etc. \u2014 and the agent loads them into global variables.</p> <p>During the conversation, when significant context changes (user updates a preference, completes a milestone), the agent calls a \"WriteContext\" flow that upserts the row in Dataverse.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#implementation","title":"Implementation","text":""},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-1-create-the-dataverse-table","title":"Step 1: Create the Dataverse table","text":"<p>In Power Apps \u2192 Tables \u2192 New Table:</p> Column Type Description <code>UserId</code> Single line of text (Primary) <code>System.User.Id</code> or UPN <code>DisplayName</code> Single line of text User's name for personalization <code>PreferredLanguage</code> Choice (EN/FR/DE/...) Language preference <code>Region</code> Single line of text Detected or chosen region <code>LastTopicName</code> Single line of text Last topic interacted with <code>LastInteraction</code> Date and Time Timestamp of last conversation <code>CustomData</code> Multiple lines of text JSON blob for extensible storage <p>Set <code>UserId</code> as the Alternate Key for fast lookups.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-2-create-the-readcontext-power-automate-flow","title":"Step 2: Create the ReadContext Power Automate flow","text":"<p>Trigger: When an HTTP request is received (or Run a flow from Copilot)</p> <pre><code>Trigger: Run a flow from Copilot\n  Input: userId (Text)\n\nAction: List Rows (Dataverse)\n  Table: UserContext\n  Filter: cr_userid eq '{userId}'\n  Top Count: 1\n\nCondition: length(outputs('List_Rows')?['body/value']) &gt; 0\n  Yes \u2192 Respond to Copilot:\n    preferredLanguage: first(outputs('List_Rows')?['body/value'])?['cr_preferredlanguage']\n    region: first(outputs('List_Rows')?['body/value'])?['cr_region']\n    lastTopicName: first(outputs('List_Rows')?['body/value'])?['cr_lasttopicname']\n    displayName: first(outputs('List_Rows')?['body/value'])?['cr_displayname']\n    customData: first(outputs('List_Rows')?['body/value'])?['cr_customdata']\n  No \u2192 Respond to Copilot:\n    (return empty/default values \u2014 this is a new user)\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-3-create-the-writecontext-power-automate-flow","title":"Step 3: Create the WriteContext Power Automate flow","text":"<pre><code>Trigger: Run a flow from Copilot\n  Inputs: userId, displayName, preferredLanguage, region, lastTopicName, customData (all Text)\n\nAction: List Rows (Dataverse)\n  Table: UserContext\n  Filter: cr_userid eq '{userId}'\n  Top Count: 1\n\nCondition: length(outputs('List_Rows')?['body/value']) &gt; 0\n  Yes \u2192 Update Row (Dataverse)\n    Row ID: first(outputs('List_Rows')?['body/value'])?['cr_usercontextid']\n    Set all fields from inputs\n    LastInteraction: utcNow()\n  No \u2192 Add Row (Dataverse)\n    Set all fields from inputs\n    LastInteraction: utcNow()\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-4-load-context-in-agent-instructions-m365-copilot-compatible","title":"Step 4: Load context in agent instructions (M365 Copilot compatible)","text":"<p>Because <code>ConversationStart</code> topic doesn't fire in M365 Copilot (see Gotchas Compendium \u2014 Channel Limitations), the safest approach is to load context via agent instructions:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: My Agent\ninstructions: |+\n  # Agent Behavior\n\n  ## CRITICAL: Load User Context\n  At the START of every new conversation, BEFORE answering the user's first question,\n  you MUST call the \"ReadUserContext\" action with the current user's ID.\n\n  Use the returned values to personalize your responses:\n  - If `preferredLanguage` is set, respond in that language\n  - If `region` is set, use it for routing decisions\n  - If `lastTopicName` is set, you can reference their previous interaction\n\n  ## Saving Context\n  Whenever the user:\n  - Expresses a language preference \u2192 call \"WriteUserContext\" to save it\n  - Completes a significant task \u2192 call \"WriteUserContext\" with the topic name\n  - Provides profile information \u2192 call \"WriteUserContext\" to persist it\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-5-alternative-load-context-in-conversationstart-topic-non-m365-channels","title":"Step 5: Alternative \u2014 Load context in ConversationStart topic (non-M365 channels)","text":"<p>For channels that support <code>ConversationStart</code> (Web Chat, Teams), you can also use a topic:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnConversationStart\n  id: main\n  actions:\n    # Call ReadContext flow\n    - kind: InvokeFlow\n      id: loadUserContext\n      flowId: \"@environmentVariables('ReadContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n      outputVariable: Topic.StoredContext\n\n    # Populate global variables from stored context\n    - kind: SetVariable\n      id: setLanguage\n      variable: Global.PreferredLanguage\n      value: =Topic.StoredContext.preferredLanguage\n\n    - kind: SetVariable\n      id: setRegion\n      variable: Global.UserRegion\n      value: =Topic.StoredContext.region\n\n    - kind: SetVariable\n      id: setLastTopic\n      variable: Global.LastTopicName\n      value: =Topic.StoredContext.lastTopicName\n\n    - kind: SetVariable\n      id: setDisplayName\n      variable: Global.UserDisplayName\n      value: =Topic.StoredContext.displayName\n\n    # Personalized greeting\n    - kind: ConditionGroup\n      id: checkReturning\n      conditions:\n        - id: isReturning\n          condition: =!IsBlank(Global.UserDisplayName)\n          actions:\n            - kind: SendActivity\n              id: greetReturning\n              activity:\n                text:\n                  - \"Welcome back, {Global.UserDisplayName}! \ud83d\udc4b\"\n      elseActions:\n        - kind: SendActivity\n          id: greetNew\n          activity:\n            text:\n              - \"Hello! I'm your assistant. How can I help you today?\"\n\n    # Save context update to log the new session\n    - kind: InvokeFlow\n      id: updateLastInteraction\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        displayName: =Global.UserDisplayName\n        preferredLanguage: =Global.PreferredLanguage\n        region: =Global.UserRegion\n        lastTopicName: =Global.LastTopicName\n        customData: \"\"\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-6-write-context-at-key-moments","title":"Step 6: Write context at key moments","text":"<p>In any topic where meaningful context changes, call the WriteContext flow:</p> <pre><code>    # After user selects a language preference\n    - kind: InvokeFlow\n      id: saveLanguagePref\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        displayName: =Global.UserDisplayName\n        preferredLanguage: =Topic.SelectedLanguage\n        region: =Global.UserRegion\n        lastTopicName: \"LanguagePreference\"\n        customData: =Global.CustomData\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires Dataverse table + 2 Power Automate flows. Straightforward but multiple components. Maintainability \ud83d\udfe2 Dataverse is well-tooled \u2014 schema changes via UI, built-in admin. Flows are simple read/write. Channel Compatibility \ud83d\udfe2 Works in all channels. Use agent instructions (not ConversationStart) for M365 Copilot. Scalability \ud83d\udfe2 Dataverse handles millions of rows. Built for enterprise workloads. Cross-session Recall \ud83d\udfe2 Persistent by design \u2014 data survives indefinitely. Latency \ud83d\udfe2 Dataverse reads are fast (&lt;1 second). Power Automate adds ~1-2s overhead."},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#limitations","title":"Limitations","text":"<ul> <li>Dataverse license required: Requires a Power Platform environment with Dataverse. Not available in all tenant configurations \u2014 particularly restrictive for personal/trial environments.</li> <li>Power Automate dependency: Two cloud flows to maintain. Flow run quotas apply (10K runs/month on standard license).</li> <li>Schema rigidity: Adding new fields means updating the table schema, both flows, and the agent's variable mapping. The <code>CustomData</code> JSON blob mitigates this for ad-hoc fields.</li> <li>No real-time sync: If a user has two simultaneous conversations (rare but possible), writes from one won't be visible in the other until next session.</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#approach-b-sharepoint-list-via-power-automate","title":"Approach B: SharePoint List via Power Automate","text":"<p>Summary: Use a SharePoint list as a lightweight key-value store for user context. Read/write via Power Automate flows. Technique: SharePoint Online list, two Power Automate cloud flows, global variables for in-conversation access.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#how-it-works_1","title":"How It Works","text":"<p>The architecture is identical to Approach A, but replaces Dataverse with a SharePoint list. This matters because SharePoint is available to virtually every Microsoft 365 tenant \u2014 no additional licensing is needed.</p> <pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio&lt;/b&gt;&lt;br/&gt;Agent\"] -- \"ReadContext /&lt;br/&gt;WriteContext\" --&gt; B[\"&lt;b&gt;Power Automate&lt;/b&gt;&lt;br/&gt;ReadContext /&lt;br/&gt;WriteContext\"]\n    B -- \"Lookup / Upsert\" --&gt; C[\"&lt;b&gt;SharePoint&lt;/b&gt;&lt;br/&gt;List: UserContext\"]\n    C -. \"Stored fields\" .-&gt; B\n    B -. \"Global variables\" .-&gt; A</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#implementation_1","title":"Implementation","text":""},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-1-create-the-sharepoint-list","title":"Step 1: Create the SharePoint list","text":"<p>On any SharePoint site accessible to your Power Automate connections:</p> Column Type Description <code>Title</code> Single line of text (built-in) Used as <code>UserId</code> \u2014 user's UPN or System.User.Id <code>DisplayName</code> Single line of text User's name <code>PreferredLanguage</code> Choice (EN/FR/DE/...) Language preference <code>Region</code> Single line of text Detected or chosen region <code>LastTopicName</code> Single line of text Last topic interacted with <code>LastInteraction</code> Date and Time Timestamp of last conversation <code>CustomData</code> Multiple lines of text (Plain) JSON blob for extensible storage <p>Create an indexed column on <code>Title</code> for fast lookups.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-2-create-the-readcontext-power-automate-flow_1","title":"Step 2: Create the ReadContext Power Automate flow","text":"<pre><code>Trigger: Run a flow from Copilot\n  Input: userId (Text)\n\nAction: Get Items (SharePoint)\n  Site: [Your SharePoint site]\n  List: UserContext\n  Filter Query: Title eq '{userId}'\n  Top Count: 1\n\nCondition: length(outputs('Get_Items')?['body/value']) &gt; 0\n  Yes \u2192 Respond to Copilot:\n    preferredLanguage: first(outputs('Get_Items')?['body/value'])?['PreferredLanguage']?['Value']\n    region: first(outputs('Get_Items')?['body/value'])?['Region']\n    lastTopicName: first(outputs('Get_Items')?['body/value'])?['LastTopicName']\n    displayName: first(outputs('Get_Items')?['body/value'])?['DisplayName']\n    customData: first(outputs('Get_Items')?['body/value'])?['CustomData']\n  No \u2192 Respond to Copilot:\n    (return empty/default values)\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-3-create-the-writecontext-power-automate-flow_1","title":"Step 3: Create the WriteContext Power Automate flow","text":"<pre><code>Trigger: Run a flow from Copilot\n  Inputs: userId, displayName, preferredLanguage, region, lastTopicName, customData\n\nAction: Get Items (SharePoint)\n  Filter Query: Title eq '{userId}'\n  Top Count: 1\n\nCondition: length(outputs('Get_Items')?['body/value']) &gt; 0\n  Yes \u2192 Update Item (SharePoint)\n    ID: first(outputs('Get_Items')?['body/value'])?['ID']\n    Set all columns from inputs\n    LastInteraction: utcNow()\n  No \u2192 Create Item (SharePoint)\n    Title: userId\n    Set all columns from inputs\n    LastInteraction: utcNow()\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-4-agent-integration","title":"Step 4: Agent integration","text":"<p>Identical to Approach A \u2014 use agent instructions for M365 Copilot, or ConversationStart topic for other channels. The YAML is the same; only the flow backing changes.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 SharePoint lists are familiar to most M365 users. No special setup or licensing. Maintainability \ud83d\udfe2 Schema changes via SharePoint UI. List is visible, editable, exportable. Channel Compatibility \ud83d\udfe2 Same as Approach A \u2014 all channels via agent instructions. Scalability \ud83d\udfe1 SharePoint lists handle up to ~30M items, but queries slow down past ~5,000 items without indexed columns. Fine for most scenarios. Cross-session Recall \ud83d\udfe2 Persistent \u2014 SharePoint data survives indefinitely with versioning. Latency \ud83d\udfe1 SharePoint reads are slower than Dataverse (~1-3 seconds). Acceptable but noticeable."},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#limitations_1","title":"Limitations","text":"<ul> <li>SharePoint query performance: Without indexed columns, queries degrade past ~5,000 rows. For large organizations (10K+ users), this becomes problematic. Create indexed columns on <code>Title</code>.</li> <li>List threshold: SharePoint's 5,000 item list view threshold can affect flow queries. Use OData filters to stay below the threshold.</li> <li>No relational data: SharePoint lists are flat. If you need relationships between context records (e.g., per-agent preferences), you'll need multiple lists or JSON in <code>CustomData</code>.</li> <li>Concurrent write risk: SharePoint doesn't have row-level locking. Simultaneous writes for the same user could cause data loss (last-write-wins). Rare in practice.</li> <li>Power Automate dependency: Same flow quota considerations as Approach A.</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#approach-c-external-rest-api-via-http-request-node","title":"Approach C: External REST API via HTTP Request Node","text":"<p>Summary: Use the <code>HttpRequest</code> node to call an external API (Azure Table Storage, Cosmos DB, or any REST endpoint) directly \u2014 no Power Automate needed. Technique: <code>HttpRequest</code> node in topic YAML, environment variables for API keys, external persistence store.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;&lt;br/&gt;HttpRequest node\"] -- \"HTTP GET / POST\" --&gt; B[\"&lt;b&gt;External API&lt;/b&gt;&lt;br/&gt;Azure Table Storage,&lt;br/&gt;Cosmos DB, custom\"]\n    B -. \"JSON response\" .-&gt; A</code></pre> <p>No Power Automate in the loop. The agent calls the API directly. This removes a dependency and can reduce latency, but it requires the external API to exist and be reachable.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#implementation_2","title":"Implementation","text":""},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-1-set-up-the-external-store","title":"Step 1: Set up the external store","text":"<p>The simplest option is Azure Table Storage (serverless, ~$0.01/month for small workloads):</p> <p>Create a table <code>UserContext</code> with:</p> <ul> <li>PartitionKey: <code>\"agent\"</code> (or agent name, for multi-agent scenarios)</li> <li>RowKey: User ID (email or System.User.Id)</li> <li>Columns: <code>PreferredLanguage</code>, <code>Region</code>, <code>LastTopicName</code>, <code>DisplayName</code>, <code>LastInteraction</code>, <code>CustomData</code></li> </ul> <p>You'll need a small Azure Function (or API Management policy) as a facade to handle authentication and expose clean REST endpoints. Alternatively, use Azure Table Storage's REST API directly with a SAS token.</p> <p>Example Azure Function endpoints:</p> <ul> <li><code>GET /api/context/{userId}</code> \u2014 Returns stored context</li> <li><code>PUT /api/context/{userId}</code> \u2014 Upserts context</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-2-store-api-credentials-in-environment-variables","title":"Step 2: Store API credentials in environment variables","text":"<p>In the Copilot Studio solution, define environment variables:</p> <pre><code>&lt;environmentvariabledefinition schemaname=\"agent_ContextApiBaseUrl\"&gt;\n  &lt;defaultvalue&gt;https://my-context-api.azurewebsites.net/api&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_ContextApiKey\"&gt;\n  &lt;defaultvalue&gt;[stored securely]&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-3-read-context-via-http-node","title":"Step 3: Read context via HTTP node","text":"<p>In the ConversationStart topic (or called from agent instructions via an explicit topic):</p> <pre><code>    # Read stored user context\n    - kind: HttpRequest\n      id: http_readContext\n      method: GET\n      url: =Concatenate(Env.agent_ContextApiBaseUrl, \"/context/\", EncodeUrl(System.User.Id))\n      headers:\n        - key: \"x-api-key\"\n          value: =Env.agent_ContextApiKey\n        - key: \"Accept\"\n          value: \"application/json\"\n      responseType: json\n      responseVariable: Topic.StoredContext\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.HttpStatus\n        errorResponseVariable: Topic.HttpError\n      timeout: 5000\n\n    # Check if context was loaded successfully\n    - kind: ConditionGroup\n      id: checkContextLoaded\n      conditions:\n        - id: success\n          condition: =Topic.HttpStatus &gt;= 200 &amp;&amp; Topic.HttpStatus &lt; 300 &amp;&amp; !IsBlank(Topic.StoredContext)\n          actions:\n            - kind: SetVariable\n              id: setLang\n              variable: Global.PreferredLanguage\n              value: =Topic.StoredContext.preferredLanguage\n\n            - kind: SetVariable\n              id: setRegion\n              variable: Global.UserRegion\n              value: =Topic.StoredContext.region\n\n            - kind: SetVariable\n              id: setName\n              variable: Global.UserDisplayName\n              value: =Topic.StoredContext.displayName\n\n            - kind: SetVariable\n              id: setLastTopic\n              variable: Global.LastTopicName\n              value: =Topic.StoredContext.lastTopicName\n      elseActions:\n        # First-time user or API error \u2014 proceed with defaults\n        - kind: SetVariable\n          id: setDefaultLang\n          variable: Global.PreferredLanguage\n          value: \"EN\"\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-4-write-context-via-http-node","title":"Step 4: Write context via HTTP node","text":"<pre><code>    # Save updated user context\n    - kind: HttpRequest\n      id: http_writeContext\n      method: PUT\n      url: =Concatenate(Env.agent_ContextApiBaseUrl, \"/context/\", EncodeUrl(System.User.Id))\n      headers:\n        - key: \"x-api-key\"\n          value: =Env.agent_ContextApiKey\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"displayName\": \"{Global.UserDisplayName}\",\n          \"preferredLanguage\": \"{Global.PreferredLanguage}\",\n          \"region\": \"{Global.UserRegion}\",\n          \"lastTopicName\": \"LanguagePreference\",\n          \"customData\": \"{Global.CustomData}\"\n        }\n      responseType: json\n      responseVariable: Topic.WriteResult\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.WriteStatus\n      timeout: 5000\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#step-5-agent-instructions-for-m365-copilot","title":"Step 5: Agent instructions for M365 Copilot","text":"<p>Same pattern as Approach A \u2014 instruct the agent to call a \"LoadContext\" topic before answering:</p> <pre><code>instructions: |+\n  ## CRITICAL: Load User Context\n  At the START of every conversation, call the \"LoadUserContext\" topic \n  to retrieve the user's stored preferences and history.\n</code></pre>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 Requires building and hosting an external API. Most effort upfront. Maintainability \ud83d\udfe1 External API is a separate codebase to maintain. But schema changes don't require Power Automate edits. Channel Compatibility \ud83d\udfe2 HTTP nodes work in all channels. Scalability \ud83d\udfe2 Azure Table Storage / Cosmos DB scale to billions of rows. Best scalability of all approaches. Cross-session Recall \ud83d\udfe2 Persistent in external store. Fully controlled retention and backup. Latency \ud83d\udfe2 Direct HTTP call eliminates Power Automate overhead. Fastest option (~200-500ms for Azure Table Storage)."},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#limitations_2","title":"Limitations","text":"<ul> <li>External infrastructure required: You must build, deploy, and maintain an API. This is overkill for simple agents.</li> <li>Security complexity: API keys, SAS tokens, or Managed Identity configuration. More attack surface than Dataverse/SharePoint.</li> <li>No Power Platform integration: Data isn't visible in Power Apps, Model-driven apps, or Power BI without additional integration.</li> <li>Cold start latency: Azure Functions on Consumption plan may have cold start delays (~2-5 seconds for first call). Use Premium plan or keep-alive pings to mitigate.</li> <li>Cost: Small but nonzero \u2014 Azure Functions + Table Storage. Negligible for low-volume, but scales with usage.</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Dataverse Approach B: SharePoint Approach C: HTTP API Implementation Effort \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe2 Low (1-2 hours) \ud83d\udd34 High (4+ hours) Licensing Requirements \ud83d\udd34 Dataverse license \ud83d\udfe2 M365 only \ud83d\udfe1 Azure subscription Query Performance \ud83d\udfe2 Fast (&lt;1s) \ud83d\udfe1 Moderate (1-3s) \ud83d\udfe2 Fast (&lt;500ms) Scalability (users) \ud83d\udfe2 Millions \ud83d\udfe1 Thousands (indexed) \ud83d\udfe2 Billions Power Platform Integration \ud83d\udfe2 Native (Power Apps, BI) \ud83d\udfe1 Via connectors \ud83d\udd34 None built-in External Dependencies \ud83d\udfe1 Power Automate flows \ud83d\udfe1 Power Automate flows \ud83d\udfe1 External API/infra Schema Flexibility \ud83d\udfe1 Table schema + JSON blob \ud83d\udfe1 List columns + JSON blob \ud83d\udfe2 Fully flexible Data Visibility \ud83d\udfe2 Power Apps admin \ud83d\udfe2 SharePoint UI \ud83d\udfe1 Custom tooling Channel Support \ud83d\udfe2 All \ud83d\udfe2 All \ud83d\udfe2 All Best When... Power Platform-native org with Dataverse M365-only org, small-medium user base Pro-dev team with Azure, maximum performance"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios: Approach A (Dataverse) \u2014 if your organization has Dataverse available.</p> <p>Dataverse is the canonical Power Platform persistence layer. It integrates naturally with Power Apps (for admin views), Power BI (for analytics), and Power Automate. Query performance is excellent, and the tooling for schema management is mature. If you're already in the Power Platform ecosystem, this is the path of least resistance long-term.</p> <p>Choose Approach B (SharePoint) when: Your organization doesn't have Dataverse licenses, or you're building a prototype/internal tool where the simplest possible setup wins. SharePoint lists are available to every M365 tenant. Just watch for the 5,000-item threshold if you have many users \u2014 create indexed columns from the start.</p> <p>Choose Approach C (HTTP API) when: You have a pro-dev team with Azure expertise and need maximum flexibility \u2014 custom schemas, sub-second latency, or integration with non-Microsoft systems. This is also the right choice if your agent persists data for a non-Power-Platform audience (e.g., context shared with a custom web app, mobile app, or other agents outside Copilot Studio).</p> <p>A practical default: Start with Approach B (SharePoint) for prototyping (zero licensing friction), then graduate to Approach A (Dataverse) for production if your Power Platform environment supports it.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>ConversationStart topic does NOT fire in M365 Copilot (see Gotchas Compendium). If you load context in <code>OnConversationStart</code>, it will work in Web Chat and Teams but silently fail in M365 Copilot. Always implement context loading in agent instructions as the primary mechanism. Use ConversationStart as a supplementary path for channels that support it (e.g., to show a personalized greeting).</p> <p>Warning</p> <p><code>System.User.Id</code> format varies by channel. In Teams, it's an AAD Object ID. In Web Chat, it may be a session-specific ID. In M365 Copilot, it's typically the AAD Object ID. Always test which identifier you receive in your target channel and use a stable, consistent key (UPN via Graph API is the safest universal identifier).</p> <p>Warning</p> <p>Global variables reset between conversations \u2014 that's the whole point of this Gem. Don't assume <code>Global.PreferredLanguage</code> persists. If the context-loading flow fails silently, the agent will run with empty globals. Always set sensible defaults in the <code>elseActions</code> branch of your context-loading logic.</p> <p>Note</p> <p>Power Automate flow runs count against your quota. Each conversation start triggers at least one flow run (ReadContext). If your agent has 1,000 conversations/day, that's 1,000 flow runs just for loading context. Plan your flow licensing accordingly. Approach C (HTTP) avoids this entirely.</p> <p>Note</p> <p>SharePoint list indexing is not automatic. You must manually create indexed columns on your lookup field (e.g., <code>Title</code>). Without indexing, queries degrade sharply past 5,000 items. Go to List Settings \u2192 Indexed Columns \u2192 Create New Index.</p>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Builds on persisted user context to dynamically adjust agent behavior (language, tone, expertise level)</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 The <code>Global.DebugMode</code> preference could be persisted across sessions using the patterns in this Gem, so admins don't re-enable debug mode every conversation</li> </ul>"},{"location":"gems/GEM-001-persisting-user-context-across-sessions/#references","title":"References","text":"<ul> <li>Microsoft Learn: Use Dataverse with Copilot Studio</li> <li>Microsoft Learn: Power Automate cloud flows in Copilot Studio</li> <li>Microsoft Learn: SharePoint connector in Power Automate</li> <li>Microsoft Learn: HTTP Request node</li> <li>Microsoft Learn: System variables (System.User)</li> <li>Azure Table Storage pricing</li> </ul> <p>Gem 001 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/","title":"Gem 002: Persona-Adaptive Agent Instructions","text":"<p>Make your agent a chameleon \u2014 adjusting tone, depth, language, and behavior based on who it's talking to.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#classification","title":"Classification","text":"Attribute Value Category Personalization Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 persona detection + conditional instructions) Channels All (with M365 Copilot caveats for initialization) Prerequisite Gems Gem 001 (for persistent persona across sessions)"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#the-problem","title":"The Problem","text":"<p>A single set of agent instructions is a one-size-fits-all experience. But real users are diverse:</p> <ul> <li>A senior engineer asks \"What's the deployment pipeline architecture?\" and expects a precise, technical deep-dive. The same agent should not explain what CI/CD means.</li> <li>A new hire asks \"How do I deploy my code?\" and needs step-by-step guidance with context. The agent should not respond with \"Run <code>az pipelines run --name release-prod</code>\" and assume they know what that means.</li> <li>An HR manager asks about the PTO policy and expects a concise, authoritative answer. Not a developer-oriented response full of caveats about engineering sprint schedules.</li> <li>A French employee expects the agent to respond in French by default. Not to be asked \"What language do you prefer?\" every single time.</li> </ul> <p>The core challenge: Copilot Studio agent instructions are static. They're defined once in the GPT component YAML and apply identically to every user in every conversation. There's no built-in mechanism to say \"if the user is an engineer, behave like this; if they're from HR, behave like that.\"</p> <p>You need to make the instructions effectively dynamic \u2014 injecting persona-specific behavior at runtime while keeping the architecture maintainable as the number of personas grows.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that adapts its behavior based on the user's persona:</p> <ul> <li>[ ] Automatic detection: The user's persona is identified without asking (or with minimal questions on first interaction)</li> <li>[ ] Behavioral adaptation: The agent adjusts tone, vocabulary, detail level, and response language per persona</li> <li>[ ] Maintainable configuration: Adding a new persona doesn't require rewriting the entire instruction set</li> <li>[ ] Graceful fallback: If persona detection fails, the agent defaults to a reasonable \"general user\" behavior</li> <li>[ ] Transparent to the user: The adaptation feels natural \u2014 users shouldn't feel like they're being \"categorized\"</li> </ul>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#approach-a-persona-branched-instructions-in-gpt-component","title":"Approach A: Persona-Branched Instructions in GPT Component","text":"<p>Summary: Define all persona variations directly in the main agent instructions (GPT component), using conditional Markdown sections. The agent selects the right behavioral section at runtime based on a global variable. Technique: GPT <code>instructions</code> field with persona sections, Power Automate or Graph API for persona detection, global variables.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#how-it-works","title":"How It Works","text":"<p>The agent's system prompt contains a \"behavioral router\" \u2014 multiple persona profiles written inline. A global variable (<code>Global.UserPersona</code>) is set at conversation start (via Graph API, persisted context from Gem 001, or user selection). The agent follows the instructions matching that persona.</p> <pre><code>flowchart TB\n    I[\"&lt;b&gt;GPT Instructions&lt;/b&gt;\"]\n    I --- E[\"&lt;b&gt;If UserPersona = Engineer&lt;/b&gt;&lt;br/&gt;Use technical language&lt;br/&gt;Include code snippets&lt;br/&gt;Be concise\"]\n    I --- M[\"&lt;b&gt;If UserPersona = Manager&lt;/b&gt;&lt;br/&gt;Use business language&lt;br/&gt;Focus on impact and timelines&lt;br/&gt;Provide summaries\"]\n    I --- N[\"&lt;b&gt;If UserPersona = NewHire&lt;/b&gt;&lt;br/&gt;Use simple language&lt;br/&gt;Explain acronyms&lt;br/&gt;Step-by-step guidance\"]\n    I --- D[\"&lt;b&gt;Default&lt;/b&gt;&lt;br/&gt;Balanced, professional tone\"]</code></pre> <p>The LLM reads the entire instruction set but follows the section matching the current persona. This works because LLMs are excellent at conditional instruction following.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#implementation","title":"Implementation","text":""},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-1-detect-the-users-persona","title":"Step 1: Detect the user's persona","text":"<p>Use one or more of these signals (in priority order):</p> Signal Source Reliability Setup Persisted preference Gem 001 (Dataverse/SharePoint) \ud83d\udfe2 High (user-confirmed) Requires Gem 001 Job title / department Graph API via Power Automate \ud83d\udfe1 Medium (may be stale) Power Automate flow User's Entra ID groups Graph API group membership \ud83d\udfe2 High (admin-managed) Power Automate flow Explicit user choice Question node at start \ud83d\udfe2 High (direct) Simple but adds friction <p>Graph API persona detection flow (extend the ReadContext flow from Gem 001):</p> <pre><code>Action: HTTP to Microsoft Graph\n  Method: GET\n  URI: https://graph.microsoft.com/v1.0/users/{userId}?$select=jobTitle,department\n\nAction: Map to Persona (Switch)\n  jobTitle contains \"Engineer|Developer|Architect\" \u2192 \"Engineer\"\n  jobTitle contains \"Manager|Director|VP\"         \u2192 \"Manager\"\n  department equals \"Human Resources\"              \u2192 \"HR\"\n  department equals \"Legal\"                        \u2192 \"Legal\"\n  default                                          \u2192 \"General\"\n\nOutput: persona (string)\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-2-set-the-global-variable","title":"Step 2: Set the global variable","text":"<p>In agent instructions (M365 Copilot compatible):</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Adaptive Agent\ninstructions: |+\n  # Agent Behavior\n\n  ## CRITICAL: Detect User Persona\n  At the START of every conversation, call the \"GetUserContext\" action.\n  Store the returned `persona` value. Use it to select your behavioral profile below.\n\n  If the action fails or returns no persona, use the \"General\" profile.\n</code></pre> <p>Or via ConversationStart topic (non-M365 channels):</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnConversationStart\n  id: main\n  actions:\n    - kind: InvokeFlow\n      id: getUserPersona\n      flowId: \"@environmentVariables('GetUserContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n      outputVariable: Topic.UserContext\n\n    - kind: SetVariable\n      id: setPersona\n      variable: Global.UserPersona\n      value: =If(IsBlank(Topic.UserContext.persona), \"General\", Topic.UserContext.persona)\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-3-write-persona-branched-instructions","title":"Step 3: Write persona-branched instructions","text":"<p>The key is structuring instructions so the LLM follows only the matching section:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Adaptive Agent\ninstructions: |+\n  # Adaptive Agent Instructions\n\n  You are an intelligent assistant for Contoso employees. Your behavior adapts\n  based on the user's persona (stored in the conversation context).\n\n  ## Persona Profiles\n\n  ### When the user's persona is \"Engineer\"\n  - **Tone**: Direct, technical, peer-to-peer\n  - **Vocabulary**: Use technical terms freely (API, CI/CD, latency, throughput)\n  - **Detail level**: High \u2014 include configuration examples, code snippets, CLI commands\n  - **Response format**: Prefer code blocks and bullet points over paragraphs\n  - **Assumptions**: User understands the tech stack. Don't explain basic concepts.\n  - **Example**: \"To trigger a pipeline re-run: `az pipelines run --name release-prod --branch main`\"\n\n  ### When the user's persona is \"Manager\"\n  - **Tone**: Professional, outcome-focused\n  - **Vocabulary**: Business language \u2014 impact, timeline, risk, stakeholders\n  - **Detail level**: Medium \u2014 summaries with option to drill down\n  - **Response format**: Start with the bottom line, then provide context\n  - **Assumptions**: User cares about WHAT and WHEN, less about HOW\n  - **Example**: \"The deployment will be ready by Thursday. Two items are blocking: security review and load testing.\"\n\n  ### When the user's persona is \"NewHire\"\n  - **Tone**: Friendly, supportive, encouraging\n  - **Vocabulary**: Simple language \u2014 define acronyms on first use\n  - **Detail level**: Maximum \u2014 step-by-step with screenshots/links where available\n  - **Response format**: Numbered steps, explain WHY each step matters\n  - **Assumptions**: User may not know internal tools or processes\n  - **Example**: \"CI/CD (Continuous Integration/Continuous Deployment) is how we automatically test and deploy code. Here's how to use it: 1. First, go to...\"\n\n  ### When the user's persona is \"HR\"\n  - **Tone**: Formal, policy-oriented\n  - **Vocabulary**: HR terminology \u2014 compliance, policy, leave entitlement\n  - **Detail level**: Cite specific policy documents and sections\n  - **Response format**: Structured with policy references\n  - **Assumptions**: User wants authoritative, citable answers\n  - **Example**: \"Per Policy HR-2024-PTO, Section 3.2: Employees with 2+ years tenure are entitled to 25 days PTO.\"\n\n  ### Default (persona is \"General\" or unknown)\n  - **Tone**: Balanced, professional, approachable\n  - **Vocabulary**: Avoid jargon \u2014 explain technical terms if used\n  - **Detail level**: Medium \u2014 provide enough context without overwhelming\n  - **Response format**: Clear paragraphs with key points highlighted\n  - **Assumptions**: Mixed expertise \u2014 provide context but don't over-explain\n\n  ## Universal Rules (apply to ALL personas)\n  - Always cite sources when referencing policies or documentation\n  - Never fabricate information \u2014 say \"I don't have that information\" if unsure\n  - Offer to clarify or provide more detail if the response might not match the user's level\n  - Respect confidentiality \u2014 never share one user's data with another\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-4-persist-the-detected-persona-link-to-gem-001","title":"Step 4: Persist the detected persona (link to Gem 001)","text":"<p>After detecting the persona, save it via Gem 001's WriteContext pattern so it persists across sessions:</p> <pre><code>    - kind: InvokeFlow\n      id: savePersona\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        preferredLanguage: =Global.PreferredLanguage\n        region: =Global.UserRegion\n        lastTopicName: =Global.LastTopicName\n        customData: =\"{\"\"persona\"\": \"\"\" &amp; Global.UserPersona &amp; \"\"\"}\"\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Once persona detection exists, the instructions are just Markdown sections. No code, no flows for the behavioral part. Maintainability \ud83d\udfe1 All personas in one instruction block. Easy to read, but the instructions grow large (token cost) as personas increase. Channel Compatibility \ud83d\udfe2 Works in all channels. Instructions are channel-agnostic. Scalability \ud83d\udfe1 Works well for 3-6 personas. Beyond 8-10, the instruction block becomes unwieldy and may exceed effective token window. Automatic Detection \ud83d\udfe1 Depends on Graph API data quality. Job titles are inconsistent across organizations. Graceful Fallback \ud83d\udfe2 Default persona section guarantees sensible behavior when detection fails."},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#limitations","title":"Limitations","text":"<ul> <li>Token saturation: Every persona's instructions are included in every conversation, even though only one is used. With 8+ personas, the system prompt becomes very long, potentially reducing response quality.</li> <li>LLM compliance is probabilistic: The model usually follows the right section, but complex or ambiguous queries may cause bleed between personas. The more clearly sections are delineated, the better.</li> <li>No runtime instruction changes: If the user's role changes mid-conversation (e.g., \"Actually, I'm asking as a manager, not an engineer\"), the persona is already set. Handling mid-conversation persona switches requires additional logic.</li> <li>Job title inconsistency: \"Sr. Software Engineer,\" \"Software Developer III,\" \"Platform Engineer\" \u2014 all map to \"Engineer\" but require fuzzy matching in the detection flow.</li> </ul>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#approach-b-multi-agent-persona-routing","title":"Approach B: Multi-Agent Persona Routing","text":"<p>Summary: Create separate specialist agents per persona, each with tailored instructions and knowledge sources. An orchestrator routes to the right specialist based on the detected persona. Technique: Multiple child agents (one per persona), orchestrator agent with routing logic, per-agent knowledge and instructions.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    O[\"&lt;b&gt;Orchestrator&lt;/b&gt;&lt;br/&gt;Persona Router\"] --&gt; E[\"&lt;b&gt;Engineer Agent&lt;/b&gt;&lt;br/&gt;Technical deep-dives\"]\n    O --&gt; M[\"&lt;b&gt;Manager Agent&lt;/b&gt;&lt;br/&gt;Business summaries\"]\n    O --&gt; N[\"&lt;b&gt;NewHire Agent&lt;/b&gt;&lt;br/&gt;Guided step-by-step\"]</code></pre> <p>Each child agent has:</p> <ul> <li>Its own tailored instructions (tone, vocabulary, detail level)</li> <li>Optionally, its own knowledge sources (e.g., Engineer agent can access API docs; Manager agent focuses on project status docs)</li> <li>A focused system prompt that stays within the effective token window</li> </ul> <p>The orchestrator detects the persona and routes all queries to the matching specialist for the entire conversation.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#implementation_1","title":"Implementation","text":""},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-1-create-persona-specific-child-agents","title":"Step 1: Create persona-specific child agents","text":"<p>Each agent is a standalone <code>AgentDialog</code> component:</p> <p>Engineer Agent:</p> <pre><code>kind: AgentDialog\nbeginDialog:\n  kind: OnToolSelected\n  id: main\n  description: Technical assistant for engineers and developers. Routes here when the user has an Engineering persona.\n\nsettings:\n  instructions: |\n    # Engineer Assistant\n\n    ## Your Identity\n    You are a senior technical advisor speaking peer-to-peer with engineers.\n\n    ## Communication Style\n    - Be direct and technical. No hand-holding.\n    - Use code examples, CLI commands, and configuration snippets freely.\n    - Reference API documentation and architecture diagrams.\n    - Prefer precision over friendliness.\n\n    ## Response Format\n    - Lead with the answer, then provide context\n    - Use code blocks for commands and config\n    - Use tables for comparisons\n    - Link to source documentation\n\n    ## Knowledge Focus\n    - Architecture documentation\n    - API references\n    - CI/CD pipeline configuration\n    - Infrastructure and deployment guides\n\ninputType: {}\noutputType: {}\n</code></pre> <p>Manager Agent:</p> <pre><code>kind: AgentDialog\nbeginDialog:\n  kind: OnToolSelected\n  id: main\n  description: Business-focused assistant for managers and directors. Routes here when the user has a Manager persona.\n\nsettings:\n  instructions: |\n    # Manager Assistant\n\n    ## Your Identity\n    You are a business advisor who translates technical topics into executive language.\n\n    ## Communication Style\n    - Lead with the bottom line: what, when, impact\n    - Use business vocabulary: risk, timeline, stakeholders, ROI\n    - Summarize first, offer details on request\n    - Avoid technical jargon \u2014 translate it when necessary\n\n    ## Response Format\n    - Start with 1-2 sentence executive summary\n    - Follow with key points (3-5 bullets maximum)\n    - Offer \"Would you like more detail on any of these?\"\n    - Use timelines and status indicators\n\n    ## Knowledge Focus\n    - Project status and timelines\n    - Team capacity and resource allocation\n    - Policy summaries and compliance\n    - Budget and cost information\n\ninputType: {}\noutputType: {}\n</code></pre> <p>NewHire Agent:</p> <pre><code>kind: AgentDialog\nbeginDialog:\n  kind: OnToolSelected\n  id: main\n  description: Onboarding assistant for new employees. Routes here when the user is a recent hire or has limited organizational context.\n\nsettings:\n  instructions: |\n    # New Employee Guide\n\n    ## Your Identity\n    You are a friendly onboarding buddy who helps new colleagues navigate the organization.\n\n    ## Communication Style\n    - Warm and encouraging \u2014 starting a new job is overwhelming\n    - Define EVERY acronym on first use: \"PTO (Paid Time Off)\"\n    - Never assume they know internal tools, processes, or people\n    - Provide context for WHY things are done a certain way\n\n    ## Response Format\n    - Numbered step-by-step instructions\n    - Include \"\ud83d\udca1 Tip:\" callouts for non-obvious things\n    - Link to onboarding documentation\n    - End with \"Is there anything else about [topic] you'd like to know?\"\n\n    ## Knowledge Focus\n    - Onboarding documentation and checklists\n    - HR policies explained in plain language\n    - Tool setup guides\n    - Team structure and key contacts\n\ninputType: {}\noutputType: {}\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-2-configure-the-orchestrator-to-route-by-persona","title":"Step 2: Configure the orchestrator to route by persona","text":"<pre><code>kind: GptComponentMetadata\ndisplayName: Persona-Adaptive Orchestrator\ninstructions: |+\n  # Orchestrator Agent\n\n  ## CRITICAL: Detect User Persona\n  At the START of every conversation, call the \"GetUserContext\" action \n  to retrieve the user's persona.\n\n  ## Routing Rules\n  Based on the detected persona, delegate ALL queries to the matching specialist:\n\n  - **persona = \"Engineer\"** \u2192 Route to Engineer Agent\n  - **persona = \"Manager\"** \u2192 Route to Manager Agent\n  - **persona = \"NewHire\"** \u2192 Route to NewHire Agent\n  - **persona = \"HR\"** \u2192 Route to HR Agent\n  - **persona = \"General\" or unknown** \u2192 Answer directly using balanced, professional tone\n\n  ## IMPORTANT\n  - Do NOT answer questions yourself when a specialist is available\n  - Route the ENTIRE conversation to one specialist (don't switch mid-conversation)\n  - If the user explicitly requests a different style (\"explain this more simply\"), \n    tell them: \"I can switch to a more guided mode. Would you like that?\" \n    Then re-route to the appropriate specialist.\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-3-leverage-copilot-studios-generative-orchestration","title":"Step 3: Leverage Copilot Studio's generative orchestration","text":"<p>Generative orchestration automatically routes to child agents based on their name and description (see Gotchas Compendium \u2014 Agent Instructions). This means the orchestrator instructions + well-written agent descriptions may be sufficient \u2014 no explicit routing topics needed.</p> <p>The key is writing clear agent descriptions that include persona keywords:</p> <pre><code># Engineer Agent description (in OnToolSelected)\ndescription: Technical assistant for engineers and developers. \n             Routes here when the user has an Engineering persona.\n\n# Manager Agent description\ndescription: Business-focused assistant for managers and directors. \n             Routes here when the user has a Manager persona.\n</code></pre> <p>The orchestrator's instructions tell it to use the persona value for routing, and the agent descriptions provide the matching criteria.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Multiple agents to create and maintain. More setup than Approach A. Maintainability \ud83d\udfe2 Each agent is independent \u2014 editing Engineer instructions doesn't affect Manager. Clear separation of concerns. Channel Compatibility \ud83d\udfe2 Child agent routing works in all channels. Scalability \ud83d\udfe2 Adding a new persona = adding a new agent. No impact on existing personas. Each agent's instructions stay lean. Automatic Detection \ud83d\udfe1 Same detection mechanism as Approach A. Graceful Fallback \ud83d\udfe2 Orchestrator answers directly for unknown personas."},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#limitations_1","title":"Limitations","text":"<ul> <li>Multi-agent complexity: More components to deploy, test, and maintain. Each persona is a separate bot component in the solution.</li> <li>Knowledge duplication risk: If agents share the same knowledge sources but with different interpretation styles, you're duplicating knowledge configuration.</li> <li>Cold routing: The orchestrator decides the persona once. If the routing is wrong, the user is stuck with the wrong specialist's tone for the entire conversation.</li> <li>Licensing impact: Multiple agents within one Copilot Studio agent don't incur extra licensing, but deploying separate top-level agents would.</li> <li>Overkill for tone-only adaptation: If the only difference between personas is tone (not knowledge source or capabilities), full agent separation is heavyweight machinery for a lightweight problem.</li> </ul>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#approach-c-dynamic-instruction-injection-via-prompt-tool","title":"Approach C: Dynamic Instruction Injection via Prompt Tool","text":"<p>Summary: Use a Prompt Tool (AI prompt) to dynamically generate persona-tailored instructions as a pre-processing step before the main response. Technique: Prompt Tool that takes user persona + raw query, returns a persona-adapted system context that the main agent then uses.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    Q[\"User Query\"] --&gt; PT[\"&lt;b&gt;Prompt Tool: PersonaAdapter&lt;/b&gt;&lt;br/&gt;Input: persona, userQuery&lt;br/&gt;Logic: Generate response guidelines&lt;br/&gt;Output: adaptedGuidelines\"]\n    PT --&gt; R[\"&lt;b&gt;Main Agent Response&lt;/b&gt;&lt;br/&gt;Uses adaptedGuidelines as&lt;br/&gt;additional context for answer\"]</code></pre> <p>Instead of static per-persona sections (Approach A) or separate agents (Approach B), a Prompt Tool dynamically generates tailored response guidelines for each query. This keeps the main instructions lean and defers persona logic to a purpose-built AI step.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#implementation_2","title":"Implementation","text":""},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-1-create-the-personaadapter-prompt-tool","title":"Step 1: Create the PersonaAdapter prompt tool","text":"<pre><code>kind: PromptTool\nid: prompt_personaAdapter\ndisplayName: \"Persona Response Adapter\"\ndescription: \"Generates persona-tailored response guidelines for a given query\"\ninstructions: |\n  You are an instruction generator. Given a user's persona and their question,\n  generate SPECIFIC response guidelines for an AI assistant.\n\n  User Persona: {persona}\n  User Question: {userQuery}\n\n  Generate response guidelines that include:\n  1. **Tone**: How should the response sound?\n  2. **Vocabulary level**: Technical, business, simple?\n  3. **Detail depth**: High-level summary or step-by-step?\n  4. **Format**: Code blocks, bullet points, numbered steps, executive summary?\n  5. **What to include**: Key aspects to cover for THIS persona asking THIS question\n  6. **What to avoid**: Things this persona wouldn't want or need\n\n  Persona profiles for reference:\n  - Engineer: Technical peer, wants code, commands, architecture details\n  - Manager: Business-focused, wants impact, timeline, bottom line\n  - NewHire: Beginner-friendly, wants step-by-step, acronym definitions, encouragement\n  - HR: Policy-focused, wants citations, formal tone, compliance language\n  - General: Balanced professional tone, moderate detail\n\n  Output ONLY the guidelines as a concise instruction block (5-8 lines max).\n  Do NOT answer the user's question \u2014 only generate guidelines for the assistant.\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: persona\n    type: string\n    required: true\n    description: \"The user's detected persona\"\n  - name: userQuery\n    type: string\n    required: true\n    description: \"The user's question\"\noutputs:\n  - name: guidelines\n    type: string\n    description: \"Tailored response guidelines\"\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-2-integrate-into-the-agents-main-instructions","title":"Step 2: Integrate into the agent's main instructions","text":"<pre><code>kind: GptComponentMetadata\ndisplayName: Adaptive Agent\ninstructions: |+\n  # Adaptive Agent\n\n  ## CRITICAL: Persona Adaptation\n  Before answering ANY user question:\n  1. Call \"GetUserContext\" to retrieve the user's persona\n  2. Call \"PersonaAdapter\" with the persona and the user's question\n  3. Follow the returned guidelines when crafting your response\n\n  ## Universal Rules\n  - Always cite sources\n  - Never fabricate information\n  - Respect confidentiality\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#step-3-topic-level-integration-alternative-to-agent-instructions","title":"Step 3: Topic-level integration (alternative to agent instructions)","text":"<p>If you prefer explicit control, use a wrapper topic:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnUnknownIntent\n  id: main\n  priority: -1\n  actions:\n    # Get persona-tailored guidelines\n    - kind: InvokePrompt\n      id: getGuidelines\n      promptId: prompt_personaAdapter\n      inputs:\n        persona: =If(IsBlank(Global.UserPersona), \"General\", Global.UserPersona)\n        userQuery: =System.Activity.Text\n      outputVariable: Topic.ResponseGuidelines\n\n    # Use SearchAndSummarize with custom instructions that include guidelines\n    - kind: SearchAndSummarizeContent\n      id: adaptedSearch\n      variable: Topic.FinalResponse\n      userInput: =System.Activity.Text\n      customInstructions: =Topic.ResponseGuidelines\n</code></pre> <p>This is powerful: the <code>customInstructions</code> field of <code>SearchAndSummarizeContent</code> is set dynamically from the prompt tool's output. Each query gets persona-tailored generation instructions.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Prompt Tool definition is simple. Integration with main flow requires careful sequencing. Maintainability \ud83d\udfe2 Persona profiles are centralized in the prompt tool. Adding a persona = editing one prompt. Channel Compatibility \ud83d\udfe2 Prompt Tools work in all channels. Scalability \ud83d\udfe2 New personas just need a line in the prompt tool's reference list. No architectural changes. Automatic Detection \ud83d\udfe1 Same detection as other approaches. Graceful Fallback \ud83d\udfe2 \"General\" persona generates balanced guidelines."},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#limitations_2","title":"Limitations","text":"<ul> <li>Double LLM call: Every user query hits the LLM twice \u2014 once for guideline generation, once for the actual response. This adds latency (~1-3 seconds) and token cost.</li> <li>Guideline quality dependency: The quality of the response depends on the quality of the generated guidelines. If the Prompt Tool generates vague guidelines, the main response won't be well-adapted.</li> <li>Debugging complexity: When the response tone is wrong, is it the Prompt Tool's guidelines that are off, or the main agent's interpretation? Two-stage diagnosis.</li> <li>Token cost: Roughly 2x token usage per query compared to Approach A. At scale, this matters.</li> <li>Non-deterministic: Guidelines vary slightly per call (LLM temperature), so the same persona + query may produce subtly different response styles across conversations.</li> </ul>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Branched Instructions Approach B: Multi-Agent Approach C: Prompt Tool Implementation Effort \ud83d\udfe2 Low (1-2 hours) \ud83d\udfe1 Medium (3-4 hours) \ud83d\udfe1 Medium (2-3 hours) Adding New Persona \ud83d\udfe1 Edit main instructions \ud83d\udfe2 Add new agent \ud83d\udfe2 Add line to prompt Instruction Token Cost \ud83d\udd34 All personas in every call \ud83d\udfe2 Only one persona per call \ud83d\udfe2 Dynamic, lean per call Response Latency \ud83d\udfe2 No extra latency \ud83d\udfe2 No extra latency \ud83d\udfe1 +1-3s (double LLM call) Per-Persona Knowledge \ud83d\udd34 Same knowledge for all \ud83d\udfe2 Separate knowledge per agent \ud83d\udfe1 Can vary via customInstructions Separation of Concerns \ud83d\udd34 All in one file \ud83d\udfe2 Fully isolated agents \ud83d\udfe1 Centralized but decoupled Debugging \ud83d\udfe2 One place to check \ud83d\udfe1 Multiple agents to check \ud83d\udd34 Two-stage diagnosis Best When... 3-5 personas, tone-only adaptation 5+ personas OR per-persona knowledge Highly dynamic, query-specific adaptation"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios: Approach A (Branched Instructions) \u2014 simplest, fastest, and sufficient for the majority of persona adaptation needs.</p> <p>If your personas differ only in tone, vocabulary, and detail level (not in which knowledge sources they access), Approach A handles this elegantly with zero additional infrastructure. The LLM is excellent at conditional instruction following, and the entire configuration lives in one file.</p> <p>Choose Approach B (Multi-Agent) when: Personas need different knowledge sources (e.g., Engineers see API docs, Managers see project status docs) or different tool access (e.g., Engineers can trigger deployments, Managers can only view status). The extra architecture cost pays for itself when persona separation extends beyond tone into capabilities.</p> <p>Choose Approach C (Prompt Tool) when: You need query-specific adaptation \u2014 not just \"be technical\" but \"for THIS specific question asked by THIS persona, here's exactly how to frame the answer.\" This is the most flexible approach but the most expensive in latency and tokens. Best for high-value, low-volume scenarios (e.g., executive-facing agents where response quality justifies the cost).</p> <p>Practical escalation path:</p> <pre><code>Start with   \u2192  Approach A (tone/vocabulary adaptation)\nGraduate to  \u2192  Approach B (if you need per-persona knowledge or tools)\nConsider     \u2192  Approach C (if query-level adaptation quality is critical)\n</code></pre>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Agent instructions have a practical token limit. While Copilot Studio doesn't enforce a hard character limit on instructions, the LLM's context window is finite. If your Approach A instructions exceed ~4,000 words (with all persona sections), the model may lose focus on later sections. Test with your most complex persona and longest query to verify quality doesn't degrade.</p> <p>Warning</p> <p>Generative orchestration routes by description, not by explicit rules (see Gotchas Compendium). In Approach B, the orchestrator may not always follow your explicit routing rules. It uses agent descriptions + its own judgment. Write descriptions that clearly include the persona keyword: \"Routes here when the user has an Engineering persona.\" Test routing with ambiguous queries.</p> <p>Warning</p> <p>ConversationStart doesn't fire in M365 Copilot (see Gotchas Compendium). If you load persona in <code>ConversationStart</code>, it won't work in M365 Copilot. Always use agent instructions as the primary persona-loading mechanism: \"Before answering, call GetUserContext to retrieve the user's persona.\"</p> <p>Note</p> <p>Graph API job titles are wildly inconsistent. \"Engineer,\" \"Software Engineer,\" \"Sr. Developer III,\" \"Platform Eng.\" \u2014 all mean \"Engineer.\" Your persona mapping needs fuzzy matching. Consider using Entra ID groups instead of job titles for more reliable persona assignment (e.g., \"Engineering\" group \u2192 Engineer persona).</p> <p>Note</p> <p>Users may want to switch persona mid-conversation. A manager might say \"Explain this to me like I'm an engineer.\" Approach A handles this naturally (the LLM adapts to the explicit request, overriding the persona section). Approach B requires re-routing to a different agent (harder). Build in an explicit \"Switch mode\" escape hatch if your users are likely to do this.</p>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Provides the persistence layer to remember persona across sessions (so detection doesn't repeat every conversation)</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Debug mode can reveal which persona was detected and which behavioral profile is active, invaluable for testing persona adaptation</li> </ul>"},{"location":"gems/GEM-002-persona-adaptive-agent-instructions/#references","title":"References","text":"<ul> <li>Microsoft Learn: Agent instructions and custom prompts</li> <li>Microsoft Learn: Prompt tools overview</li> <li>Microsoft Learn: Child agents and orchestration</li> <li>Microsoft Graph API: User resource</li> <li>Microsoft Learn: Entra ID groups for access control</li> </ul> <p>Gem 002 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/","title":"Gem 003: Tracing Agent Progress Before Response","text":"<p>Show the user what your agent is doing while it's thinking \u2014 not just what it concluded.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#classification","title":"Classification","text":"Attribute Value Category Observability Complexity \u2b50\u2b50 to \u2b50\u2b50\u2b50 (depends on approach) Channels All (with rendering differences \u2014 see Platform Gotchas) Prerequisite Gems None (Gem 004 is complementary, not required)"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#the-problem","title":"The Problem","text":"<p>When a user asks a Copilot Studio agent a complex question, the agent may take 5-15 seconds to respond. During that time, the user sees... nothing. Maybe a typing indicator. Maybe not even that. The experience feels like talking to a wall.</p> <p>This is especially painful in these scenarios:</p> <ul> <li>Multi-step orchestration: The orchestrator analyzes the query, selects a specialist agent, the specialist searches a knowledge source, assembles context, calls the LLM, and returns a response. Each step takes time. The user sees none of it.</li> <li>Power Automate flow calls: A flow retrieves data from an external API, processes it, and returns results. The flow might take 5-10 seconds. The user waits in silence.</li> <li>Knowledge-heavy queries: The agent searches multiple knowledge sources, ranks results, and synthesizes an answer. The user doesn't know if the agent is working or frozen.</li> <li>Multi-agent routing: In a hub-and-spoke architecture, the orchestrator routes to a specialist who then does its own processing. The total chain can take 10+ seconds with zero feedback.</li> </ul> <p>Modern AI interfaces (ChatGPT, Copilot in Edge, Claude) have trained users to expect visible progress \u2014 streaming tokens, \"Searching the web...\", \"Analyzing code...\" indicators. Copilot Studio's default experience falls short of this expectation.</p> <p>The fundamental constraint: Copilot Studio does not support token streaming (progressive word-by-word display). Responses arrive as complete messages. But you can simulate progress by sending intermediate messages at key decision points in your topic flow.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A progress experience that keeps users informed while the agent processes their request:</p> <ul> <li>[ ] Perceived responsiveness: Users see activity within 1-2 seconds of sending a message, even if the full response takes 10+ seconds</li> <li>[ ] Meaningful progress: Updates reflect actual work being done (not generic spinners) \u2014 \"Searching knowledge base...\" then \"Found 3 relevant documents...\" then the answer</li> <li>[ ] Non-intrusive: Progress indicators don't clutter the conversation or make scrolling painful after the response arrives</li> <li>[ ] Channel-consistent: Works acceptably across M365 Copilot, Teams, and Web Chat</li> <li>[ ] Low implementation overhead: Shouldn't require major refactoring of existing topics</li> </ul>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#approach-a-sequential-progress-messages-in-topics","title":"Approach A: Sequential Progress Messages in Topics","text":"<p>Summary: Insert <code>SendActivity</code> nodes before each long-running action in your topic flow. Each message describes what the agent is about to do. The user sees a breadcrumb trail of activity. Technique: <code>SendActivity</code> nodes with progress text, placed before <code>InvokeFlow</code>, <code>HttpRequest</code>, <code>SearchAndSummarizeContent</code>, and other slow actions.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#how-it-works","title":"How It Works","text":"<pre><code>User: \"What's our Q4 revenue vs Q3?\"\n\nAgent sends: \"\ud83d\udcca Looking up Q4 revenue data...\"          \u2190 immediate (&lt; 1s)\n  [Agent calls Power Automate flow to query data]\nAgent sends: \"\ud83d\udcca Found Q4 data. Now pulling Q3...\"       \u2190 after flow returns (2-3s)\n  [Agent calls second flow or knowledge search]\nAgent sends: \"\ud83d\udcca Comparing quarters...\"                   \u2190 after second call (2-3s)\n  [Agent formats the response]\nAgent sends: \"Here's the comparison:                      \u2190 final response (1-2s)\n  Q4: $2.4M | Q3: $2.1M | Growth: +14%\"\n</code></pre> <p>The user sees 4 messages in sequence. The first arrives within a second. Each subsequent message confirms the agent is making progress. The final message is the actual answer.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#implementation","title":"Implementation","text":"<p>Step 1: Identify slow actions in your topic</p> <p>Any action that takes &gt;2 seconds warrants a progress message:</p> Action Type Typical Latency Progress Message <code>InvokeFlow</code> (Power Automate) 2-10 seconds \"\u26a1 Running [description]...\" <code>HttpRequest</code> (external API) 1-5 seconds \"\ud83d\udd17 Calling [service name]...\" <code>SearchAndSummarizeContent</code> 3-8 seconds \"\ud83d\udd0d Searching knowledge base...\" Agent routing (multi-agent) 2-5 seconds \"\ud83e\udd16 Consulting [specialist name]...\" <p>Step 2: Insert progress messages before slow actions</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Revenue Comparison\n    triggerQueries:\n      - \"compare revenue\"\n      - \"Q4 vs Q3 revenue\"\n  actions:\n    # Progress: Step 1\n    - kind: SendActivity\n      id: progress_step1\n      activity:\n        text:\n          - \"\ud83d\udcca Looking up Q4 revenue data...\"\n\n    - kind: InvokeFlow\n      id: getQ4Data\n      flowId: \"@environmentVariables('GetRevenueFlowId')\"\n      inputs:\n        quarter: \"Q4\"\n      outputVariable: Topic.Q4Revenue\n\n    # Progress: Step 2\n    - kind: SendActivity\n      id: progress_step2\n      activity:\n        text:\n          - \"\ud83d\udcca Found Q4 data. Now pulling Q3 for comparison...\"\n\n    - kind: InvokeFlow\n      id: getQ3Data\n      flowId: \"@environmentVariables('GetRevenueFlowId')\"\n      inputs:\n        quarter: \"Q3\"\n      outputVariable: Topic.Q3Revenue\n\n    # Progress: Step 3\n    - kind: SendActivity\n      id: progress_step3\n      activity:\n        text:\n          - \"\ud83d\udcca Comparing quarters...\"\n\n    # Calculate and respond\n    - kind: SetVariable\n      id: calcGrowth\n      variable: init:Topic.Growth\n      value: =Round(((Topic.Q4Revenue - Topic.Q3Revenue) / Topic.Q3Revenue) * 100, 1)\n\n    - kind: SendActivity\n      id: sendResult\n      activity:\n        text:\n          - \"Here's the comparison:\\n\\n| Quarter | Revenue |\\n|---|---|\\n| **Q4** | ${Topic.Q4Revenue} |\\n| **Q3** | ${Topic.Q3Revenue} |\\n| **Growth** | {Topic.Growth}% |\"\n</code></pre> <p>Step 3: Standardize progress message format</p> <p>Adopt a consistent visual pattern so users recognize progress messages instantly:</p> <pre><code>[Emoji] [Present participle verb] [object]...\n</code></pre> <p>Examples:</p> <ul> <li>\"\ud83d\udd0d Searching the knowledge base...\"</li> <li>\"\u26a1 Retrieving your account details...\"</li> <li>\"\ud83e\udd16 Consulting the HR policy specialist...\"</li> <li>\"\ud83d\udcca Analyzing the data...\"</li> <li>\"\u270d\ufe0f Composing your answer...\"</li> </ul> <p>Step 4: Add progress to generative answer flows</p> <p>For <code>SearchAndSummarizeContent</code> (the generative answers node), wrap it with progress messages:</p> <pre><code>    # Before knowledge search\n    - kind: SendActivity\n      id: progress_searching\n      activity:\n        text:\n          - \"\ud83d\udd0d Searching our knowledge base for relevant information...\"\n\n    - kind: SearchAndSummarizeContent\n      id: genAnswers\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n\n    # After search \u2014 conditional on having results\n    - kind: ConditionGroup\n      id: checkAnswer\n      conditions:\n        - id: hasAnswer\n          condition: =!IsBlank(Topic.Answer)\n          actions:\n            - kind: SendActivity\n              id: sendAnswer\n              activity:\n                text:\n                  - \"{Topic.Answer}\"\n      elseActions:\n        - kind: SendActivity\n          id: noResults\n          activity:\n            text:\n              - \"I searched our knowledge base but couldn't find relevant information for that question. Could you rephrase or provide more context?\"\n</code></pre> <p>Step 5: Multi-agent progress (orchestrator \u2192 specialist)</p> <p>In multi-agent architectures, the orchestrator can announce which specialist it's routing to:</p> <pre><code># In orchestrator instructions:\ninstructions: |+\n  ## Progress Communication\n  When routing to a specialist agent, ALWAYS tell the user which specialist \n  you're consulting before transferring:\n\n  - If routing to Engineer Agent: say \"\ud83e\udd16 Consulting our technical specialist...\"\n  - If routing to HR Agent: say \"\ud83e\udd16 Connecting you with our HR policy expert...\"\n  - If routing to Finance Agent: say \"\ud83d\udcca Checking with our finance specialist...\"\n\n  Send this message BEFORE invoking the specialist agent.\n</code></pre>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Just <code>SendActivity</code> nodes \u2014 no new components, flows, or infrastructure. Maintainability \ud83d\udfe2 Progress messages are plain text. Easy to add, edit, or remove. Channel Compatibility \ud83d\udfe2 Plain text works in all channels. No rendering dependencies. Scalability \ud83d\udfe2 Add progress messages only where needed. No global overhead. Perceived Responsiveness \ud83d\udfe2 First message appears within 1 second. Users see continuous activity. Non-intrusive \ud83d\udfe1 Messages persist in the conversation. Multiple progress lines can clutter scroll history."},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#limitations","title":"Limitations","text":"<ul> <li>Conversation clutter: Each progress message is a permanent chat bubble. A 4-step process creates 4 messages before the answer \u2014 that's 5 bubbles total. In long conversations, this creates visual noise when scrolling back.</li> <li>No streaming: This simulates progress with discrete steps, not continuous streaming. Users still see messages appear as complete blocks, not word-by-word.</li> <li>Manual placement: You must identify slow actions and manually insert progress messages. No automatic instrumentation.</li> <li>Orchestrator limitations: In generative orchestration mode, you can't easily inject progress messages between the orchestrator's internal steps (intent detection \u2192 agent selection \u2192 response). Progress is only possible in manually-authored topics or via agent instructions.</li> <li>Cannot retract: Once a progress message is sent, it stays in the conversation. You can't \"replace\" \"Searching...\" with \"Found 3 results\" \u2014 both messages remain visible.</li> </ul>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#approach-b-llm-self-narration-via-agent-instructions","title":"Approach B: LLM Self-Narration via Agent Instructions","text":"<p>Summary: Instruct the agent to narrate its reasoning process within its response \u2014 showing the chain of thought as part of the answer itself. Technique: Agent instructions that mandate visible reasoning steps before the final answer. The LLM includes its process in the response text.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#how-it-works_1","title":"How It Works","text":"<pre><code>User: \"Should we use Azure Functions or Container Apps for our new microservice?\"\n\nAgent responds (single message):\n  \ud83d\udd0d **Analyzing your question...**\n  I'm comparing two Azure compute options for microservices.\n\n  \ud83d\udccb **Evaluating Azure Functions:**\n  - Serverless, event-driven, consumption billing\n  - Best for: short-lived, stateless operations\n  - Limitation: cold start latency, execution timeout (10 min default)\n\n  \ud83d\udccb **Evaluating Container Apps:**\n  - Managed Kubernetes, supports long-running processes\n  - Best for: microservices needing persistent connections, background jobs\n  - Limitation: minimum instance cost, more configuration\n\n  \u2705 **Recommendation:**\n  For a new microservice with HTTP endpoints and background processing,\n  **Container Apps** gives you more flexibility. Use Azure Functions if your\n  workload is purely event-driven with short execution times.\n</code></pre> <p>The entire narration arrives as one message (no streaming), but the included reasoning steps make the response feel more transparent than a bare conclusion.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#implementation_1","title":"Implementation","text":"<p>Step 1: Add self-narration instructions to the GPT component</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Transparent Agent\ninstructions: |+\n  # Agent Behavior\n\n  ## Response Structure\n  For EVERY response, structure your answer with visible reasoning steps:\n\n  1. **Start with analysis** (1-2 sentences):\n     Begin with \"\ud83d\udd0d **Analyzing...**\" followed by a brief restatement of what \n     you're evaluating. This shows you understood the question.\n\n  2. **Show your work** (key findings):\n     Use \"\ud83d\udccb **[Finding/Step]:**\" headers for each major element of your analysis.\n     Include the key facts, sources, or comparisons you considered.\n     Cite specific documents or data sources when available.\n\n  3. **Deliver the conclusion**:\n     Use \"\u2705 **[Recommendation/Answer]:**\" for the final answer.\n     This should be the most prominent part of the response.\n\n  ## When to Show Reasoning\n  - **Complex questions** (comparisons, analysis, multi-factor decisions): ALWAYS show full reasoning\n  - **Simple factual questions** (\"What's the PTO policy?\"): Skip analysis, go straight to answer\n  - **Follow-up questions**: Abbreviated reasoning (reference previous analysis)\n\n  ## Formatting Rules\n  - Use emoji prefixes for each phase (\ud83d\udd0d \ud83d\udccb \u2705) for visual scanning\n  - Bold the phase headers\n  - Keep analysis sections concise (3-5 bullet points each)\n  - The conclusion should be actionable and direct\n</code></pre> <p>Step 2: Add topic-level narration for manual flows</p> <p>For manually-authored topics with explicit actions, combine Approach A's progress messages with summarized findings:</p> <pre><code>    # Progress message (sent before flow call)\n    - kind: SendActivity\n      id: progress_lookup\n      activity:\n        text:\n          - \"\ud83d\udd0d Looking up your account details...\"\n\n    - kind: InvokeFlow\n      id: getAccount\n      flowId: \"@environmentVariables('GetAccountFlowId')\"\n      inputs:\n        userId: =System.User.Id\n      outputVariable: Topic.AccountData\n\n    # Response with visible reasoning\n    - kind: SendActivity\n      id: respondWithContext\n      activity:\n        text:\n          - \"\ud83d\udccb **Account Found:**\\n- Plan: {Topic.AccountData.plan}\\n- Status: {Topic.AccountData.status}\\n- Renewal: {Topic.AccountData.renewalDate}\\n\\n\u2705 **Summary:** Your {Topic.AccountData.plan} plan is **{Topic.AccountData.status}** and renews on {Topic.AccountData.renewalDate}.\"\n</code></pre> <p>Step 3: Control narration depth per persona (link to Gem 002)</p> <p>Combine with Gem 002's persona adaptation to vary narration depth:</p> <pre><code>instructions: |+\n  ## Narration Depth by Persona\n\n  ### Engineer persona\n  Show full technical reasoning: compare options, cite metrics, show trade-offs.\n  Include technical details in analysis sections.\n\n  ### Manager persona\n  Abbreviated reasoning: 1-line analysis, focus on the conclusion.\n  Start with the bottom line, offer \"Here's why:\" as optional detail.\n\n  ### NewHire persona\n  Extended reasoning: explain your thought process as teaching moments.\n  Add \"\ud83d\udca1 Tip:\" callouts to help them learn from the analysis.\n</code></pre>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions only \u2014 zero infrastructure. Add to existing agent in 15 minutes. Maintainability \ud83d\udfe2 Narration rules live in instructions. One place to edit. Channel Compatibility \ud83d\udfe2 Plain text with Markdown formatting. Works everywhere. Scalability \ud83d\udfe2 Applies to all generative responses automatically via instructions. Perceived Responsiveness \ud83d\udfe1 The entire response still arrives as one block. Users wait for the full message, but the structured content feels more thorough. Non-intrusive \ud83d\udfe2 It's one message with internal structure. No extra chat bubbles."},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#limitations_1","title":"Limitations","text":"<ul> <li>No real-time progress: The user still waits for the complete response. The narration is visible only once everything arrives. This doesn't solve the \"5 seconds of silence\" problem \u2014 it makes the eventual response feel more valuable.</li> <li>Token cost: Self-narration makes responses 30-50% longer. More tokens = more cost per response + slightly longer generation time.</li> <li>LLM compliance variability: The model follows narration instructions most of the time, but may skip reasoning steps for simple questions or deviate from the exact format. Regular testing is needed.</li> <li>Not applicable to non-generative responses: If a topic uses only manual <code>SendActivity</code> nodes (no LLM generation), self-narration doesn't apply. You'd need Approach A's sequential messages instead.</li> <li>Formatting limitations: Markdown rendering varies by channel. M365 Copilot renders Markdown well; some Web Chat implementations may not. Bold and emoji are universally safe.</li> </ul>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#approach-c-typing-indicator-with-staged-adaptive-cards","title":"Approach C: Typing Indicator with Staged Adaptive Cards","text":"<p>Summary: Send an initial \"processing\" Adaptive Card immediately, showing the agent is working. Follow with the actual response when ready. The card provides structured visual feedback. Technique: Immediate <code>SendActivity</code> with an Adaptive Card showing status, followed by the final response message.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"\ud83d\udc64 User: Find the latest architecture&lt;br/&gt;review for Project Atlas\"] --&gt; B\n    B[\"\ud83d\udd04 &lt;b&gt;Progress Card&lt;/b&gt; sent immediately&lt;br/&gt;\u25aa Identifying relevant knowledge sources&lt;br/&gt;\u25ab Searching documentation&lt;br/&gt;\u25ab Composing response&lt;br/&gt;\u23f1 Estimated: 5-10 seconds\"] --&gt; C\n    C[\"Agent processes request&lt;br/&gt;(knowledge search, LLM generation)\"] --&gt; D\n    D[\"\u2705 Final answer sent as text message\"]</code></pre> <p>The card acts as a visual \"working\" indicator. It arrives instantly, reassuring the user. The final response follows as a separate message.</p> <p>Important limitation: Copilot Studio cannot update a sent Adaptive Card in-place. The card is static once sent. You cannot change \"\u25ab Searching documentation\" to \"\u25aa Searching documentation \u2713\" without sending a new card. This makes true progress bars impossible \u2014 the card is a static \"I'm working\" signal.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#implementation_2","title":"Implementation","text":"<p>Step 1: Create a reusable progress card pattern</p> <pre><code>    # Send immediately before any slow operation\n    - kind: SendActivity\n      id: sendProgressCard\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: ColumnSet\n                  columns:\n                    - type: Column\n                      width: auto\n                      items:\n                        - type: TextBlock\n                          text: \"\ud83d\udd04\"\n                          size: large\n                    - type: Column\n                      width: stretch\n                      items:\n                        - type: TextBlock\n                          text: \"Working on your request...\"\n                          weight: bolder\n                          size: medium\n                        - type: TextBlock\n                          text: \"This may take a few seconds.\"\n                          isSubtle: true\n                          size: small\n                          spacing: none\n                - type: ColumnSet\n                  separator: true\n                  spacing: medium\n                  columns:\n                    - type: Column\n                      width: stretch\n                      items:\n                        - type: FactSet\n                          facts:\n                            - title: \"\ud83d\udd0d\"\n                              value: \"Searching knowledge sources\"\n                            - title: \"\ud83d\udcca\"\n                              value: \"Analyzing results\"\n                            - title: \"\u270d\ufe0f\"\n                              value: \"Composing response\"\n</code></pre> <p>Step 2: Create specialized progress cards per topic type</p> <p>For different topic categories, customize the card to show relevant steps:</p> <p>Knowledge search topic:</p> <pre><code>    - kind: SendActivity\n      id: sendSearchProgress\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"\ud83d\udd0d Searching Knowledge Base\"\n                  weight: bolder\n                - type: TextBlock\n                  text: \"Looking through documentation, policies, and FAQs for your answer...\"\n                  wrap: true\n                  isSubtle: true\n                - type: TextBlock\n                  text: \"\u23f1 Usually takes 3-8 seconds\"\n                  size: small\n                  isSubtle: true\n</code></pre> <p>Multi-agent routing topic:</p> <pre><code>    - kind: SendActivity\n      id: sendRoutingProgress\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"\ud83e\udd16 Connecting to Specialist\"\n                  weight: bolder\n                - type: FactSet\n                  facts:\n                    - title: \"Query\"\n                      value: \"{System.Activity.Text}\"\n                    - title: \"Specialist\"\n                      value: \"{Topic.TargetAgent}\"\n                    - title: \"Region\"\n                      value: \"{Global.UserRegion}\"\n                - type: TextBlock\n                  text: \"\u23f1 Preparing your response...\"\n                  size: small\n                  isSubtle: true\n</code></pre> <p>Step 3: Follow with the actual response</p> <p>After the slow operation completes, send the response as a regular message:</p> <pre><code>    # Progress card (sent immediately)\n    - kind: SendActivity\n      id: sendProgressCard\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              # ... card definition from above ...\n\n    # Slow operation\n    - kind: SearchAndSummarizeContent\n      id: searchKnowledge\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n\n    # Actual response\n    - kind: SendActivity\n      id: sendFinalAnswer\n      activity:\n        text:\n          - \"{Topic.Answer}\"\n</code></pre> <p>Step 4: Combine with Approach A for multi-step flows</p> <p>For flows with multiple slow operations, send the card first, then use Approach A's text progress messages between steps, then the final answer:</p> <pre><code>    # 1. Initial progress card\n    - kind: SendActivity\n      id: progressCard\n      activity:\n        attachments:\n          # ... Adaptive Card ...\n\n    # 2. First slow operation\n    - kind: InvokeFlow\n      id: step1\n      # ...\n\n    # 3. Text progress update\n    - kind: SendActivity\n      id: progress_step2\n      activity:\n        text:\n          - \"\ud83d\udcca Data retrieved. Analyzing trends...\"\n\n    # 4. Second slow operation\n    - kind: InvokeFlow\n      id: step2\n      # ...\n\n    # 5. Final response\n    - kind: SendActivity\n      id: finalResponse\n      activity:\n        text:\n          - \"Here are the results: ...\"\n</code></pre>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Adaptive Card JSON is verbose. Requires card design per topic category. Maintainability \ud83d\udfe1 Card JSON in YAML is hard to read. Changes require careful JSON editing. Channel Compatibility \ud83d\udfe1 Cards render in Teams and Web Chat. M365 Copilot renders cards but styling may differ. Scalability \ud83d\udfe1 Reusable card patterns help, but each topic category may need its own card design. Perceived Responsiveness \ud83d\udfe2 Instant visual feedback \u2014 the card appears within 1 second. More polished than plain text. Non-intrusive \ud83d\udfe1 The progress card remains in chat history after the response. Takes up visual space."},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#limitations_2","title":"Limitations","text":"<ul> <li>Cards cannot be updated in-place: Once sent, the card is static. You cannot show a progress bar filling up or check off completed steps. The card is a snapshot, not a live indicator.</li> <li>Visual space: The progress card + the actual response = 2 messages. The card takes up significant visual space (especially on mobile) and remains in scroll history.</li> <li>Channel rendering differences: Adaptive Cards look great in Teams, acceptable in Web Chat, and vary in M365 Copilot. <code>FactSet</code> rendering and column layouts may differ.</li> <li>Overkill for simple queries: Showing a progress card for a 2-second response feels heavy-handed. You need to selectively apply cards only to known-slow operations.</li> <li>No fallback for non-card channels: If deployed to a channel that doesn't render Adaptive Cards, the progress card is invisible. Always include a text fallback.</li> </ul>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Sequential Messages Approach B: LLM Self-Narration Approach C: Adaptive Card Implementation Effort \ud83d\udfe2 Low (30 min) \ud83d\udfe2 Low (15 min) \ud83d\udfe1 Medium (1-2 hours) Real-time Progress \ud83d\udfe2 Yes \u2014 messages appear between steps \ud83d\udd34 No \u2014 one message at the end \ud83d\udfe1 Partial \u2014 card appears immediately, static after Conversation Clutter \ud83d\udd34 Multiple messages per interaction \ud83d\udfe2 One structured message \ud83d\udfe1 Card + response = 2 messages Generative Responses \ud83d\udd34 Doesn't apply to LLM-generated answers \ud83d\udfe2 Built for generative responses \ud83d\udfe1 Card before, generative after Manual Topics \ud83d\udfe2 Full control over placement \ud83d\udd34 Doesn't apply (no LLM involved) \ud83d\udfe2 Works before any slow action Token Cost \ud83d\udfe2 None (static text) \ud83d\udfe1 +30-50% per response \ud83d\udfe2 None (static card) Visual Polish \ud83d\udfe1 Plain text with emoji \ud83d\udfe2 Structured reasoning in answer \ud83d\udfe2 Professional card UI Best When... Manual topics with slow actions (flows, APIs) Generative responses needing transparency High-polish experiences, brand-conscious deployments"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios: Combine Approaches A + B \u2014 they're complementary, not competing.</p> <p>Use Approach A (sequential messages) in manually-authored topics with explicit slow actions. Before every <code>InvokeFlow</code> or <code>HttpRequest</code> that takes &gt;2 seconds, insert a progress message. This gives real-time feedback where you have full control over the flow.</p> <p>Use Approach B (self-narration) for generative responses where the LLM generates the answer. Add narration instructions to your GPT component so every generative answer shows its reasoning. This doesn't provide real-time progress (the response still arrives as one block), but the structured content feels transparent and builds trust.</p> <pre><code>Manual topics (flows, APIs)  \u2192  Approach A: Sequential progress messages\nGenerative answers (LLM)     \u2192  Approach B: Self-narration instructions\nHigh-polish deployments      \u2192  Approach C: Add initial progress card\n</code></pre> <p>Choose Approach C when: Visual presentation matters \u2014 stakeholder-facing agents, customer support, or brand-conscious deployments where a \"Working on it...\" Adaptive Card feels more professional than plain text. Combine it with A (card first, then text updates, then answer).</p> <p>Skip Approach C when: You're building internal tools where function beats polish. The card JSON overhead isn't worth it for developer-facing agents.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Copilot Studio native generative answers do NOT support token streaming. Unlike ChatGPT or Copilot in Edge, Copilot Studio's built-in generative answers (<code>SearchAndSummarizeContent</code>, agent instructions) send complete messages. You cannot show text appearing word-by-word. All approaches in this Gem are workarounds \u2014 discrete messages or structured single responses \u2014 not true streaming. Note: Custom engine agents built with Bot Framework SDK CAN stream responses in Teams (informative updates \u2192 token-by-token response \u2192 final message), but this requires building outside Copilot Studio's native authoring experience.</p> <p>Warning</p> <p>Generative orchestration is a black box for progress. When using generative orchestration (the AI automatically routes to topics/agents), you cannot insert progress messages between the orchestrator's internal steps. Progress messages only work in manually-authored topics or via agent instructions (for LLM self-narration). If your agent is 100% generative orchestration, only Approach B applies.</p> <p>Warning</p> <p>Adaptive Cards cannot be updated after sending. Once <code>SendActivity</code> delivers a card, it's immutable. There's no \"update card\" or \"replace message\" API in Copilot Studio. True progress bars or step-by-step checkmarks are not possible. The card is a static \"I'm working\" signal.</p> <p>Note</p> <p>M365 Copilot may batch messages. In some M365 Copilot rendering scenarios, rapidly-sent sequential messages (Approach A) may appear as a batch rather than one-by-one. The progress effect is reduced. This is a rendering behavior, not a Copilot Studio limitation. Test in your target channel.</p> <p>Note</p> <p>Emoji rendering is channel-dependent. The emoji in progress messages (\ud83d\udd0d \ud83d\udcca \u270d\ufe0f \ud83e\udd16) render natively in Teams and M365 Copilot. In custom Web Chat deployments, rendering depends on the browser/OS. Emoji are universally safe, but their visual prominence varies.</p> <p>Note</p> <p>Self-narration adds ~30-50% token cost. Approach B generates longer responses by design. If you're on a consumption-based LLM pricing model, factor this into your cost estimates. For most agents, the improved user experience justifies the cost. For high-volume agents (100K+ conversations/month), test the cost impact.</p>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 GEM-004 shows diagnostic information to administrators; this Gem shows progress to all users. Approach A's progress messages and GEM-004's debug blocks can coexist in the same topic (progress for everyone, debug for admins).</li> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Self-narration depth can be adjusted per persona (engineers get full analysis, managers get bottom-line-first).</li> </ul>"},{"location":"gems/GEM-003-tracing-agent-progress-before-response/#references","title":"References","text":"<ul> <li>Microsoft Learn: Message nodes in Copilot Studio</li> <li>Microsoft Learn: Adaptive Cards in Copilot Studio</li> <li>Microsoft Learn: Generative orchestration</li> <li>Adaptive Cards Designer</li> <li>Chain-of-Thought prompting techniques</li> </ul> <p>Gem 003 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/","title":"Gem 004: Debug Mode for M365 Copilot Channel","text":"<p>Replicate the Test Canvas diagnostic experience inside M365 Copilot \u2014 where the built-in Test panel doesn't exist.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#classification","title":"Classification","text":"Attribute Value Category Observability Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 multiple components, conditional logic) Channels M365 Copilot, Teams, Web Chat (designed for channels where Test Canvas is unavailable) Prerequisite Gems None"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#the-problem","title":"The Problem","text":"<p>Copilot Studio's Test Canvas is the primary debugging tool during development. It shows rich diagnostic information: which topic was triggered, variable values at each step, knowledge search results, error codes, and timing. It's indispensable during development.</p> <p>But the Test Canvas only exists inside Copilot Studio's authoring environment. The moment your agent is published to M365 Copilot, Teams, or a custom website, all of that diagnostic visibility vanishes. The agent becomes a black box: you see the final response, but nothing about how it got there.</p> <p>This creates real problems:</p> <ul> <li>Troubleshooting production issues: A user reports an incorrect answer. Was it a routing error? A knowledge source gap? A variable not set? Without diagnostics, you're guessing.</li> <li>Validating behavior in-channel: Agents behave differently across channels (see Platform Gotchas). What works in the Test Canvas may fail in M365 Copilot \u2014 and you can't debug it in-place.</li> <li>Multi-agent architectures: When an orchestrator routes to specialist agents, you need visibility into which agent was selected and why. In the Test Canvas you see this; in M365 Copilot you don't.</li> <li>Stakeholder demos: During UAT or demos, when something goes wrong, \"let me check in the authoring tool\" is a poor answer. Having in-channel diagnostics builds confidence.</li> </ul> <p>The built-in <code>System.Conversation.InTestMode</code> variable is <code>true</code> only inside the Test Canvas \u2014 it's always <code>false</code> in every deployed channel. So you cannot conditionally show debug output using the platform's own test detection. You need to build your own debug mechanism.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A debug mode that mirrors key Test Canvas diagnostics, available in any deployed channel:</p> <ul> <li>[ ] Channel-agnostic: Works in M365 Copilot, Teams, and Web Chat \u2014 not just the Test Canvas</li> <li>[ ] Toggleable per-user: Can be activated and deactivated during a conversation without redeploying the agent</li> <li>[ ] Access-controlled: Regular users never see debug output, even accidentally</li> <li>[ ] Diagnostic coverage: Shows topic routing, variable state, knowledge search info, and errors</li> <li>[ ] Low overhead: Minimal performance impact when debug mode is off</li> </ul>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#approach-a-keyword-triggered-inline-debug-messages","title":"Approach A: Keyword-Triggered Inline Debug Messages","text":"<p>Summary: A \"magic keyword\" topic toggles a global debug flag; topics conditionally emit extra text messages with diagnostic info when the flag is on. Technique: Global variable (<code>Global.DebugMode</code>), <code>OnRecognizedIntent</code> trigger topic, <code>ConditionGroup</code> nodes checking the flag, <code>SendActivity</code> with diagnostic output.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#how-it-works","title":"How It Works","text":"<pre><code>User: \"xdebug on\"\n  \u2192 ToggleDebug topic fires\n  \u2192 Sets Global.DebugMode = true\n  \u2192 Confirms: \"\ud83d\udd27 Debug mode enabled\"\n\nUser: \"What's the PTO policy in France?\"\n  \u2192 Orchestrator routes to France Specialist\n  \u2192 France Specialist searches knowledge source\n  \u2192 Response: \"In France, employees get 25 days...\"\n  \u2192 Debug check: Global.DebugMode = true \u2192 emit debug message\n  \u2192 Debug: \"\ud83d\udd27 Topic: FrancePolicies | Agent: FranceHR | Search: 3 results | Time: 1.2s\"\n\nUser: \"xdebug off\"\n  \u2192 ToggleDebug topic fires\n  \u2192 Sets Global.DebugMode = false\n  \u2192 Confirms: \"Debug mode disabled\"\n</code></pre> <p>The debug output is a regular text message sent conditionally. It appears in the conversation stream right after the agent's actual response. The keyword <code>xdebug</code> is deliberately obscure \u2014 regular users won't accidentally type it.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#implementation","title":"Implementation","text":"<p>Step 1: Create the Toggle Debug topic</p> <p>This topic listens for the debug keyword and flips the global variable:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Toggle Debug Mode\n    includeInOnSelectIntent: false\n    triggerQueries:\n      - \"xdebug on\"\n      - \"xdebug off\"\n      - \"xdebug\"\n      - \"enable debug mode\"\n      - \"disable debug mode\"\n  actions:\n    # Detect if user wants ON or OFF\n    - kind: ConditionGroup\n      id: detectDirection\n      conditions:\n        - id: wantsOn\n          condition: =Contains(Lower(System.Activity.Text), \"on\") || Contains(Lower(System.Activity.Text), \"enable\")\n          actions:\n            - kind: SetVariable\n              id: setDebugOn\n              variable: Global.DebugMode\n              value: =true\n            - kind: SendActivity\n              id: confirmOn\n              activity:\n                text:\n                  - \"\ud83d\udd27 Debug mode **enabled**. Diagnostic info will appear after each response.\\n\\nSay **xdebug off** to disable.\"\n        - id: wantsOff\n          condition: =Contains(Lower(System.Activity.Text), \"off\") || Contains(Lower(System.Activity.Text), \"disable\")\n          actions:\n            - kind: SetVariable\n              id: setDebugOff\n              variable: Global.DebugMode\n              value: =false\n            - kind: SendActivity\n              id: confirmOff\n              activity:\n                text:\n                  - \"Debug mode **disabled**.\"\n      elseActions:\n        # Plain \"xdebug\" toggles current state\n        - kind: SetVariable\n          id: toggleDebug\n          variable: Global.DebugMode\n          value: =If(Global.DebugMode, false, true)\n        - kind: SendActivity\n          id: confirmToggle\n          activity:\n            text:\n              - \"\ud83d\udd27 Debug mode is now **{If(Global.DebugMode, \\\"enabled\\\", \\\"disabled\\\")}**.\"\n</code></pre> <p>Step 2: Add debug output blocks to your topics</p> <p>After key actions (knowledge search, API call, routing decision), insert a conditional debug block. This is a reusable pattern you'll repeat in every topic that needs diagnostics:</p> <pre><code>    # === DEBUG OUTPUT BLOCK (copy to any topic) ===\n    - kind: ConditionGroup\n      id: debugOutput_afterSearch\n      conditions:\n        - id: isDebugOn\n          condition: =Global.DebugMode = true\n          actions:\n            - kind: SendActivity\n              id: debugMsg_search\n              activity:\n                text:\n                  - \"\ud83d\udd27 **Debug Trace**\\n- **Topic**: PasswordReset\\n- **Step**: Knowledge Search\\n- **Query**: {System.Activity.Text}\\n- **Result found**: {If(IsBlank(Topic.SearchResult), \\\"No\\\", \\\"Yes\\\")}\\n- **Conversation**: {System.Conversation.Id}\\n- **Time (UTC)**: {Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 3: Add debug output to the OnError topic</p> <p>Enhance the standard error handler to include debug-level detail even in production channels:</p> <pre><code>kind: AdaptiveDialog\nstartBehavior: UseLatestPublishedContentAndCancelOtherTopics\nbeginDialog:\n  kind: OnError\n  id: main\n  actions:\n    - kind: SetVariable\n      id: setTimestamp\n      variable: init:Topic.CurrentTime\n      value: =Text(Now(), DateTimeFormat.UTC)\n\n    - kind: ConditionGroup\n      id: debugOrNormal\n      conditions:\n        # Show full details in Test Canvas OR when debug mode is on\n        - id: showDetails\n          condition: =System.Conversation.InTestMode = true || Global.DebugMode = true\n          actions:\n            - kind: SendActivity\n              id: sendDetailedError\n              activity:\n                text:\n                  - \"\ud83d\udd27 **Error Details**\\n- **Message**: {System.Error.Message}\\n- **Code**: {System.Error.Code}\\n- **Conversation**: {System.Conversation.Id}\\n- **Time (UTC)**: {Topic.CurrentTime}\"\n      elseActions:\n        - kind: SendActivity\n          id: sendUserError\n          activity:\n            text:\n              - \"I'm sorry, something went wrong. Please try again.\\n\\nIf the issue persists, reference conversation **{System.Conversation.Id}** (at {Topic.CurrentTime} UTC).\"\n\n    - kind: LogCustomTelemetryEvent\n      id: logError\n      eventName: AgentError\n      properties: \"={ErrorMessage: System.Error.Message, ErrorCode: System.Error.Code, ConversationId: System.Conversation.Id, TimeUTC: Topic.CurrentTime, DebugMode: Global.DebugMode}\"\n\n    - kind: CancelAllDialogs\n      id: cancelAll\n</code></pre> <p>Step 4 (Optional): Role-based access control</p> <p>For stricter security, check the user's role before allowing the debug toggle. This requires a Power Automate flow that queries the user's group membership:</p> <pre><code>    # In the ToggleDebug topic, BEFORE setting the variable:\n    - kind: ConditionGroup\n      id: checkUserRole\n      conditions:\n        - id: isAdmin\n          condition: =Global.UserRole = \"Admin\" || Global.UserRole = \"Developer\"\n          actions:\n            # ... proceed with toggle logic ...\n      elseActions:\n        - kind: SendActivity\n          id: denyAccess\n          activity:\n            text:\n              - \"Sorry, debug mode is only available to administrators.\"\n</code></pre>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Simple YAML \u2014 global variable + ConditionGroup. No external dependencies. Maintainability \ud83d\udfe1 Debug blocks must be manually added to each topic. Risk of inconsistency as topics grow. Channel Compatibility \ud83d\udfe2 Plain text works everywhere \u2014 M365 Copilot, Teams, Web Chat. Scalability \ud83d\udfe1 Works well up to ~15 topics. Beyond that, maintaining debug blocks in every topic becomes tedious. Diagnostic Coverage \ud83d\udfe1 Shows what you explicitly instrument. No automatic coverage \u2014 you only see what you code. Low Overhead (debug off) \ud83d\udfe2 A single boolean check per topic. Negligible performance impact."},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#limitations","title":"Limitations","text":"<ul> <li>Manual instrumentation: You must add debug blocks to every topic and every step you want to trace. There's no \"auto-trace everything.\"</li> <li>Conversation clutter: Debug messages are visible as regular messages. In a long conversation, they can make the chat noisy.</li> <li>No persistent record: Debug output is ephemeral \u2014 once the conversation ends, the trace is gone (unless you also telemetry-log it).</li> <li>Security through obscurity: The keyword approach relies on users not guessing <code>xdebug</code>. For regulated environments, role-based gating (Step 4) is necessary.</li> </ul>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#approach-b-application-insights-telemetry-pipeline","title":"Approach B: Application Insights Telemetry Pipeline","text":"<p>Summary: Instrument topics with <code>LogCustomTelemetryEvent</code> nodes at every key decision point. Query the telemetry out-of-band via Application Insights and KQL. Technique: <code>LogCustomTelemetryEvent</code> nodes, Application Insights connected to the agent, KQL queries, optional Power BI dashboard.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;&lt;br/&gt;(any channel)\"] --&gt;|telemetry events| B[\"&lt;b&gt;Application Insights&lt;/b&gt;&lt;br/&gt;(telemetry sink)\"]\n    B --&gt; C[\"&lt;b&gt;KQL Query / Power BI&lt;/b&gt;&lt;br/&gt;(diagnostic viewer)\"]</code></pre> <p>Every topic emits structured telemetry events at key decision points: topic entry, knowledge search, API call, routing decision, error. These events flow to Application Insights where they can be queried, filtered, and visualized \u2014 completely outside the conversation.</p> <p>The user never sees debug output. The developer queries Application Insights separately, filtering by conversation ID, timestamp, or user.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#implementation_1","title":"Implementation","text":"<p>Step 1: Connect Application Insights to your agent</p> <p>In Copilot Studio:</p> <ol> <li>Go to Settings \u2192 Advanced \u2192 Application Insights</li> <li>Enter your Application Insights Connection String</li> <li>Save \u2014 telemetry starts flowing immediately</li> </ol> <p>Step 2: Instrument topics with telemetry events</p> <p>Add <code>LogCustomTelemetryEvent</code> nodes at key points. Use a consistent event naming scheme:</p> <pre><code>    # At topic entry\n    - kind: LogCustomTelemetryEvent\n      id: log_topicEntry\n      eventName: AgentTrace\n      properties: \"={TracePoint: \\\"TopicEntry\\\", TopicName: \\\"PasswordReset\\\", UserQuery: System.Activity.Text, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # After knowledge search\n    - kind: LogCustomTelemetryEvent\n      id: log_afterSearch\n      eventName: AgentTrace\n      properties: \"={TracePoint: \\\"KnowledgeSearch\\\", TopicName: \\\"PasswordReset\\\", HasResults: !IsBlank(Topic.SearchResult), ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # At routing decision (multi-agent)\n    - kind: LogCustomTelemetryEvent\n      id: log_routing\n      eventName: AgentTrace\n      properties: \"={TracePoint: \\\"AgentRouting\\\", SelectedAgent: Topic.TargetAgent, UserRegion: Global.UserRegion, RoutingReason: Topic.RoutingReason, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # Before response\n    - kind: LogCustomTelemetryEvent\n      id: log_response\n      eventName: AgentTrace\n      properties: \"={TracePoint: \\\"ResponseSent\\\", TopicName: \\\"PasswordReset\\\", ResponseLength: Len(Topic.ResponseText), ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 3: Define a standard telemetry schema</p> <p>Consistency across all topics makes querying reliable. Use these standard properties:</p> Property Type Description Example <code>TracePoint</code> string Where in the flow this event fires <code>TopicEntry</code>, <code>KnowledgeSearch</code>, <code>AgentRouting</code>, <code>ResponseSent</code>, <code>Error</code> <code>TopicName</code> string Name of the current topic <code>PasswordReset</code> <code>ConversationId</code> string Unique conversation identifier <code>System.Conversation.Id</code> <code>Timestamp</code> string UTC timestamp <code>Text(Now(), DateTimeFormat.UTC)</code> <code>UserQuery</code> string The user's message (at entry points) <code>System.Activity.Text</code> <code>SelectedAgent</code> string Which agent was routed to (multi-agent) <code>FranceHRSpecialist</code> <code>HasResults</code> boolean Whether knowledge search returned results <code>true</code> / <code>false</code> <p>Step 4: Query with KQL</p> <p>Open Application Insights \u2192 Logs and run:</p> <pre><code>// Full conversation trace (ordered timeline)\ncustomEvents\n| where name == \"AgentTrace\"\n| where tostring(customDimensions.ConversationId) == \"&lt;paste-conversation-id&gt;\"\n| extend TracePoint = tostring(customDimensions.TracePoint)\n| extend TopicName = tostring(customDimensions.TopicName)\n| extend UserQuery = tostring(customDimensions.UserQuery)\n| extend SelectedAgent = tostring(customDimensions.SelectedAgent)\n| project timestamp, TracePoint, TopicName, UserQuery, SelectedAgent\n| order by timestamp asc\n</code></pre> <pre><code>// Error summary (last 24 hours)\ncustomEvents\n| where name == \"AgentTrace\"\n| where tostring(customDimensions.TracePoint) == \"Error\"\n| where timestamp &gt; ago(24h)\n| extend ErrorMessage = tostring(customDimensions.ErrorMessage)\n| extend TopicName = tostring(customDimensions.TopicName)\n| summarize ErrorCount = count() by TopicName, ErrorMessage\n| order by ErrorCount desc\n</code></pre> <pre><code>// Routing decisions analysis (multi-agent)\ncustomEvents\n| where name == \"AgentTrace\"\n| where tostring(customDimensions.TracePoint) == \"AgentRouting\"\n| where timestamp &gt; ago(7d)\n| extend SelectedAgent = tostring(customDimensions.SelectedAgent)\n| extend UserRegion = tostring(customDimensions.UserRegion)\n| summarize RouteCount = count() by SelectedAgent, UserRegion\n| render barchart\n</code></pre> <p>Step 5 (Optional): Power BI dashboard</p> <p>Connect Power BI to Application Insights for a live trace dashboard:</p> <ol> <li>Use the <code>customEvents</code> table as data source</li> <li>Filter by <code>name == \"AgentTrace\"</code></li> <li>Create visuals: conversation timeline, error rates, routing distribution</li> <li>Share with team for real-time monitoring</li> </ol>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires App Insights setup + learning KQL. Once set up, adding events is straightforward. Maintainability \ud83d\udfe2 Consistent schema makes queries reusable. Easy to add new trace points. Channel Compatibility \ud83d\udfe2 Works identically in all channels \u2014 telemetry flows regardless of deployment target. Scalability \ud83d\udfe2 Handles any number of topics. Built for enterprise-scale logging. Diagnostic Coverage \ud83d\udfe1 Same manual instrumentation as Approach A. But data is persistent and queryable. Low Overhead (debug off) \ud83d\udfe1 Telemetry is always-on \u2014 every conversation is traced. Small but constant performance cost."},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#limitations_1","title":"Limitations","text":"<ul> <li>Not real-time in conversation: You see diagnostics in Application Insights, not in the chat. There's a delay of ~2-5 minutes before events appear.</li> <li>Requires Application Insights: Additional Azure resource with associated costs (though the free tier covers most development scenarios).</li> <li>KQL learning curve: Writing effective queries requires familiarity with Kusto Query Language.</li> <li>No interactive debugging: You can't \"step through\" a conversation. You reconstruct what happened after the fact.</li> <li>Always-on cost: Unlike Approach A (which does nothing when debug is off), telemetry events fire for every user, every conversation. At high scale, this may cost more.</li> </ul>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#approach-c-adaptive-card-debug-panel","title":"Approach C: Adaptive Card Debug Panel","text":"<p>Summary: Render diagnostic information in a structured, collapsible Adaptive Card that appears after the agent's response \u2014 only when debug mode is active. Technique: Global variable (<code>Global.DebugMode</code>) from Approach A + <code>SendActivity</code> with Adaptive Card attachment containing expandable sections.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#how-it-works_2","title":"How It Works","text":"<pre><code>User: \"xdebug on\"\n  \u2192 Debug mode enabled (same as Approach A)\n\nUser: \"What's the refund policy?\"\n  \u2192 Agent responds normally: \"Our refund policy is...\"\n  \u2192 Debug check: Global.DebugMode = true \u2192 emit Adaptive Card\n  \u2192 Card appears with collapsible sections:\n     [\ud83d\udccd Routing]  \u2192 Topic: RefundPolicy, Agent: SupportSpecialist\n     [\ud83d\udcca Variables] \u2192 Global.UserRegion: US, Topic.SearchHits: 3\n     [\ud83d\udd0d Knowledge] \u2192 Query: \"refund policy\", Sources: 2 SharePoint docs\n     [\u23f1 Timing]    \u2192 Total: 1.8s\n</code></pre> <p>The card renders as a single message with expandable sections using <code>Action.ShowCard</code>. When collapsed, it's a compact \"\ud83d\udd27 Debug Panel\" header. When expanded, it shows structured diagnostics in <code>FactSet</code> format.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#implementation_2","title":"Implementation","text":"<p>Step 1: Reuse the Toggle Debug topic from Approach A</p> <p>(Same <code>ToggleDebug</code> topic \u2014 see Approach A, Step 1)</p> <p>Step 2: Build the debug card in topic actions</p> <p>After the main response, add a conditional debug card. This example captures routing, variables, and timing:</p> <pre><code>    # === ADAPTIVE CARD DEBUG PANEL ===\n    - kind: ConditionGroup\n      id: debugPanel\n      conditions:\n        - id: isDebugOn\n          condition: =Global.DebugMode = true\n          actions:\n            # Capture timing\n            - kind: SetVariable\n              id: setDebugTimestamp\n              variable: init:Topic.DebugTimestamp\n              value: =Text(Now(), DateTimeFormat.UTC)\n\n            - kind: SendActivity\n              id: sendDebugCard\n              activity:\n                attachments:\n                  - contentType: application/vnd.microsoft.card.adaptive\n                    content:\n                      type: AdaptiveCard\n                      \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n                      version: \"1.5\"\n                      body:\n                        - type: TextBlock\n                          text: \"\ud83d\udd27 Debug Panel\"\n                          weight: bolder\n                          size: medium\n                          color: accent\n                        - type: TextBlock\n                          text: \"Conversation {System.Conversation.Id}\"\n                          size: small\n                          isSubtle: true\n                      actions:\n                        - type: Action.ShowCard\n                          title: \"\ud83d\udccd Routing\"\n                          card:\n                            type: AdaptiveCard\n                            body:\n                              - type: FactSet\n                                facts:\n                                  - title: \"Topic\"\n                                    value: \"RefundPolicy\"\n                                  - title: \"Trigger\"\n                                    value: \"OnRecognizedIntent\"\n                                  - title: \"Agent\"\n                                    value: \"SupportSpecialist\"\n                        - type: Action.ShowCard\n                          title: \"\ud83d\udcca Variables\"\n                          card:\n                            type: AdaptiveCard\n                            body:\n                              - type: FactSet\n                                facts:\n                                  - title: \"Global.DebugMode\"\n                                    value: \"{Global.DebugMode}\"\n                                  - title: \"Global.UserRegion\"\n                                    value: \"{Global.UserRegion}\"\n                                  - title: \"Topic.SearchHits\"\n                                    value: \"{Topic.SearchHits}\"\n                        - type: Action.ShowCard\n                          title: \"\ud83d\udd0d Knowledge\"\n                          card:\n                            type: AdaptiveCard\n                            body:\n                              - type: FactSet\n                                facts:\n                                  - title: \"User Query\"\n                                    value: \"{System.Activity.Text}\"\n                                  - title: \"Results Found\"\n                                    value: \"{If(IsBlank(Topic.SearchResult), \\\"None\\\", \\\"Yes\\\")}\"\n                        - type: Action.ShowCard\n                          title: \"\u23f1 Timing\"\n                          card:\n                            type: AdaptiveCard\n                            body:\n                              - type: FactSet\n                                facts:\n                                  - title: \"Timestamp (UTC)\"\n                                    value: \"{Topic.DebugTimestamp}\"\n</code></pre> <p>Step 3: Create a reusable debug card pattern</p> <p>Since the card structure repeats across topics, standardize it. Each topic only needs to customize the topic-specific facts (topic name, agent name, and topic variables):</p> <pre><code>    # Template: replace the values marked with [CUSTOMIZE] per topic\n    # Routing section:     [CUSTOMIZE] Topic name, trigger type, agent name\n    # Variables section:   [CUSTOMIZE] Topic-specific variables\n    # Knowledge section:   Keep as-is (uses System.Activity.Text)\n    # Timing section:      Keep as-is (auto-generated timestamp)\n</code></pre> <p>Step 4: Handle channels without Adaptive Card support</p> <p>Some channels render Adaptive Cards poorly or not at all. Add a fallback text representation:</p> <pre><code>    # After the Adaptive Card send, add a text fallback for limited channels\n    - kind: SendActivity\n      id: debugFallbackText\n      activity:\n        text:\n          - \"\ud83d\udd27 Debug | Topic: RefundPolicy | Agent: SupportSpecialist | Results: {If(IsBlank(Topic.SearchResult), \\\"None\\\", \\\"Yes\\\")} | {Topic.DebugTimestamp}\"\n</code></pre> <p>Note: In practice, M365 Copilot and Teams both support Adaptive Cards (schema 1.5), so the fallback is mainly for custom website channels with minimal card rendering.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Moderate \u2014 Adaptive Card JSON is verbose. Initial setup takes more effort than plain text. Maintainability \ud83d\udfe1 Same manual instrumentation as Approach A, but card JSON is harder to read/edit than plain text. Channel Compatibility \ud83d\udfe1 Works in Teams and Web Chat. M365 Copilot renders cards but <code>Action.ShowCard</code> collapsibility may vary. Test carefully. Scalability \ud83d\udfe1 Same topic-by-topic effort as Approach A. Card JSON is bulkier in YAML files. Diagnostic Coverage \ud83d\udfe1 Same as Approach A \u2014 you see what you instrument. But the structured layout makes it easier to scan. Low Overhead (debug off) \ud83d\udfe2 Same boolean check as Approach A. No card rendered when debug is off."},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#limitations_2","title":"Limitations","text":"<ul> <li>Adaptive Card rendering varies: <code>Action.ShowCard</code> (the collapsible sections) works well in Teams and Web Chat but may render differently in M365 Copilot. Always test the actual target channel.</li> <li>Schema version ceiling: Teams requires schema 1.5. Some advanced card features (e.g., <code>Action.Execute</code>) are not available.</li> <li>Verbose YAML: The card JSON embedded in YAML makes topic files significantly larger and harder to read.</li> <li>Static content: Unlike Approach A's simple text (which can use any Power Fx expression inline), Adaptive Cards have more limited data binding. Complex expressions may need intermediate <code>SetVariable</code> steps.</li> <li>No data export: The card is visual only. Unlike Approach B, there's no persistent record to query later.</li> </ul>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Keyword Inline Approach B: App Insights Approach C: Adaptive Card Implementation Effort \ud83d\udfe2 Low (30 min) \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe1 Medium (1-2 hours) Channel Support \ud83d\udfe2 All channels \ud83d\udfe2 All channels \ud83d\udfe1 Card-capable channels Real-time Feedback \ud83d\udfe2 Instant, in-chat \ud83d\udd34 Delayed (2-5 min) \ud83d\udfe2 Instant, in-chat Visual Quality \ud83d\udfe1 Plain text \ud83d\udfe2 Rich dashboards \ud83d\udfe2 Structured cards Persistent Record \ud83d\udd34 Ephemeral \ud83d\udfe2 Queryable, permanent \ud83d\udd34 Ephemeral Conversation Noise \ud83d\udd34 Adds text messages \ud83d\udfe2 Zero noise \ud83d\udfe1 Adds card messages Maintenance Burden \ud83d\udfe1 Per-topic blocks \ud83d\udfe1 Per-topic events \ud83d\udd34 Per-topic card JSON Production Monitoring \ud83d\udd34 Not suitable \ud83d\udfe2 Built for this \ud83d\udd34 Not suitable Cost \ud83d\udfe2 Free \ud83d\udfe1 App Insights costs \ud83d\udfe2 Free Best When... Quick debugging during development &amp; UAT Production monitoring &amp; post-incident investigation Stakeholder demos &amp; visual debugging sessions"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios: Combine Approaches A + B.</p> <p>Use Approach A (keyword inline) for interactive debugging during development, UAT, and channel-specific testing. It's fast to implement, works everywhere, and gives instant feedback. This is your \"developer console.\"</p> <p>Use Approach B (Application Insights) for production monitoring and post-incident investigation. It runs silently for all users, creates permanent records, and enables trend analysis across conversations. This is your \"production telemetry.\"</p> <p>Together, they cover both the interactive and asynchronous debugging needs:</p> <pre><code>Development &amp; UAT  \u2192  Approach A (keyword inline): instant, in-chat feedback\nProduction         \u2192  Approach B (App Insights): silent, persistent, queryable\nStakeholder demos  \u2192  Approach C (Adaptive Card): visually polished debugging\n</code></pre> <p>Choose Approach C instead of A when: You need visually structured diagnostics for stakeholder demos or when non-technical team members need to read debug output. The collapsible card sections are much easier to scan than plain text \u2014 but the implementation cost is higher.</p> <p>Skip Approach B when: You're building a prototype or internal tool where production monitoring isn't needed. The App Insights setup and KQL learning curve aren't justified for throwaway agents.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p><code>System.Conversation.InTestMode</code> is useless outside the Test Canvas. This built-in variable is <code>true</code> ONLY in the Copilot Studio authoring Test panel. In every deployed channel (M365 Copilot, Teams, Web Chat), it's always <code>false</code>. Do not rely on it for production debug logic \u2014 you must create your own <code>Global.DebugMode</code> flag.</p> <p>Warning</p> <p>M365 Copilot does NOT support the ConversationStart topic (see Gotchas Compendium). If you planned to initialize debug settings in <code>ConversationStart</code>, it won't fire in M365 Copilot. The <code>ToggleDebug</code> topic (triggered by user keyword) avoids this issue entirely since it's user-initiated. If you need automatic initialization, use agent instructions instead: \"Before answering, check if Global.DebugMode has been initialized.\"</p> <p>Warning</p> <p>Adaptive Card <code>Action.ShowCard</code> rendering varies by channel. In Teams, <code>Action.ShowCard</code> renders as a collapsible section. In M365 Copilot, the rendering may differ \u2014 some users report that show/hide toggles work inconsistently. Always test your debug card in the actual target channel before relying on the collapsible UX.</p> <p>Note</p> <p>Application Insights telemetry has a ~2-5 minute ingestion delay. Events sent via <code>LogCustomTelemetryEvent</code> are not instantly queryable. For real-time debugging, use Approach A. For post-incident analysis, the delay is irrelevant.</p> <p>Note</p> <p>Global variables persist within a conversation but reset between conversations. <code>Global.DebugMode</code> resets to <code>false</code> when a new conversation starts. Users must re-enable debug mode each session. This is actually a security benefit \u2014 debug mode doesn't accidentally leak into future conversations.</p>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Could be used to persist a user's debug preference across conversations (so admins don't have to type <code>xdebug on</code> every session)</li> <li>Gem 003: Tracing Agent Progress Before Response \u2014 Focuses on streaming/real-time progress indicators while the agent is still thinking, complementing the post-response diagnostics in this Gem</li> </ul>"},{"location":"gems/GEM-004-debug-mode-for-m365-copilot/#references","title":"References","text":"<ul> <li>Microsoft Learn: Application Insights for Copilot Studio</li> <li>Microsoft Learn: Test your agent</li> <li>Microsoft Learn: Adaptive Cards schema 1.5</li> <li>Microsoft Learn: System variables reference</li> <li>Microsoft Learn: LogCustomTelemetryEvent</li> <li>KQL Quick Reference</li> </ul> <p>Gem 004 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-005-multi-language-agent-response/","title":"Gem 005: Multi-Language Agent Response","text":"<p>Detect your user's language and respond in kind \u2014 without asking every time.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#classification","title":"Classification","text":"Attribute Value Category Personalization Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 detection logic + instruction adaptation) Channels All (detection method varies by channel) Prerequisite Gems Gem 001 (for persisting language preference across sessions)"},{"location":"gems/GEM-005-multi-language-agent-response/#the-problem","title":"The Problem","text":"<p>Enterprise organizations are global. A Copilot Studio agent deployed to 5,000 employees across France, the US, and Japan will receive queries in French, English, and Japanese \u2014 sometimes mixed within a single conversation.</p> <p>The default Copilot Studio experience handles this poorly:</p> <ul> <li>Agent instructions are monolingual: The system prompt is written in one language. If the instructions say \"respond professionally,\" the LLM defaults to the language of the instructions \u2014 usually English.</li> <li>No built-in language detection: There's no <code>System.User.Language</code> variable. The platform doesn't tell you what language the user typed in.</li> <li>Repeated friction: Asking \"What language do you prefer?\" every session is wasteful. For a French employee who always writes in French, this should be automatic.</li> <li>Knowledge source language mismatch: If your knowledge base is in English but the user asks in French, the generative answer may respond in English, French, or an awkward mix \u2014 depending on how the LLM processes the retrieved context.</li> <li>Mid-conversation switching: A user starts in English, then switches to French when asking about French-specific policies. The agent should follow seamlessly.</li> </ul> <p>The core challenge: determining the user's language reliably, applying it consistently, and persisting it across sessions \u2014 with minimal user friction and maximum accuracy.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that responds in the user's language naturally:</p> <ul> <li>[ ] Automatic detection: Language is identified without explicitly asking the user</li> <li>[ ] Accurate matching: Detection works correctly &gt;95% of the time for supported languages</li> <li>[ ] Persistent preference: Once detected (or chosen), the language preference carries across sessions</li> <li>[ ] Seamless switching: If the user changes language mid-conversation, the agent follows</li> <li>[ ] Knowledge source compatibility: Responses are in the user's language even when knowledge sources are in a different language</li> </ul>"},{"location":"gems/GEM-005-multi-language-agent-response/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-005-multi-language-agent-response/#approach-a-graph-api-profile-based-detection","title":"Approach A: Graph API Profile-Based Detection","text":"<p>Summary: Retrieve the user's <code>preferredLanguage</code> or <code>usageLocation</code> from their Entra ID profile via Microsoft Graph API. Set the language at conversation start. Technique: Power Automate flow calling Graph API, global variable for language, agent instructions for response language.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Conversation start\"] --&gt; B[\"Power Automate:&lt;br/&gt;GET /users/&amp;#123;id&amp;#125;?$select=&lt;br/&gt;preferredLanguage, usageLocation\"]\n    B --&gt; C[\"Map to language:&lt;br/&gt;preferredLanguage = fr-FR \u2192 French\"]\n    C --&gt; D[\"Set Global.ResponseLanguage = French\"]\n    D --&gt; E[\"Agent instructions:&lt;br/&gt;Respond in Global.ResponseLanguage\"]</code></pre> <p>The user's Entra ID profile contains <code>preferredLanguage</code> (e.g., <code>fr-FR</code>, <code>en-US</code>, <code>ja-JP</code>) \u2014 set by IT administrators. This is the most reliable signal because it's admin-managed and doesn't depend on what the user types.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#implementation","title":"Implementation","text":"<p>Step 1: Retrieve language from Graph API</p> <p>Extend the GetUserContext flow from Gem 001 (or create a standalone flow):</p> <pre><code>Action: HTTP to Microsoft Graph\n  Method: GET\n  URI: https://graph.microsoft.com/v1.0/users/{userId}?$select=preferredLanguage,usageLocation,mail\n\nAction: Map Language (Compose)\n  Expression: \n    if(startsWith(outputs('HTTP')?['body/preferredLanguage'], 'fr'), 'French',\n    if(startsWith(outputs('HTTP')?['body/preferredLanguage'], 'ja'), 'Japanese',\n    if(startsWith(outputs('HTTP')?['body/preferredLanguage'], 'de'), 'German',\n    if(startsWith(outputs('HTTP')?['body/preferredLanguage'], 'es'), 'Spanish',\n    'English'))))\n\nOutput: responseLanguage (string)\n</code></pre> <p>Step 2: Set global variable and instruct the agent</p> <p>Via agent instructions (M365 Copilot compatible):</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Multilingual Agent\ninstructions: |+\n  # Multilingual Agent\n\n  ## CRITICAL: Language Detection\n  At the START of every conversation, call \"GetUserContext\" to retrieve the user's \n  language preference. Store it as the conversation language.\n\n  ## Language Rules\n  - ALWAYS respond in the user's detected language\n  - If the detected language is \"French\": respond entirely in French\n  - If the detected language is \"Japanese\": respond entirely in Japanese\n  - Default: respond in English\n\n  ## Mid-Conversation Language Switch\n  If the user writes a message in a DIFFERENT language than detected, \n  switch to that language for the remainder of the conversation.\n\n  ## Knowledge Source Handling\n  When knowledge sources are in English but the user's language is French:\n  - Search in English (knowledge sources are English)\n  - Translate your response to French\n  - Cite source documents by their original English titles\n</code></pre> <p>Or via ConversationStart topic (non-M365 channels):</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnConversationStart\n  id: main\n  actions:\n    - kind: InvokeFlow\n      id: getUserLanguage\n      flowId: \"@environmentVariables('GetUserContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n      outputVariable: Topic.UserContext\n\n    - kind: SetVariable\n      id: setLanguage\n      variable: Global.ResponseLanguage\n      value: =If(IsBlank(Topic.UserContext.responseLanguage), \"English\", Topic.UserContext.responseLanguage)\n</code></pre> <p>Step 3: Persist language preference (link to Gem 001)</p> <p>Save the detected language using Gem 001's WriteContext pattern so the Graph API call only happens once per user \u2014 subsequent sessions load the cached preference.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires Power Automate flow + Graph API. Straightforward but multi-component. Maintainability \ud83d\udfe2 Language mapping is a simple lookup. Adding languages = adding mapping entries. Channel Compatibility \ud83d\udfe2 Graph API works regardless of channel. Detection Accuracy \ud83d\udfe1 Depends on IT setting <code>preferredLanguage</code> correctly. Many orgs leave this blank or set to defaults. Seamless Switching \ud83d\udfe1 Doesn't detect mid-conversation switches. Agent instructions handle this via \"if user writes in different language.\" Knowledge Compatibility \ud83d\udfe2 Agent instructions can mandate translation of English knowledge to user's language."},{"location":"gems/GEM-005-multi-language-agent-response/#limitations","title":"Limitations","text":"<ul> <li>Depends on IT data quality: <code>preferredLanguage</code> is often blank or set to the org default (<code>en-US</code>) for everyone. If your org hasn't populated Entra profiles, this approach returns English for all users.</li> <li>Fallback chain needed: <code>preferredLanguage</code> \u2192 <code>usageLocation</code> \u2192 default. Multiple Graph fields may need checking.</li> <li>One language at start: Detects once. If the user's profile says English but they write in French, the agent starts in English (though instructions can tell it to switch).</li> <li>Power Automate latency: Adds 1-2 seconds at conversation start for the Graph API call.</li> </ul>"},{"location":"gems/GEM-005-multi-language-agent-response/#approach-b-llm-auto-detection-from-user-input","title":"Approach B: LLM Auto-Detection from User Input","text":"<p>Summary: Let the LLM detect the language of the user's first message and respond in that language automatically. No external calls needed. Technique: Agent instructions that mandate language matching, with optional Prompt Tool for explicit classification.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"\ud83d\udc64 User: Quelle est la politique de cong\u00e9s ?\"] --&gt; B[\"LLM detects: input is French\"]\n    B --&gt; C[\"LLM responds in French&lt;br/&gt;(per instructions)\"]\n    C --&gt; D[\"All subsequent responses in French&lt;br/&gt;(until user switches)\"]</code></pre> <p>The simplest possible approach: the LLM naturally detects the input language and mirrors it \u2014 you just need to tell it to do so explicitly in the instructions.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#implementation_1","title":"Implementation","text":"<p>Step 1: Add language-matching instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Auto-Language Agent\ninstructions: |+\n  # Language-Adaptive Agent\n\n  ## Language Detection Rule\n  ALWAYS respond in the SAME LANGUAGE the user writes in.\n\n  - If the user writes in French \u2192 respond entirely in French\n  - If the user writes in English \u2192 respond entirely in English\n  - If the user writes in Japanese \u2192 respond entirely in Japanese\n  - If you're unsure \u2192 respond in English and ask:\n    \"I detected your message might be in [language]. Would you prefer I respond in [language]?\"\n\n  ## Language Consistency\n  - Once you detect the user's language, maintain it for the entire conversation\n  - If the user switches language mid-conversation, follow their switch\n  - NEVER mix languages in a single response (except for proper nouns or cited document titles)\n\n  ## Knowledge Source Translation\n  Our knowledge base is in English. When the user's language is not English:\n  - Search using the user's original query (the search engine handles multilingual queries)\n  - Translate the retrieved information into the user's language\n  - Keep document titles and reference IDs in their original language\n</code></pre> <p>That's it. No flows, no Graph API, no variables. The LLM handles everything.</p> <p>Step 2 (Optional): Explicit classification via Prompt Tool</p> <p>For more control (e.g., to store the detected language in a variable for routing):</p> <pre><code>kind: PromptTool\nid: prompt_detectLanguage\ndisplayName: \"Language Detector\"\ndescription: \"Detects the language of user input\"\ninstructions: |\n  Detect the language of the following text and return ONLY the language name.\n\n  Supported languages: English, French, German, Spanish, Japanese, Chinese, Korean, Portuguese, Italian, Dutch, Arabic\n\n  If the text is too short or ambiguous, return \"English\" as default.\n\n  Text: {userMessage}\n\n  Return ONLY the language name, nothing else.\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: userMessage\n    type: string\n    required: true\noutputs:\n  - name: language\n    type: string\n</code></pre> <p>Step 3 (Optional): Persist detected language (link to Gem 001)</p> <p>After detection, save the language via Gem 001's persistence so the agent defaults correctly in the next session:</p> <pre><code>    - kind: InvokePrompt\n      id: detectLang\n      promptId: prompt_detectLanguage\n      inputs:\n        userMessage: =System.Activity.Text\n      outputVariable: Topic.DetectedLanguage\n\n    - kind: SetVariable\n      id: setLang\n      variable: Global.ResponseLanguage\n      value: =Topic.DetectedLanguage\n\n    # Persist for next session\n    - kind: InvokeFlow\n      id: saveLangPref\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        preferredLanguage: =Global.ResponseLanguage\n</code></pre>"},{"location":"gems/GEM-005-multi-language-agent-response/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions only (no Prompt Tool needed). Zero infrastructure. 15 minutes. Maintainability \ud83d\udfe2 One instruction block. Adding languages = adding a line. Channel Compatibility \ud83d\udfe2 Works everywhere \u2014 LLM-based, no channel dependencies. Detection Accuracy \ud83d\udfe1 LLMs are excellent at language detection for sentences. Weak for 1-2 word inputs (\"Help\" could be English or French verb). Seamless Switching \ud83d\udfe2 Automatically follows user's language change. No explicit switch mechanism needed. Knowledge Compatibility \ud83d\udfe1 Translation quality depends on the LLM. Complex technical content may lose nuance in translation."},{"location":"gems/GEM-005-multi-language-agent-response/#limitations_1","title":"Limitations","text":"<ul> <li>Short input ambiguity: Single-word or very short messages can be misidentified. \"OK,\" \"Merci,\" \"Hello\" \u2014 some overlap between languages.</li> <li>First-message cold start: The first message determines the language. If the user's first message is an emoji or a single word, detection may be wrong.</li> <li>No proactive language: The agent can't greet the user in their language because it doesn't know the language until the user types something.</li> <li>Translation quality: Having the LLM translate knowledge source content is impressive but not flawless. Technical terminology, legal language, or policy-specific terms may be mistranslated.</li> <li>No explicit variable: Without the optional Prompt Tool step, the language is implicit in the LLM's behavior. You can't use it for routing decisions or conditional logic in topics.</li> </ul>"},{"location":"gems/GEM-005-multi-language-agent-response/#approach-c-explicit-user-language-selection","title":"Approach C: Explicit User Language Selection","text":"<p>Summary: Ask the user to choose their language at the start of the conversation (first time only). Persist the choice via Gem 001 and apply it to all future sessions. Technique: Question node with language options, global variable, persistent storage, agent instructions.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#how-it-works_2","title":"How It Works","text":"<pre><code>First conversation:\n  Agent: \"\ud83c\udf10 Please select your preferred language:\n          \ud83c\uddec\ud83c\udde7 English | \ud83c\uddeb\ud83c\uddf7 Fran\u00e7ais | \ud83c\udde9\ud83c\uddea Deutsch | \ud83c\uddef\ud83c\uddf5 \u65e5\u672c\u8a9e\"\n  User selects: Fran\u00e7ais\n  \u2192 Saved to persistent storage\n  \u2192 All responses in French\n\nSecond conversation (and all future):\n  \u2192 Language loaded from storage\n  \u2192 Agent responds in French immediately\n  \u2192 No question asked\n</code></pre> <p>Maximum accuracy (the user chose it), but adds friction to the first interaction. Subsequent sessions are frictionless because the preference is persisted.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#implementation_2","title":"Implementation","text":"<p>Step 1: Create a language selection topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Set Language Preference\n    triggerQueries:\n      - \"change language\"\n      - \"switch language\"\n      - \"changer de langue\"\n      - \"\u8a00\u8a9e\u3092\u5909\u66f4\"\n  actions:\n    - kind: Question\n      id: askLanguage\n      variable: init:Topic.SelectedLanguage\n      prompt: \"\ud83c\udf10 Please select your preferred language / Veuillez choisir votre langue :\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"English\"\n          synonyms: [\"EN\", \"english\", \"anglais\"]\n        - value: \"French\"\n          synonyms: [\"FR\", \"french\", \"fran\u00e7ais\", \"francais\"]\n        - value: \"German\"\n          synonyms: [\"DE\", \"german\", \"deutsch\", \"allemand\"]\n        - value: \"Japanese\"\n          synonyms: [\"JA\", \"japanese\", \"\u65e5\u672c\u8a9e\", \"japonais\"]\n        - value: \"Spanish\"\n          synonyms: [\"ES\", \"spanish\", \"espa\u00f1ol\", \"espagnol\"]\n\n    - kind: SetVariable\n      id: setLanguage\n      variable: Global.ResponseLanguage\n      value: =Topic.SelectedLanguage\n\n    # Persist for future sessions\n    - kind: InvokeFlow\n      id: saveLanguage\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        preferredLanguage: =Global.ResponseLanguage\n\n    - kind: SendActivity\n      id: confirmLanguage\n      activity:\n        text:\n          - \"\u2705 Language set to **{Global.ResponseLanguage}**. All future conversations will use this language.\\n\\nYou can change it anytime by saying \\\"change language\\\".\"\n</code></pre> <p>Step 2: Auto-prompt on first conversation only</p> <p>In agent instructions:</p> <pre><code>instructions: |+\n  ## Language Handling\n\n  At the START of every conversation, call \"GetUserContext\" to check if a \n  language preference exists.\n\n  - If `preferredLanguage` is set \u2192 use it immediately, DO NOT ask\n  - If `preferredLanguage` is empty (first-time user) \u2192 ask the user to choose \n    by calling the \"SetLanguagePreference\" topic\n\n  ## Response Language\n  ALWAYS respond in Global.ResponseLanguage.\n\n  ## Language Change\n  If the user says \"change language\" or equivalent in any language,\n  trigger the SetLanguagePreference topic to let them choose again.\n</code></pre> <p>Step 3: Combine with ConversationStart for non-M365 channels</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnConversationStart\n  id: main\n  actions:\n    - kind: InvokeFlow\n      id: loadContext\n      flowId: \"@environmentVariables('ReadContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n      outputVariable: Topic.UserContext\n\n    - kind: SetVariable\n      id: setLang\n      variable: Global.ResponseLanguage\n      value: =Topic.UserContext.preferredLanguage\n\n    - kind: ConditionGroup\n      id: checkLanguageSet\n      conditions:\n        - id: hasLanguage\n          condition: =!IsBlank(Global.ResponseLanguage)\n          actions:\n            - kind: SendActivity\n              id: greetInLanguage\n              activity:\n                text:\n                  - =If(Global.ResponseLanguage = \"French\", \"Bonjour ! Comment puis-je vous aider ?\", If(Global.ResponseLanguage = \"Japanese\", \"\u3053\u3093\u306b\u3061\u306f\uff01\u4f55\u304b\u304a\u624b\u4f1d\u3044\u3067\u304d\u307e\u3059\u304b\uff1f\", \"Hello! How can I help you?\"))\n      elseActions:\n        # First-time user \u2014 ask for language\n        - kind: GotoTopic\n          id: gotoLanguageSelect\n          topicId: SetLanguagePreference\n</code></pre>"},{"location":"gems/GEM-005-multi-language-agent-response/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Question node + persistence flow. Simple and clear. Maintainability \ud83d\udfe2 Choice list is easy to update. Adding a language = adding a choice option. Channel Compatibility \ud83d\udfe2 Multiple choice questions work in all channels. Detection Accuracy \ud83d\udfe2 100% accurate \u2014 the user chose it explicitly. Seamless Switching \ud83d\udfe2 \"Change language\" topic allows switching anytime. Knowledge Compatibility \ud83d\udfe2 Known language enables explicit translation instructions."},{"location":"gems/GEM-005-multi-language-agent-response/#limitations_2","title":"Limitations","text":"<ul> <li>First-session friction: New users must answer a language question before anything else. For an agent that serves 90% English-speaking users, this is unnecessary for most people.</li> <li>Choice list maintenance: Adding less-common languages expands the choice list, potentially overwhelming users. Consider showing only languages relevant to your org.</li> <li>No detection of unexpected languages: If a user writes in Korean but Korean isn't in your choice list, the agent responds in whatever the user previously selected.</li> <li>ConversationStart limitation: The language selection prompt doesn't fire in M365 Copilot unless handled via agent instructions.</li> </ul>"},{"location":"gems/GEM-005-multi-language-agent-response/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Graph API Approach B: LLM Auto-Detect Approach C: Explicit Choice Implementation Effort \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe2 Low (15 min) \ud83d\udfe2 Low (1 hour) Detection Accuracy \ud83d\udfe1 Depends on IT data \ud83d\udfe1 Good for sentences, weak for short input \ud83d\udfe2 100% (user chose it) First-Session Friction \ud83d\udfe2 Zero (automatic) \ud83d\udfe2 Zero (automatic) \ud83d\udd34 Language question before first use Mid-Conversation Switch \ud83d\udfe1 Via instructions only \ud83d\udfe2 Automatic \ud83d\udfe2 \"Change language\" command Proactive Greeting \ud83d\udfe2 Greet in detected language \ud83d\udd34 Can't greet (don't know language yet) \ud83d\udfe2 Greet in saved language Infrastructure \ud83d\udfe1 Power Automate + Graph API \ud83d\udfe2 None \ud83d\udfe1 Persistence flow (Gem 001) Best When... IT maintains Entra profiles well Quick deployment, LLM handles it Maximum accuracy, users accept one-time setup"},{"location":"gems/GEM-005-multi-language-agent-response/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios: Combine Approaches B + C with Gem 001 persistence.</p> <ol> <li>First session: Use Approach B (LLM auto-detect) \u2014 the agent silently detects the user's language from their first message and responds accordingly. After detection, persist the language using Gem 001.</li> <li>Subsequent sessions: Load the persisted preference. The agent greets and responds in the saved language immediately.</li> <li>Override: Provide Approach C's \"change language\" topic for users who want to explicitly switch.</li> </ol> <p>This gives you: zero friction (no question asked), reasonable accuracy (LLM detection), persistence (no re-detection), and an escape hatch (explicit switch).</p> <p>Add Approach A when: Your IT organization maintains Entra profiles well (<code>preferredLanguage</code> is populated). Use it as the primary signal with LLM detection as fallback for users without profile data.</p> <p>Use Approach C alone when: You support fewer than 3 languages and/or regulatory requirements demand the user explicitly confirms their language choice.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>ConversationStart doesn't fire in M365 Copilot (see Gotchas Compendium). If you load language in <code>ConversationStart</code>, it only works in Web Chat and Teams. For M365 Copilot, use agent instructions: \"Before responding, load the user's language preference.\"</p> <p>Warning</p> <p>LLM translation quality varies by language pair. English \u2192 French/Spanish/German: excellent. English \u2192 Japanese/Korean/Arabic: good but may miss nuance in technical or legal terminology. For high-stakes content (HR policies, legal notices), consider human-translated knowledge sources in each language rather than LLM translation.</p> <p>Note</p> <p>Generative answers search works cross-lingually. Copilot Studio's <code>SearchAndSummarizeContent</code> can find English documents when the user asks in French. The semantic search layer handles this. The challenge is the response language \u2014 use <code>customInstructions</code> to mandate: \"Always respond in the user's language.\"</p> <p>Note</p> <p><code>System.User.Language</code> does not exist. There is no built-in system variable for user language in Copilot Studio. You must detect or store it yourself.</p>"},{"location":"gems/GEM-005-multi-language-agent-response/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Provides the persistence layer for language preference</li> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Language is a facet of persona. Combine language adaptation with persona-specific tone and vocabulary.</li> </ul>"},{"location":"gems/GEM-005-multi-language-agent-response/#references","title":"References","text":"<ul> <li>Microsoft Graph API: User resource (preferredLanguage)</li> <li>Microsoft Learn: Generative answers custom instructions</li> <li>IETF Language Tags (BCP 47)</li> </ul> <p>Gem 005 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/","title":"Gem 006: Adaptive Cards as Multi-Field Forms","text":"<p>Collect multiple inputs in a single interaction \u2014 not a five-message interrogation.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#classification","title":"Classification","text":"Attribute Value Category UX Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 card design + response parsing) Channels Web Chat, Teams (schema 1.5), M365 Copilot (with caveats) Prerequisite Gems None"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#the-problem","title":"The Problem","text":"<p>Collecting structured data from users is one of the most common agent tasks: create a support ticket (name, email, category, description, priority), submit a request (type, details, urgency), or register for an event (name, date choice, dietary requirements).</p> <p>The default Copilot Studio approach is sequential Question nodes \u2014 one question per field, one message per answer. For a 5-field form, that's 10 messages (5 questions + 5 answers) before any processing happens.</p> <p>This creates problems:</p> <ul> <li>Conversation fatigue: Users feel like they're being interrogated. \"What's your name?\" \"What's your email?\" \"What category?\" \"Can you describe the issue?\" \"What's the priority?\" \u2014 five back-and-forths for what should be a single form.</li> <li>Context switching: Each question breaks the user's flow. By question 4, they've forgotten the overall purpose.</li> <li>No editing: If the user makes a typo in field 2, they can't go back and fix it without restarting the entire sequence.</li> <li>Mobile UX: On mobile, each question+answer pair takes significant scroll space. A 10-message sequence fills multiple screens.</li> <li>Validation complexity: Validating inputs across fields (e.g., \"if category is Urgent, description is required\") requires complex conditional branching between question nodes.</li> </ul> <p>Adaptive Cards offer a form-like experience \u2014 multiple input fields rendered as a single card, submitted with one button click.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A smooth data collection experience that respects the user's time:</p> <ul> <li>[ ] Single-interaction collection: 3-6 fields collected in one user action (not sequential messages)</li> <li>[ ] Input validation: Required fields, format validation, sensible defaults</li> <li>[ ] Review before submit: User can see all their inputs and edit before committing</li> <li>[ ] Channel-safe: Works in Teams (schema 1.5) and Web Chat at minimum</li> <li>[ ] Parseable output: Each field is extractable as a separate variable for processing</li> </ul>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#approach-a-sequential-question-nodes-baseline","title":"Approach A: Sequential Question Nodes (Baseline)","text":"<p>Summary: The standard approach \u2014 one Question node per field, sequential execution. Technique: Multiple <code>Question</code> nodes with entity validation, followed by a confirmation message.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#how-it-works","title":"How It Works","text":"<pre><code>Agent: \"What's your name?\"\nUser: \"John Smith\"\nAgent: \"What's your email?\"\nUser: \"john@contoso.com\"\nAgent: \"What category? (Billing / Technical / Account)\"\nUser: \"Technical\"\nAgent: \"Describe the issue:\"\nUser: \"Can't login to the portal\"\nAgent: \"Priority? (Low / Medium / High)\"\nUser: \"High\"\nAgent: \"Got it! Creating ticket:\n        Name: John Smith\n        Email: john@contoso.com\n        Category: Technical\n        Issue: Can't login to the portal\n        Priority: High\n\n        Shall I submit this?\"\n</code></pre> <p>10 messages minimum. But it works in every channel, requires no card design, and each field is validated individually.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#implementation","title":"Implementation","text":"<pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Create Support Ticket\n    triggerQueries:\n      - \"create ticket\"\n      - \"submit a ticket\"\n      - \"I need help\"\n  actions:\n    - kind: Question\n      id: askName\n      variable: init:Topic.UserName\n      prompt: \"What's your full name?\"\n      entity: PersonNamePrebuiltEntity\n\n    - kind: Question\n      id: askEmail\n      variable: init:Topic.UserEmail\n      prompt: \"What's your email address?\"\n      entity: EmailPrebuiltEntity\n\n    - kind: Question\n      id: askCategory\n      variable: init:Topic.Category\n      prompt: \"What category does this fall under?\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"Billing\"\n        - value: \"Technical\"\n        - value: \"Account\"\n\n    - kind: Question\n      id: askDescription\n      variable: init:Topic.Description\n      prompt: \"Please describe the issue:\"\n      entity: StringPrebuiltEntity\n\n    - kind: Question\n      id: askPriority\n      variable: init:Topic.Priority\n      prompt: \"What priority level?\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"Low\"\n        - value: \"High\"\n        - value: \"Critical\"\n\n    # Confirmation\n    - kind: SendActivity\n      id: confirmDetails\n      activity:\n        text:\n          - \"Here's your ticket summary:\\n\\n- **Name**: {Topic.UserName}\\n- **Email**: {Topic.UserEmail}\\n- **Category**: {Topic.Category}\\n- **Issue**: {Topic.Description}\\n- **Priority**: {Topic.Priority}\\n\\nShall I submit this?\"\n\n    - kind: Question\n      id: confirmSubmit\n      variable: init:Topic.Confirmed\n      prompt: \"Submit this ticket?\"\n      entity: BooleanPrebuiltEntity\n</code></pre>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Drag-and-drop in UI or simple YAML. No card design needed. Maintainability \ud83d\udfe2 Each field is a separate node. Easy to add, remove, or reorder. Channel Compatibility \ud83d\udfe2 Works in ALL channels. Universal. User Experience \ud83d\udd34 10+ messages. Feels like an interrogation. No editing without restart. Input Validation \ud83d\udfe2 Per-field entity validation. Email, phone, choice \u2014 each validated on input. Parseable Output \ud83d\udfe2 Each field is already a separate variable."},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#limitations","title":"Limitations","text":"<ul> <li>Conversation fatigue: 5 fields = 10 messages minimum. Users dislike this.</li> <li>No go-back: If the user makes a mistake in field 2, they can't go back. They'd need to restart or say \"actually, change my email to...\"</li> <li>No at-a-glance view: The user can't see all fields at once before filling them in.</li> <li>Mobile scroll: On mobile devices, the message chain takes up significant vertical space.</li> </ul>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#approach-b-single-adaptive-card-form","title":"Approach B: Single Adaptive Card Form","text":"<p>Summary: Render all input fields in one Adaptive Card. User fills in all fields and submits with a single button click. Technique: <code>SendActivity</code> with Adaptive Card attachment containing <code>Input.*</code> elements, <code>Action.Submit</code>, output parsed from card response.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Agent sends &lt;b&gt;Adaptive Card&lt;/b&gt;\"] --&gt; B\n    B[\"\ud83c\udfab &lt;b&gt;Create Support Ticket&lt;/b&gt;&lt;br/&gt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&lt;br/&gt;Name: text input&lt;br/&gt;Email: text input&lt;br/&gt;Category: dropdown&lt;br/&gt;Issue: multiline text&lt;br/&gt;Priority: Low / High / Critical&lt;br/&gt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&lt;br/&gt;Submit Ticket\"] --&gt; C\n    C[\"\ud83d\udc64 User fills all fields \u2192 clicks Submit\"] --&gt; D\n    D[\"\u2705 Ticket #4521 created!&lt;br/&gt;Confirmation sent to john@contoso.com\"]</code></pre> <p>2 messages total (card + confirmation) instead of 10+.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#implementation_1","title":"Implementation","text":"<p>Step 1: Design the Adaptive Card form</p> <pre><code>    - kind: SendActivity\n      id: sendTicketForm\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"\ud83c\udfab Create Support Ticket\"\n                  weight: bolder\n                  size: large\n                - type: TextBlock\n                  text: \"Fill in the details below and click Submit.\"\n                  isSubtle: true\n                  wrap: true\n                  spacing: none\n\n                # Name field\n                - type: Input.Text\n                  id: userName\n                  label: \"Full Name\"\n                  placeholder: \"e.g., John Smith\"\n                  isRequired: true\n                  errorMessage: \"Name is required\"\n\n                # Email field\n                - type: Input.Text\n                  id: userEmail\n                  label: \"Email Address\"\n                  placeholder: \"e.g., john@contoso.com\"\n                  isRequired: true\n                  errorMessage: \"Email is required\"\n                  style: email\n\n                # Category dropdown\n                - type: Input.ChoiceSet\n                  id: category\n                  label: \"Category\"\n                  isRequired: true\n                  errorMessage: \"Please select a category\"\n                  choices:\n                    - title: \"Billing\"\n                      value: \"billing\"\n                    - title: \"Technical\"\n                      value: \"technical\"\n                    - title: \"Account\"\n                      value: \"account\"\n                  placeholder: \"Select category...\"\n\n                # Description (multiline)\n                - type: Input.Text\n                  id: description\n                  label: \"Describe the Issue\"\n                  placeholder: \"What's going on?\"\n                  isRequired: true\n                  errorMessage: \"Description is required\"\n                  isMultiline: true\n                  maxLength: 1000\n\n                # Priority (radio-style)\n                - type: Input.ChoiceSet\n                  id: priority\n                  label: \"Priority\"\n                  style: expanded\n                  value: \"low\"\n                  choices:\n                    - title: \"Low\"\n                      value: \"low\"\n                    - title: \"High\"\n                      value: \"high\"\n                    - title: \"Critical\"\n                      value: \"critical\"\n\n              actions:\n                - type: Action.Submit\n                  title: \"Submit Ticket\"\n                  style: positive\n                  data:\n                    action: submitTicket\n</code></pre> <p>Step 2: Capture and parse the card response</p> <p>The card response arrives as a JSON object with all field values. Use <code>AdaptiveCardPrompt</code> to capture it, or handle the submit action:</p> <pre><code>    - kind: AdaptiveCardPrompt\n      id: ticketFormPrompt\n      card:\n        # ... entire card definition from above ...\n      outputVariable: Topic.FormResponse\n\n    # Parse individual fields\n    - kind: SetVariable\n      id: parseName\n      variable: init:Topic.UserName\n      value: =Topic.FormResponse.userName\n\n    - kind: SetVariable\n      id: parseEmail\n      variable: init:Topic.UserEmail\n      value: =Topic.FormResponse.userEmail\n\n    - kind: SetVariable\n      id: parseCategory\n      variable: init:Topic.Category\n      value: =Topic.FormResponse.category\n\n    - kind: SetVariable\n      id: parseDescription\n      variable: init:Topic.Description\n      value: =Topic.FormResponse.description\n\n    - kind: SetVariable\n      id: parsePriority\n      variable: init:Topic.Priority\n      value: =Topic.FormResponse.priority\n</code></pre> <p>Step 3: Process the parsed data</p> <pre><code>    # Confirmation + action\n    - kind: SendActivity\n      id: sendConfirmation\n      activity:\n        text:\n          - \"\u2705 **Ticket Created!**\\n\\n| Field | Value |\\n|---|---|\\n| Name | {Topic.UserName} |\\n| Email | {Topic.UserEmail} |\\n| Category | {Topic.Category} |\\n| Issue | {Topic.Description} |\\n| Priority | {Topic.Priority} |\\n\\nYou'll receive a confirmation email shortly.\"\n\n    # Call flow to create the actual ticket\n    - kind: InvokeFlow\n      id: createTicket\n      flowId: \"@environmentVariables('CreateTicketFlowId')\"\n      inputs:\n        name: =Topic.UserName\n        email: =Topic.UserEmail\n        category: =Topic.Category\n        description: =Topic.Description\n        priority: =Topic.Priority\n      outputVariable: Topic.TicketResult\n</code></pre>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Card JSON is verbose. Requires understanding of Adaptive Card schema. Maintainability \ud83d\udfe1 Card JSON embedded in YAML is hard to read. Use the Adaptive Cards Designer for visual editing, then paste. Channel Compatibility \ud83d\udfe1 Works in Teams (1.5) and Web Chat. M365 Copilot renders cards but submit behavior may vary. User Experience \ud83d\udfe2 2 messages total. User sees all fields at once, fills at their pace, submits once. Input Validation \ud83d\udfe1 <code>isRequired</code> + <code>errorMessage</code> handles required fields. Format validation (email regex) is limited to what the card schema supports. Parseable Output \ud83d\udfe2 Card response is structured JSON. Each <code>id</code> maps to a value."},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#limitations_1","title":"Limitations","text":"<ul> <li>No server-side validation: Adaptive Cards validate on the client side only (<code>isRequired</code>, <code>maxLength</code>). You can't enforce \"email must be from @contoso.com\" in the card itself \u2014 that requires post-submit validation in the topic.</li> <li>Schema 1.5 ceiling: Teams limits you to schema 1.5. Some advanced input types (like <code>Input.Time</code> in expanded mode) may not render correctly.</li> <li>No conditional fields: You can't show/hide fields based on other selections within the card (e.g., \"show Description only if Category is Technical\"). All fields are always visible.</li> <li>Card size: Very large forms (10+ fields) make the card scroll, degrading mobile UX. Keep forms to 6-8 fields maximum.</li> <li>M365 Copilot submit behavior: Card submissions in M365 Copilot may behave differently than in Teams. Always test in your target channel.</li> <li>Visual design limitations: Adaptive Cards offer limited styling. Colors, fonts, and spacing are constrained by the schema. Don't expect pixel-perfect form design.</li> </ul>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#approach-c-hybrid-card-preview-sequential-validation","title":"Approach C: Hybrid \u2014 Card Preview + Sequential Validation","text":"<p>Summary: Send an Adaptive Card for the initial form, then follow up with sequential Question nodes for any fields that need correction or complex validation. Technique: Adaptive Card for initial collection, conditional validation topic, Question nodes for corrections.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#how-it-works_2","title":"How It Works","text":"<pre><code>Agent sends Adaptive Card form (same as Approach B)\nUser fills in and submits\n\nAgent validates:\n  \u2705 Name: OK\n  \u2705 Email: OK\n  \u274c Description: Too short (minimum 20 characters)\n  \u2705 Priority: OK\n\nAgent: \"Almost there! Your description needs a bit more detail (minimum 20 characters). \n        Current: 'Can't login'\n        Please provide more details:\"\nUser: \"I can't login to the support portal. I get a 403 error after entering my credentials.\"\n\nAgent: \"\u2705 Updated! Here's the final ticket:\n        [summary]\n        Shall I submit?\"\n</code></pre> <p>Best of both worlds: the card handles the bulk of data collection (1 interaction for 5 fields), and sequential questions handle only the fields that need correction (0-2 extra messages in most cases).</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#implementation_2","title":"Implementation","text":"<p>Step 1: Send the Adaptive Card form (same as Approach B)</p> <p>Use the same card definition from Approach B, Step 1.</p> <p>Step 2: Post-submit validation</p> <pre><code>    # Parse card response (same as Approach B)\n    - kind: SetVariable\n      id: parseName\n      variable: init:Topic.UserName\n      value: =Topic.FormResponse.userName\n    # ... parse other fields ...\n\n    # Validate: description length\n    - kind: ConditionGroup\n      id: validateDescription\n      conditions:\n        - id: tooShort\n          condition: =Len(Topic.Description) &lt; 20\n          actions:\n            - kind: Question\n              id: askBetterDescription\n              variable: Topic.Description\n              prompt: \"Your description needs a bit more detail (minimum 20 characters).\\n\\nCurrent: \\\"{Topic.Description}\\\"\\n\\nPlease provide more details:\"\n              entity: StringPrebuiltEntity\n\n    # Validate: email domain (optional business rule)\n    - kind: ConditionGroup\n      id: validateEmail\n      conditions:\n        - id: wrongDomain\n          condition: =!Contains(Topic.UserEmail, \"@contoso.com\")\n          actions:\n            - kind: Question\n              id: askCorrectEmail\n              variable: Topic.UserEmail\n              prompt: \"Please provide your **@contoso.com** email address:\"\n              entity: EmailPrebuiltEntity\n\n    # Confirmation with final values\n    - kind: SendActivity\n      id: finalConfirmation\n      activity:\n        text:\n          - \"\u2705 **Ticket Ready to Submit**\\n\\n| Field | Value |\\n|---|---|\\n| Name | {Topic.UserName} |\\n| Email | {Topic.UserEmail} |\\n| Category | {Topic.Category} |\\n| Issue | {Topic.Description} |\\n| Priority | {Topic.Priority} |\"\n\n    - kind: Question\n      id: confirmSubmit\n      variable: init:Topic.Confirmed\n      prompt: \"Submit this ticket?\"\n      entity: BooleanPrebuiltEntity\n</code></pre> <p>Step 3: Handle the \"edit\" flow</p> <p>Add a branch for users who want to change a specific field after seeing the summary:</p> <pre><code>    - kind: ConditionGroup\n      id: checkConfirm\n      conditions:\n        - id: confirmed\n          condition: =Topic.Confirmed = true\n          actions:\n            # Submit ticket (invoke flow)\n            - kind: InvokeFlow\n              id: submitTicket\n              flowId: \"@environmentVariables('CreateTicketFlowId')\"\n              inputs:\n                name: =Topic.UserName\n                email: =Topic.UserEmail\n                category: =Topic.Category\n                description: =Topic.Description\n                priority: =Topic.Priority\n              outputVariable: Topic.TicketResult\n            - kind: SendActivity\n              id: ticketCreated\n              activity:\n                text:\n                  - \"\ud83c\udfab Ticket **#{Topic.TicketResult.ticketNumber}** created!\"\n      elseActions:\n        - kind: SendActivity\n          id: askWhichField\n          activity:\n            text:\n              - \"What would you like to change? (Name / Email / Category / Issue / Priority)\"\n        # Re-collect the specific field...\n</code></pre>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Card + validation logic. More code than either A or B alone. Maintainability \ud83d\udfe1 Two patterns to maintain (card + validation). But validation topics are reusable. Channel Compatibility \ud83d\udfe1 Same card limitations as Approach B. Validation questions work everywhere. User Experience \ud83d\udfe2 Best UX: fast initial collection + only targeted corrections. 2-4 messages typical. Input Validation \ud83d\udfe2 Client-side (card) + server-side (topic logic). Most thorough validation. Parseable Output \ud83d\udfe2 Same as Approach B \u2014 structured JSON from card."},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#limitations_2","title":"Limitations","text":"<ul> <li>Most complex to implement: You're building both a card AND validation logic. More code to write and test.</li> <li>Validation flow can feel inconsistent: \"You filled a nice form, but now I'm asking you questions\" \u2014 the UX shifts from form-style to chat-style mid-interaction.</li> <li>Same card limitations as Approach B: Schema 1.5, no conditional fields, no server-side validation in the card itself.</li> </ul>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Sequential Questions Approach B: Adaptive Card Approach C: Hybrid Messages for 5 fields \ud83d\udd34 10+ messages \ud83d\udfe2 2 messages \ud83d\udfe2 2-4 messages Implementation Effort \ud83d\udfe2 Low (30 min) \ud83d\udfe1 Medium (1-2 hours) \ud83d\udfe1 Medium (2-3 hours) Channel Support \ud83d\udfe2 All channels \ud83d\udfe1 Card-capable only \ud83d\udfe1 Card-capable only Input Validation \ud83d\udfe2 Per-field entity \ud83d\udfe1 Client-side only \ud83d\udfe2 Client + server-side Edit Before Submit \ud83d\udd34 Restart required \ud83d\udfe2 Edit any field in card \ud83d\udfe2 Card + targeted corrections Mobile UX \ud83d\udd34 Long scroll \ud83d\udfe2 Compact card \ud83d\udfe2 Compact with corrections Conditional Fields \ud83d\udfe2 Easy with ConditionGroup \ud83d\udd34 Not possible \ud83d\udfe1 Via post-submit questions Best When... Non-card channels, 1-2 fields, conditional logic heavy 3-6 fields, card-capable channels, clean UX Complex validation, best-of-both-worlds UX"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#recommended-approach","title":"Recommended Approach","text":"<p>For 3-6 fields in card-capable channels: Approach B (Adaptive Card) \u2014 the UX improvement is dramatic. 2 messages vs 10+ is a completely different user experience. Design the card once, reuse it.</p> <p>Add Approach C's validation when: You have business rules that can't be expressed in the card schema (email domain check, field length minimum, cross-field validation). The hybrid approach gives you card speed + server validation.</p> <p>Fall back to Approach A when: You target channels without Adaptive Card support, OR you need heavily conditional forms (show field X only if the user selected option Y in field Z). Sequential questions handle conditional logic naturally.</p> <p>Practical guidance by field count:</p> <pre><code>1-2 fields     \u2192  Approach A (sequential questions \u2014 lean and simple)\n3-6 fields     \u2192  Approach B (Adaptive Card \u2014 best UX)\n3-6 + rules    \u2192  Approach C (card + validation)\n7+ fields      \u2192  Split into 2 cards or multi-page flow\n</code></pre>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Teams limits Adaptive Cards to schema version 1.5. Features like <code>Action.Execute</code> (universal actions) are not available. Stick to <code>Action.Submit</code> for form submission. Use the Adaptive Cards Designer with the \"Teams\" host config for testing.</p> <p>Warning</p> <p>Adaptive Card <code>isRequired</code> validation is client-side only. A determined user or a buggy client could submit a card with empty required fields. Always validate required fields in your topic logic after parsing the response \u2014 don't trust the card alone.</p> <p>Warning</p> <p>M365 Copilot card submit behavior may differ from Teams. In Teams, <code>Action.Submit</code> returns a structured JSON payload. In M365 Copilot, the submit behavior and data format may vary. Always test card forms in your actual target channel before going to production.</p> <p>Note</p> <p>Adaptive Cards have no conditional field visibility. You cannot show/hide fields based on other selections within the card. If you need \"show Description only when Category is Technical,\" use Approach A or C (post-card questions).</p> <p>Note</p> <p>Use the Adaptive Cards Designer for visual editing. Don't hand-write card JSON. Design visually at adaptivecards.io/designer, then paste the JSON into your YAML. Set the host config to \"Microsoft Teams\" for 1.5 compatibility.</p>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 003: Tracing Agent Progress Before Response \u2014 Adaptive Cards used for progress indicators share the same rendering constraints documented here</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Approach C uses Adaptive Cards for debug panels, subject to the same channel limitations</li> </ul>"},{"location":"gems/GEM-006-adaptive-cards-as-multi-field-forms/#references","title":"References","text":"<ul> <li>Microsoft Learn: Adaptive Cards in Copilot Studio</li> <li>Adaptive Cards Schema Explorer</li> <li>Adaptive Cards Designer</li> <li>Microsoft Learn: Input validation in Adaptive Cards</li> <li>Teams Adaptive Card schema support</li> </ul> <p>Gem 006 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-007-role-based-feature-gating/","title":"Gem 007: Role-Based Feature Gating","text":"<p>Show admin features to admins, hide them from everyone else \u2014 without deploying separate agents.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#classification","title":"Classification","text":"Attribute Value Category Security Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 role detection + conditional logic across topics) Channels All (role detection method varies) Prerequisite Gems Gem 001 (for caching role across sessions), Gem 004 (debug mode is an example of gated feature)"},{"location":"gems/GEM-007-role-based-feature-gating/#the-problem","title":"The Problem","text":"<p>A single Copilot Studio agent often needs to serve multiple audiences with different capability levels. Some features should be visible only to specific roles:</p> <ul> <li>Debug mode (Gem 004): Only admins or developers should be able to enable diagnostic output.</li> <li>Data modification: Regular users can view data; managers can approve requests; admins can delete records.</li> <li>Sensitive information: HR staff can see salary data; regular employees cannot.</li> <li>Advanced actions: Power users can trigger deployments or reindex operations; regular users can only query.</li> <li>Configuration: Agent settings (changing knowledge sources, updating prompts) should be admin-only.</li> </ul> <p>Without role gating, you have two bad options:</p> <ol> <li>Show everything to everyone: Security risk. Users see features they shouldn't access.</li> <li>Deploy separate agents per role: Maintenance nightmare. Every change must be replicated.</li> </ol> <p>The ideal is a single agent where features are conditionally available based on the user's role \u2014 detected automatically, cached for performance, and enforced consistently.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A role-based access control system within a single agent:</p> <ul> <li>[ ] Automatic role detection: User's role is identified at conversation start without asking</li> <li>[ ] Feature gating: Specific topics, actions, or information are only available to authorized roles</li> <li>[ ] Invisible to unauthorized users: Gated features aren't just disabled \u2014 they're invisible. Users don't know they exist.</li> <li>[ ] Fail-closed: If role detection fails, default to the most restrictive role (not the most permissive)</li> <li>[ ] Cacheable: Role detection doesn't need to happen on every message \u2014 once per session is sufficient</li> </ul>"},{"location":"gems/GEM-007-role-based-feature-gating/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-007-role-based-feature-gating/#approach-a-entra-id-group-membership-via-power-automate","title":"Approach A: Entra ID Group Membership via Power Automate","text":"<p>Summary: Check the user's Entra ID security group membership via Graph API. Map groups to roles. Cache the role in a global variable. Technique: Power Automate flow calling Microsoft Graph <code>/memberOf</code> endpoint, global variable for role, conditional logic in topics.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Conversation start\"] --&gt; B[\"Power Automate:&lt;br/&gt;GET /users/&amp;#123;id&amp;#125;/memberOf\"]\n    B --&gt; C{\"Check groups\"}\n    C --&gt;|Agent-Admins member| D[\"Role = Admin\"]\n    C --&gt;|Agent-PowerUsers member| E[\"Role = PowerUser\"]\n    C --&gt;|Neither| F[\"Role = User\"]\n    D --&gt; G[\"Set Global.UserRole = detected role\"]\n    E --&gt; G\n    F --&gt; G\n    G --&gt; H[\"Topics check Global.UserRole&lt;br/&gt;before exposing features\"]</code></pre> <p>Entra ID security groups are the most reliable role signal because they're admin-managed, auditable, and centrally controlled.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#implementation","title":"Implementation","text":"<p>Step 1: Create Entra ID security groups</p> <p>In Entra ID admin center, create security groups:</p> Group Name Purpose Members <code>CopilotAgent-Admins</code> Full access: debug, config, data modification IT admins, developers <code>CopilotAgent-PowerUsers</code> Extended access: advanced queries, reports Team leads, power users (no group needed) Basic access: standard features only Everyone else <p>Step 2: Create the role detection Power Automate flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Input: userId (Text)\n\nAction: HTTP to Microsoft Graph\n  Method: GET\n  URI: https://graph.microsoft.com/v1.0/users/{userId}/memberOf?$select=displayName,id\n\nAction: Filter Groups (Select)\n  From: outputs('HTTP')?['body/value']\n  Condition: item()?['@odata.type'] eq '#microsoft.graph.group'\n\nAction: Check Admin Group (Compose)\n  Expression: contains(\n    join(body('Filter_Groups')?['displayName'], ','),\n    'CopilotAgent-Admins'\n  )\n\nAction: Check PowerUser Group (Compose)\n  Expression: contains(\n    join(body('Filter_Groups')?['displayName'], ','),\n    'CopilotAgent-PowerUsers'\n  )\n\nAction: Determine Role (Compose)\n  Expression: if(outputs('Check_Admin_Group'), 'Admin',\n              if(outputs('Check_PowerUser_Group'), 'PowerUser', 'User'))\n\nOutput: role (string)\n</code></pre> <p>Step 3: Load role at conversation start</p> <p>Via agent instructions (M365 Copilot compatible):</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Role-Gated Agent\ninstructions: |+\n  # Role-Gated Agent\n\n  ## CRITICAL: Detect User Role\n  At the START of every conversation, call \"GetUserContext\" to retrieve the user's role.\n  Store it for use throughout the conversation.\n\n  ## Role-Based Feature Access\n\n  ### All Users (role = \"User\")\n  - Knowledge search and Q&amp;A\n  - View data and reports\n  - Submit requests\n\n  ### Power Users (role = \"PowerUser\")\n  - Everything in \"User\" plus:\n  - Advanced search filters\n  - Export data\n  - View audit logs\n\n  ### Admins (role = \"Admin\")\n  - Everything in \"PowerUser\" plus:\n  - Debug mode (say \"xdebug on\" \u2014 see Gem 004)\n  - Data modification (create, update, delete records)\n  - Agent configuration queries\n  - User impersonation for testing\n\n  ## IMPORTANT: Invisible Gating\n  - NEVER mention features the user cannot access\n  - NEVER say \"You don't have permission to...\" for features they shouldn't know about\n  - If a user somehow tries a restricted action, respond naturally:\n    \"I can help you with [available features]. What would you like to do?\"\n  - If role detection fails, default to \"User\" role (most restrictive)\n</code></pre> <p>Step 4: Gate features in topics with ConditionGroup</p> <pre><code>    # Example: Admin-only data deletion\n    - kind: ConditionGroup\n      id: checkAdminAccess\n      conditions:\n        - id: isAdmin\n          condition: =Global.UserRole = \"Admin\"\n          actions:\n            - kind: SendActivity\n              id: confirmDelete\n              activity:\n                text:\n                  - \"\u26a0\ufe0f You're about to delete record #{Topic.RecordId}. This cannot be undone.\\n\\nConfirm deletion?\"\n            # ... deletion flow ...\n      elseActions:\n        # Non-admins don't see this feature at all\n        - kind: SendActivity\n          id: featureNotAvailable\n          activity:\n            text:\n              - \"I can help you view records and submit requests. What would you like to do?\"\n</code></pre> <p>Step 5: Gate trigger phrases (advanced)</p> <p>For topics that should only exist for certain roles, check the role at the very start of the topic:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Admin Configuration\n    triggerQueries:\n      - \"agent config\"\n      - \"change settings\"\n      - \"admin panel\"\n  actions:\n    # Gate: Admin only\n    - kind: ConditionGroup\n      id: gateAdmin\n      conditions:\n        - id: isAdmin\n          condition: =Global.UserRole = \"Admin\"\n          actions:\n            # ... admin configuration UI ...\n      elseActions:\n        # Silently redirect \u2014 user doesn't know this topic exists\n        - kind: SearchAndSummarizeContent\n          id: fallbackSearch\n          variable: Topic.FallbackAnswer\n          userInput: =System.Activity.Text\n</code></pre> <p>Step 6: Cache role across sessions (link to Gem 001)</p> <p>Persist the role using Gem 001 so the Graph API group check doesn't run every conversation:</p> <pre><code>    # After role detection, save to persistent storage\n    - kind: InvokeFlow\n      id: cacheRole\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        customData: =\"{\"\"role\"\": \"\"\" &amp; Global.UserRole &amp; \"\"\"}\"\n</code></pre> <p>Add a cache expiry check (e.g., re-detect role if last check was &gt;24 hours ago) to handle group membership changes.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires Entra ID groups + Power Automate flow + Graph API permissions. Maintainability \ud83d\udfe2 Add/remove users from groups in Entra admin. No agent changes for membership updates. Channel Compatibility \ud83d\udfe2 Works in all channels via agent instructions. Security Strength \ud83d\udfe2 Admin-managed groups. Not bypassable by users. Auditable. Automatic Detection \ud83d\udfe2 Zero user friction. Role is invisible to the user. Fail-Closed \ud83d\udfe2 Default to \"User\" if detection fails."},{"location":"gems/GEM-007-role-based-feature-gating/#limitations","title":"Limitations","text":"<ul> <li>Entra ID admin dependency: Someone must create and maintain the security groups. If your org doesn't have dedicated Entra admin access, this is a blocker.</li> <li>Graph API permissions: Requires <code>GroupMember.Read.All</code> or <code>Directory.Read.All</code> \u2014 these are admin consent permissions. Plan for approval delay.</li> <li>Group membership propagation: When a user is added to a group, it may take minutes to propagate. If using cached roles (Gem 001), set cache expiry appropriately.</li> <li>Power Automate latency: Adds 2-3 seconds at conversation start. Caching mitigates repeat calls.</li> </ul>"},{"location":"gems/GEM-007-role-based-feature-gating/#approach-b-claim-based-roles-from-authentication-context","title":"Approach B: Claim-Based Roles from Authentication Context","text":"<p>Summary: Extract role information directly from the user's authentication token claims. No external API calls needed. Technique: Copilot Studio's authentication system variables, Entra ID app roles, conditional logic in topics.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User authenticates to Copilot Studio\"] --&gt; B[\"Auth token contains custom claims:&lt;br/&gt;roles: Agent.Admin or Agent.User\"]\n    B --&gt; C[\"Agent reads claims&lt;br/&gt;from System.User context\"]\n    C --&gt; D[\"Topics gate features&lt;br/&gt;based on claimed roles\"]</code></pre> <p>Entra ID App Roles are custom roles defined in the agent's app registration. When a user authenticates, their assigned roles appear as claims in the token. The agent reads these claims directly \u2014 no Graph API call needed.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#implementation_1","title":"Implementation","text":"<p>Step 1: Define App Roles in Azure AD App Registration</p> <p>In Azure Portal \u2192 App Registrations \u2192 your Copilot Studio app \u2192 App Roles:</p> Role Name Display Name Allowed Members Value Agent.Admin Agent Administrator Users/Groups <code>Agent.Admin</code> Agent.PowerUser Agent Power User Users/Groups <code>Agent.PowerUser</code> Agent.User Agent User Users/Groups <code>Agent.User</code> <p>Step 2: Assign roles to users/groups</p> <p>In Enterprise Applications \u2192 your app \u2192 Users and Groups \u2192 Add assignment:</p> <ul> <li>Assign \"Agent.Admin\" role to your admin group</li> <li>Assign \"Agent.PowerUser\" to power user group</li> <li>Assign \"Agent.User\" to everyone (or make it default)</li> </ul> <p>Step 3: Read role from authentication context</p> <p>Note: Copilot Studio's ability to read custom token claims varies by authentication configuration. This approach works when authentication is configured with the agent's own app registration and custom scopes.</p> <pre><code>    # Check user's role from auth context\n    - kind: SetVariable\n      id: setRole\n      variable: Global.UserRole\n      value: =If(Contains(System.User.Roles, \"Agent.Admin\"), \"Admin\", If(Contains(System.User.Roles, \"Agent.PowerUser\"), \"PowerUser\", \"User\"))\n</code></pre> <p>Step 4: Apply gating logic</p> <p>Same <code>ConditionGroup</code> patterns as Approach A, Step 4-5. The gating logic is identical \u2014 only the detection mechanism differs.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires App Registration configuration + role assignments. Maintainability \ud83d\udfe2 Role assignments managed in Entra admin. Centralized. Channel Compatibility \ud83d\udfe1 Only works for authenticated channels. Anonymous Web Chat has no claims. Security Strength \ud83d\udfe2 Token-based. Cryptographically signed. Cannot be spoofed. Automatic Detection \ud83d\udfe2 Zero latency \u2014 roles are in the token, no API call needed. Fail-Closed \ud83d\udfe2 No role claim = default to most restrictive."},{"location":"gems/GEM-007-role-based-feature-gating/#limitations_1","title":"Limitations","text":"<ul> <li>Authentication required: Only works in channels with authentication enabled. Anonymous or pre-authenticated channels have no claims.</li> <li>App Registration setup: Defining App Roles and assigning them requires Azure AD admin access and understanding of Entra ID app model.</li> <li>Copilot Studio claim access: The ability to read custom claims from <code>System.User</code> context depends on the authentication configuration. Not all setups expose custom roles. Test your specific configuration.</li> <li>Not available in all channels: M365 Copilot uses its own authentication context. Custom app roles may not be present. Test claim availability in each target channel.</li> </ul>"},{"location":"gems/GEM-007-role-based-feature-gating/#approach-c-role-variable-via-agent-instructions","title":"Approach C: Role Variable via Agent Instructions","text":"<p>Summary: Define role-based behavior entirely in agent instructions using a global variable set by any detection method. The LLM enforces feature gating. Technique: Global variable for role, detailed agent instructions defining per-role capabilities, LLM-based enforcement.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Role detected&lt;br/&gt;(via Approach A, B, Gem 001 cache,&lt;br/&gt;or manual assignment)\"] --&gt; B[\"Global.UserRole =&lt;br/&gt;Admin / PowerUser / User\"]\n    B --&gt; C[\"Agent instructions define&lt;br/&gt;what each role can do\"]\n    C --&gt; D[\"LLM enforces:&lt;br/&gt;offers only role-appropriate features\"]</code></pre> <p>This approach focuses on the enforcement side \u2014 regardless of how the role is detected, the agent instructions define the behavioral boundaries per role. The LLM becomes the gatekeeper.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#implementation_2","title":"Implementation","text":"<p>Step 1: Comprehensive role-based instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Role-Aware Agent\ninstructions: |+\n  # Role-Aware Agent\n\n  ## User Role Context\n  The current user's role is stored in the conversation context.\n  Use it to determine which features and information to offer.\n\n  ## Role Definitions\n\n  ### Role: \"User\" (Default)\n  **Capabilities:**\n  - Search knowledge base and ask questions\n  - View their own records and history\n  - Submit new requests (tickets, approvals)\n  - Get general information and guidance\n\n  **Restrictions:**\n  - Cannot view other users' data\n  - Cannot modify or delete any records\n  - Cannot access configuration or settings\n  - Cannot enable debug mode\n\n  **Behavior:**\n  - Proactively suggest available actions: \"I can help you search, view your records, or submit a request.\"\n  - If asked about admin/restricted features, respond with: \"I can help you with [list available features].\"\n  - NEVER mention restricted features exist\n\n  ### Role: \"PowerUser\"\n  **Capabilities (in addition to User):**\n  - Advanced search with filters (date range, category, status)\n  - View team-level reports and summaries\n  - Export data to CSV format\n  - View audit logs for their team\n\n  **Restrictions:**\n  - Cannot modify or delete records\n  - Cannot access agent configuration\n  - Cannot enable debug mode\n\n  ### Role: \"Admin\"\n  **Capabilities (in addition to PowerUser):**\n  - Create, update, and delete records\n  - Enable debug mode (\"xdebug on\")\n  - View all users' data\n  - Access agent configuration and settings\n  - Impersonate other users for testing\n  - View system health and performance metrics\n\n  **Behavior:**\n  - Proactively offer admin-specific actions when relevant\n  - Always confirm destructive actions (delete, bulk update)\n  - Log all admin operations for audit\n\n  ## Enforcement Rules\n  1. ALWAYS check the user's role before offering or executing features\n  2. If role is unknown or empty, treat as \"User\" (fail-closed)\n  3. NEVER reveal the existence of features the user cannot access\n  4. NEVER explain WHY a feature is restricted \u2014 just offer alternatives\n  5. If a user explicitly asks \"am I an admin?\", you may confirm their role\n</code></pre> <p>Step 2: Combine with topic-level gating</p> <p>For critical operations (data deletion, configuration changes), don't rely solely on LLM instruction following. Add explicit <code>ConditionGroup</code> checks as a defense-in-depth layer:</p> <pre><code>    # LLM may route here based on instructions, but hard-gate as backup\n    - kind: ConditionGroup\n      id: hardGateAdmin\n      conditions:\n        - id: isAdmin\n          condition: =Global.UserRole = \"Admin\"\n          actions:\n            # Proceed with admin action\n      elseActions:\n        # Hard block even if LLM made a routing mistake\n        - kind: SendActivity\n          id: blockUnauthorized\n          activity:\n            text:\n              - \"I can help you with searching, viewing your records, or submitting requests. What would you like to do?\"\n</code></pre> <p>Step 3: Feature discovery \u2014 role-appropriate suggestions</p> <pre><code>    # In a \"What can you do?\" topic\n    - kind: ConditionGroup\n      id: suggestByRole\n      conditions:\n        - id: adminSuggestions\n          condition: =Global.UserRole = \"Admin\"\n          actions:\n            - kind: SendActivity\n              id: adminFeatures\n              activity:\n                text:\n                  - \"Here's what I can help with:\\n\\n\ud83d\udccb **Search &amp; Query**: Knowledge base, records, reports\\n\ud83d\udcca **Reports**: Team and org-level analytics\\n\u270f\ufe0f **Manage Records**: Create, update, delete\\n\ud83d\udd27 **Debug Mode**: Enable diagnostics (say 'xdebug on')\\n\u2699\ufe0f **Configuration**: Agent settings and tuning\"\n        - id: powerUserSuggestions\n          condition: =Global.UserRole = \"PowerUser\"\n          actions:\n            - kind: SendActivity\n              id: powerFeatures\n              activity:\n                text:\n                  - \"Here's what I can help with:\\n\\n\ud83d\udccb **Search &amp; Query**: Knowledge base, records, advanced filters\\n\ud83d\udcca **Reports**: Team-level analytics and exports\\n\ud83d\udce5 **Export**: Download data as CSV\"\n      elseActions:\n        - kind: SendActivity\n          id: userFeatures\n          activity:\n            text:\n              - \"Here's what I can help with:\\n\\n\ud83d\udccb **Search**: Ask me anything about our knowledge base\\n\ud83d\udc41\ufe0f **View**: Check your records and history\\n\ud83d\udcdd **Submit**: Create new requests and tickets\"\n</code></pre>"},{"location":"gems/GEM-007-role-based-feature-gating/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions + ConditionGroup. No external infrastructure for the gating itself. Maintainability \ud83d\udfe2 Role definitions are in one instruction block. Adding a role = adding a section. Channel Compatibility \ud83d\udfe2 Works everywhere. Role variable set by any detection method. Security Strength \ud83d\udfe1 LLM enforcement is probabilistic. Critical actions need hard-coded ConditionGroup backup. Automatic Detection N/A This approach doesn't detect roles \u2014 it enforces them. Pair with Approach A or B for detection. Fail-Closed \ud83d\udfe2 Instructions explicitly state: unknown role = \"User\"."},{"location":"gems/GEM-007-role-based-feature-gating/#limitations_2","title":"Limitations","text":"<ul> <li>LLM enforcement is not deterministic: The LLM usually follows role boundaries, but prompt injection or clever phrasing could bypass instruction-based gating. For security-critical features, always add hard-coded <code>ConditionGroup</code> checks.</li> <li>Not a standalone approach: This defines enforcement, not detection. You still need Approach A or B (or Gem 001 cached data) to set <code>Global.UserRole</code>.</li> <li>Instruction token cost: Detailed per-role instructions consume system prompt tokens. With 4+ roles, the instructions grow significantly.</li> <li>Testing complexity: Each role effectively creates a different \"version\" of the agent. You need to test with users in each role to verify gating works correctly.</li> </ul>"},{"location":"gems/GEM-007-role-based-feature-gating/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Entra Groups Approach B: Token Claims Approach C: LLM Instructions Detection Method Graph API group check Auth token claims None (enforcement only) Implementation Effort \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe2 Low (1 hour) Security Strength \ud83d\udfe2 Admin-managed groups \ud83d\udfe2 Cryptographic token \ud83d\udfe1 Probabilistic LLM Latency \ud83d\udfe1 2-3s (API call) \ud83d\udfe2 Zero (in token) \ud83d\udfe2 Zero (variable check) Anonymous Users \ud83d\udd34 Not supported \ud83d\udd34 Not supported \ud83d\udfe1 Default to \"User\" Maintenance \ud83d\udfe2 Group membership in Entra \ud83d\udfe2 Role assignment in Entra \ud83d\udfe2 Instructions only Defense-in-Depth \ud83d\udfe2 Hard gate possible \ud83d\udfe2 Hard gate possible \ud83d\udfe1 Needs ConditionGroup backup Best When... Standard enterprise deployment Custom app with Entra auth Quick setup, non-critical gating"},{"location":"gems/GEM-007-role-based-feature-gating/#recommended-approach","title":"Recommended Approach","text":"<p>For most enterprise scenarios: Approach A (Entra Groups) + Approach C (LLM Instructions) \u2014 detection + enforcement.</p> <p>Use Entra ID groups for reliable, admin-managed role detection. Use comprehensive agent instructions for behavioral enforcement (what features to offer, how to respond). Add hard-coded <code>ConditionGroup</code> checks as defense-in-depth for security-critical operations (data deletion, configuration changes).</p> <pre><code>Detection:   Approach A (Entra groups) or B (token claims)\nEnforcement: Approach C (agent instructions) + ConditionGroup hard gates\nCaching:     Gem 001 (persist role, re-detect every 24h)\n</code></pre> <p>Choose Approach B when: You have a custom Entra app registration with App Roles configured. Token-based detection is faster (zero latency) and doesn't require Power Automate.</p> <p>Skip the hard infrastructure when: Features being gated are low-risk (e.g., showing extra information, offering additional search filters). LLM instruction-based gating (Approach C alone) is sufficient for non-security-critical feature differentiation.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>LLM instruction-based gating is not a security boundary. LLMs are probabilistic. A determined user crafting specific prompts could potentially bypass instruction-based restrictions. For any feature involving data modification, deletion, or sensitive information access, ALWAYS use a hard-coded <code>ConditionGroup</code> check on <code>Global.UserRole</code> in addition to instructions.</p> <p>Warning</p> <p>ConversationStart doesn't fire in M365 Copilot (see Gotchas Compendium). If you detect roles in <code>OnConversationStart</code>, it won't work in M365 Copilot. Use agent instructions: \"At the start of every conversation, call GetUserContext to retrieve the user's role.\"</p> <p>Warning</p> <p>Graph API <code>memberOf</code> requires admin consent. The <code>GroupMember.Read.All</code> or <code>Directory.Read.All</code> permissions require tenant admin consent. Plan for approval time. If blocked, consider Approach B (token claims) as an alternative.</p> <p>Note</p> <p>Cache roles with expiry for responsiveness. Don't call Graph API every conversation. Cache the role via Gem 001 with a 24-hour expiry. Re-detect when cache expires. This balances security (group changes propagate within 24h) with performance (no API call for most conversations).</p> <p>Note</p> <p>Test with actual role assignments, not just code. The most common bug in role gating is the detection logic working in dev but failing in production because group names differ, permissions aren't granted, or the Graph API returns unexpected data. Test with real users in real groups.</p>"},{"location":"gems/GEM-007-role-based-feature-gating/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Cache the detected role so it persists across sessions (24h expiry recommended)</li> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Role and persona are complementary. Role gates features; persona adjusts tone. A user can be Admin role with Manager persona.</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Debug mode (Approach A's keyword toggle) is the most common example of a role-gated feature</li> </ul>"},{"location":"gems/GEM-007-role-based-feature-gating/#references","title":"References","text":"<ul> <li>Microsoft Learn: Entra ID security groups</li> <li>Microsoft Learn: App Roles in Azure AD</li> <li>Microsoft Graph API: List memberOf</li> <li>Microsoft Learn: Authentication in Copilot Studio</li> </ul> <p>Gem 007 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/","title":"Gem 008: Knowledge Source Optimization","text":"<p>Your agent can't find the answer \u2014 even though it's in your documents. Here's why and how to fix it.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#classification","title":"Classification","text":"Attribute Value Category Performance Complexity \u2b50\u2b50 (Low-Moderate \u2014 mostly content preparation, not code) Channels All (knowledge retrieval is channel-agnostic) Prerequisite Gems None"},{"location":"gems/GEM-008-knowledge-source-optimization/#the-problem","title":"The Problem","text":"<p>You uploaded 50 policy documents to your Copilot Studio knowledge source. You ask the agent: \"What's the paternity leave policy?\" The agent responds: \"I couldn't find information about that.\" But the answer is clearly on page 12 of the HR Policy Guide.</p> <p>This is the most common frustration builders face. The knowledge is there, but the agent can't find it. The causes are rarely obvious:</p> <ul> <li>Document format issues: PDF files with tables break text extraction (see Gotchas Compendium \u2014 Knowledge &amp; Search). Scanned PDFs with no OCR return empty text. Complex Word documents with nested tables lose structure.</li> <li>Content density: A single 200-page document buries relevant passages in noise. The retrieval engine finds the document but can't pinpoint the right section.</li> <li>Inconsistent terminology: The user asks about \"paternity leave\" but the document says \"parental leave for fathers.\" Semantic search helps, but it's not magic.</li> <li>Missing metadata: Without clear titles, headings, and structure, the retrieval engine has less signal to work with.</li> <li>Knowledge source limits: SharePoint indexing has delays. File upload has size limits. Website crawling has depth limits.</li> </ul> <p>The fundamental challenge: Retrieval quality is primarily a content preparation problem, not a platform problem. The same content, prepared differently, can yield dramatically different retrieval accuracy.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>Knowledge sources that consistently return relevant, accurate results:</p> <ul> <li>[ ] High retrieval rate: Agent finds relevant content &gt;95% of the time when it exists</li> <li>[ ] Accurate extraction: Tables, lists, and structured data are preserved in retrieval</li> <li>[ ] Fast indexing: New or updated content is searchable within minutes, not hours</li> <li>[ ] Maintainable: Content owners can update documents without breaking retrieval</li> <li>[ ] Scalable: Approach works for 10 documents and for 1,000 documents</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-008-knowledge-source-optimization/#approach-a-document-format-strategy","title":"Approach A: Document Format Strategy","text":"<p>Summary: Optimize the file format and internal structure of documents before uploading to knowledge sources. The format matters more than the content quantity. Technique: Content conversion pipeline (Markdown \u2192 HTML \u2192 Word), structured headings, table formatting, metadata enrichment.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#how-it-works","title":"How It Works","text":"<p>The knowledge retrieval pipeline works roughly like this:</p> <pre><code>Document \u2192 Text Extraction \u2192 Chunking \u2192 Embedding \u2192 Semantic Index \u2192 Query \u2192 Retrieval\n</code></pre> <p>Problems can occur at every stage. The format you choose determines how much information survives extraction and chunking.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#implementation","title":"Implementation","text":"<p>Step 1: Choose the right format</p> Format Text Extraction Tables Structure Recommendation Word (.docx) \ud83d\udfe2 Excellent \ud83d\udfe2 Preserved \ud83d\udfe2 Headings mapped \u2705 Best choice HTML \ud83d\udfe2 Excellent \ud83d\udfe2 Preserved \ud83d\udfe2 Tags mapped \u2705 Alternative Markdown (.md) \ud83d\udfe1 Good \ud83d\udfe1 Variable \ud83d\udfe1 Depends on parser \u26a0\ufe0f Test first PDF (text-based) \ud83d\udfe1 Fair \ud83d\udd34 Often broken \ud83d\udfe1 Limited \u26a0\ufe0f Avoid if possible PDF (scanned/image) \ud83d\udd34 Poor (needs OCR) \ud83d\udd34 Lost \ud83d\udd34 None \u274c Avoid Excel (.xlsx) \ud83d\udfe1 Fair \ud83d\udfe2 By nature \ud83d\udfe1 Sheet names only \u26a0\ufe0f Limited use PowerPoint (.pptx) \ud83d\udfe1 Fair \ud83d\udfe1 Variable \ud83d\udfe1 Slide-based \u26a0\ufe0f Low density <p>Step 2: Structure documents for retrieval</p> <pre><code># Document best practices for knowledge source optimization:\n\n## Use clear heading hierarchy\n- H1: Document title / major section\n- H2: Topic area\n- H3: Specific subtopic\n- The retrieval engine uses headings as chunk boundaries\n\n## Write self-contained sections\n- Each H2/H3 section should make sense independently\n- Don't rely on \"as mentioned above\" \u2014 chunks are retrieved independently\n- Include the topic name in each section, not just the heading\n\n## Structure tables properly\n- Add a caption above each table: \"Table 1: PTO Entitlements by Tenure\"\n- Include column headers in every table\n- Avoid merged cells (they break extraction)\n- Keep tables under 20 rows \u2014 split larger tables into logical groups\n\n## Front-load answers\n- Put the key information in the first paragraph of each section\n- Don't bury the answer in paragraph 5 after contextual preamble\n- Pattern: [Answer] \u2192 [Context] \u2192 [Exceptions] \u2192 [References]\n</code></pre> <p>Step 3: Convert existing content</p> <p>If your content is in PDF (the most common problematic format), convert it:</p> <pre><code>Source PDF\n    \u2502\n    \u25bc\nOpen in Word (File \u2192 Open \u2192 select PDF)\n    \u2502\n    \u25bc\nReview conversion quality (check tables, formatting)\n    \u2502\n    \u25bc\nFix any conversion artifacts\n    \u2502\n    \u25bc\nSave as .docx\n    \u2502\n    \u25bc\nUpload to SharePoint / Knowledge Source\n</code></pre> <p>For Markdown sources:</p> <pre><code>Source Markdown\n    \u2502\n    \u25bc\nConvert to HTML (use any Markdown renderer)\n    \u2502\n    \u25bc\nOpen HTML in Word (File \u2192 Open \u2192 select HTML)\n    \u2502\n    \u25bc\nSave as .docx\n    \u2502\n    \u25bc\nUpload to Knowledge Source\n</code></pre> <p>Step 4: Validate extraction quality</p> <p>After uploading, test retrieval with specific queries targeting:</p> <ul> <li>Content in tables (\"What's the PTO for 3-year employees?\")</li> <li>Content deep in the document (\"What's the exception for contract workers?\")</li> <li>Content using different terminology (\"paternity leave\" when doc says \"parental leave\")</li> <li>Content with numbers and dates (\"What's the deadline for Q3 budget submissions?\")</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 No code. Content preparation and reformatting. Maintainability \ud83d\udfe2 Once templates are established, content owners follow the pattern. Channel Compatibility \ud83d\udfe2 Knowledge source quality improves all channels equally. Retrieval Improvement \ud83d\udfe2 Format conversion alone can improve retrieval from 60% to 90%+. Scalability \ud83d\udfe1 Manual conversion for existing content. New content follows template from the start. Indexing Speed \ud83d\udfe2 No impact on indexing speed \u2014 only on retrieval quality."},{"location":"gems/GEM-008-knowledge-source-optimization/#limitations","title":"Limitations","text":"<ul> <li>Manual conversion effort: Converting 100 existing PDFs to Word is time-consuming. Prioritize high-query-volume documents first.</li> <li>Content owner adoption: Getting content owners to write in structured formats requires training and templates.</li> <li>Format doesn't fix bad content: If the information is genuinely not in the document, no format will fix it.</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#approach-b-content-chunking-strategy","title":"Approach B: Content Chunking Strategy","text":"<p>Summary: Instead of uploading large documents as-is, split them into smaller, focused topic files. Each file addresses one question or topic area. Technique: Content decomposition \u2014 one large document becomes many small documents, each optimized for retrieval.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Before:&lt;/b&gt; 1 file \u00d7 200 pages = poor retrieval&lt;br/&gt;&lt;b&gt;After:&lt;/b&gt; 40 files \u00d7 5 pages each = excellent retrieval\"]\n    B[\"HR_Policy_Complete_Guide.docx&lt;br/&gt;(200 pages)\"] --&gt;|Split into focused topics| C[\"HR-PTO-Entitlements.docx (5 pages)\"]\n    B --&gt; D[\"HR-PTO-Carryover-Rules.docx (3 pages)\"]\n    B --&gt; E[\"HR-Parental-Leave-Policy.docx (4 pages)\"]\n    B --&gt; F[\"HR-Sick-Leave-Policy.docx (3 pages)\"]\n    B --&gt; G[\"HR-Remote-Work-Policy.docx (6 pages)\"]\n    B --&gt; H[\"HR-Expense-Reimbursement.docx (5 pages)\"]\n    B --&gt; I[\"... 34 more topic files\"]</code></pre> <p>Smaller, focused files give the retrieval engine much better signal. Each file is about one topic, so when it matches, the entire file is relevant \u2014 not just a paragraph buried in page 147.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#implementation_1","title":"Implementation","text":"<p>Step 1: Decompose large documents</p> <p>Rules for splitting:</p> Guideline Rationale One topic per file Each file should answer a clear question or cover a specific area 2-10 pages per file Long enough for depth, short enough for focused retrieval Self-contained Each file makes sense without reading the others Descriptive filename <code>HR-Parental-Leave-Policy.docx</code> not <code>Policy-Section-3.2.docx</code> Include context Each file should state its scope: \"This document covers paternity and maternity leave policies for full-time employees.\" <p>Step 2: Add metadata headers</p> <p>Start each file with a metadata block that aids retrieval:</p> <pre><code># Parental Leave Policy\n**Category**: Human Resources\n**Applies to**: Full-time employees, all regions\n**Last Updated**: January 2026\n**Related Policies**: PTO Policy, Remote Work Policy\n\n## Overview\nThis document covers parental leave entitlements including maternity leave,\npaternity leave, and adoption leave for full-time Contoso employees.\n\n## Policy Details\n...\n</code></pre> <p>Step 3: Create a naming convention</p> <pre><code>[Department]-[Topic]-[Subtopic].docx\n\nExamples:\nHR-Leave-Parental.docx\nHR-Leave-PTO-Entitlements.docx\nHR-Leave-PTO-Carryover.docx\nIT-Security-Password-Policy.docx\nIT-Security-MFA-Setup-Guide.docx\nFinance-Expense-Travel-Policy.docx\nFinance-Expense-Reimbursement-Process.docx\n</code></pre> <p>Step 4: Organize in SharePoint folders</p> <pre><code>Knowledge Base (Document Library)\n\u251c\u2500\u2500 HR/\n\u2502   \u251c\u2500\u2500 Leave/\n\u2502   \u2502   \u251c\u2500\u2500 HR-Leave-Parental.docx\n\u2502   \u2502   \u251c\u2500\u2500 HR-Leave-PTO-Entitlements.docx\n\u2502   \u2502   \u2514\u2500\u2500 HR-Leave-Sick.docx\n\u2502   \u251c\u2500\u2500 Benefits/\n\u2502   \u2502   \u251c\u2500\u2500 HR-Benefits-Health-Insurance.docx\n\u2502   \u2502   \u2514\u2500\u2500 HR-Benefits-401k.docx\n\u2502   \u2514\u2500\u2500 Onboarding/\n\u2502       \u2514\u2500\u2500 HR-Onboarding-Checklist.docx\n\u251c\u2500\u2500 IT/\n\u2502   \u2514\u2500\u2500 Security/\n\u2502       \u251c\u2500\u2500 IT-Security-Password-Policy.docx\n\u2502       \u2514\u2500\u2500 IT-Security-MFA-Setup.docx\n\u2514\u2500\u2500 Finance/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"gems/GEM-008-knowledge-source-optimization/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Significant upfront effort to split existing documents. Maintainability \ud83d\udfe1 More files to manage. Content owners must update the right file. Risk of drift between files. Channel Compatibility \ud83d\udfe2 Purely content-side. No channel impact. Retrieval Improvement \ud83d\udfe2 Dramatic improvement for large document collections. Focused files match much better. Scalability \ud83d\udfe2 Scales well \u2014 many small files perform better than few large files. Indexing Speed \ud83d\udfe1 More files to index, but each indexes faster. Net neutral."},{"location":"gems/GEM-008-knowledge-source-optimization/#limitations_1","title":"Limitations","text":"<ul> <li>Upfront decomposition effort: Splitting 50 large documents into 500 focused files is a major content project. Prioritize by user query frequency.</li> <li>Maintenance overhead: 500 files are harder to manage than 50. Content changes may need updating in multiple files if topics overlap.</li> <li>Cross-reference loss: A large document has internal references (\"see Section 4.2\"). Split files lose these references. Add explicit cross-references: \"See also: HR-Leave-PTO-Carryover.docx.\"</li> <li>Duplication risk: Information that applies to multiple topics may be duplicated across files. Accept some duplication for retrieval quality.</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#approach-c-custom-instructions-for-retrieval-enhancement","title":"Approach C: Custom Instructions for Retrieval Enhancement","text":"<p>Summary: Use the <code>customInstructions</code> field of <code>SearchAndSummarizeContent</code> to guide how the LLM interprets and presents retrieved content. Technique: Tailored search instructions that improve answer quality without changing the underlying documents.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#how-it-works_2","title":"How It Works","text":"<p>Even with perfect documents, the LLM's response quality depends on how it's instructed to use retrieved content. Custom instructions act as a \"retrieval filter\" \u2014 telling the LLM how to interpret, prioritize, and present what it finds.</p> <pre><code>User query \u2192 Semantic search \u2192 Retrieved chunks \u2192 Custom Instructions \u2192 LLM \u2192 Response\n                                                        \u2191\n                                              \"How to use these results\"\n</code></pre>"},{"location":"gems/GEM-008-knowledge-source-optimization/#implementation_2","title":"Implementation","text":"<p>Step 1: Domain-specific search instructions</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: searchWithInstructions\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n      customInstructions: |\n        ## Search Instructions\n\n        ### Source Priority\n        When multiple sources contain relevant information:\n        1. Policies and official documents take precedence over meeting notes\n        2. Most recently updated document wins when information conflicts\n        3. Region-specific policies override global policies\n\n        ### Response Requirements\n        - ALWAYS cite the specific document name and section\n        - If the answer involves dates or amounts, quote the exact text\n        - If information is from a document older than 12 months, note: \"\u26a0\ufe0f This information is from [date]. Please verify it's still current.\"\n        - If no relevant information is found, say: \"I couldn't find this in our knowledge base. Try asking [specific alternative].\"\n\n        ### Table and Data Handling\n        - If the answer is in a table, reproduce the relevant rows\n        - Include column headers for context\n        - Don't summarize numbers \u2014 quote them exactly\n\n        ### Terminology Mapping\n        Users may ask using different terms than in the documents:\n        - \"PTO\" = \"Paid Time Off\" = \"Annual Leave\" = \"Vacation\"\n        - \"WFH\" = \"Remote Work\" = \"Work From Home\" = \"Telecommuting\"\n        - \"Paternity leave\" = \"Parental leave for fathers\" = \"Family leave\"\n</code></pre> <p>Step 2: Query-type-specific instructions</p> <p>For agents with different question patterns, you can use a Prompt Tool (Gem 002's Approach C pattern) to generate query-specific search instructions:</p> <pre><code>kind: PromptTool\nid: prompt_searchOptimizer\ndisplayName: \"Search Query Optimizer\"\ndescription: \"Generates optimized search instructions based on query type\"\ninstructions: |\n  Analyze this user query and generate search instructions:\n\n  Query: {userQuery}\n\n  Determine the query type:\n  - FACTUAL: Specific fact, date, number, or policy \u2192 Instruct: \"Quote exact text, cite source\"\n  - COMPARISON: Compare two things \u2192 Instruct: \"Create comparison table, cite both sources\"\n  - PROCEDURAL: How to do something \u2192 Instruct: \"Provide step-by-step from documents\"\n  - EXPLORATORY: Open-ended question \u2192 Instruct: \"Summarize from multiple sources, cite each\"\n\n  Return ONLY the search instruction tailored to this query type (3-5 lines max).\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: userQuery\n    type: string\noutputs:\n  - name: instructions\n    type: string\n</code></pre> <p>Step 3: Combine with Approach A and B</p> <p>Custom instructions work best on top of well-formatted, well-chunked content:</p> <pre><code>Approach A (Format) + Approach B (Chunking) + Approach C (Instructions) = Maximum retrieval quality\n</code></pre>"},{"location":"gems/GEM-008-knowledge-source-optimization/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Just text in the <code>customInstructions</code> field. Minutes to implement. Maintainability \ud83d\udfe2 Instructions are easy to update and iterate. Channel Compatibility \ud83d\udfe2 Applies to all channels (instructions affect LLM, not rendering). Retrieval Improvement \ud83d\udfe1 Improves response quality from retrieved content. Doesn't fix retrieval misses (document not found). Scalability \ud83d\udfe2 Same instructions apply regardless of document count. Indexing Speed \ud83d\udfe2 No impact on indexing. Instructions apply at query time."},{"location":"gems/GEM-008-knowledge-source-optimization/#limitations_2","title":"Limitations","text":"<ul> <li>Doesn't fix retrieval misses: If the semantic search doesn't find the relevant document, custom instructions can't help. This approach improves what happens AFTER retrieval, not the retrieval itself.</li> <li>Prompt Tool adds latency: The optional query-type-specific optimization adds an LLM call before the search. +1-3 seconds.</li> <li>Token cost: Longer custom instructions = more tokens per search call.</li> <li>LLM compliance variability: The model follows custom instructions well but not perfectly. \"Always cite the document\" works 90% of the time.</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Format Strategy Approach B: Content Chunking Approach C: Custom Instructions Implementation Effort \ud83d\udfe1 Content conversion \ud83d\udd34 Document decomposition \ud83d\udfe2 Configuration only Retrieval Improvement \ud83d\udfe2 High (format fixes extraction) \ud83d\udfe2 High (focused files match better) \ud83d\udfe1 Moderate (improves response, not retrieval) Fixes \"Can't Find\" Problem \ud83d\udfe2 Yes (broken extraction) \ud83d\udfe2 Yes (buried content) \ud83d\udd34 No (post-retrieval only) Fixes \"Wrong Answer\" Problem \ud83d\udfe1 Partially \ud83d\udfe1 Partially \ud83d\udfe2 Yes (guides interpretation) Ongoing Effort \ud83d\udfe2 Low (template established) \ud83d\udfe1 Medium (maintain many files) \ud83d\udfe2 Low (adjust instructions) Best When... Documents are in PDF/wrong format Large documents with many topics Retrieval works but answers are poor quality"},{"location":"gems/GEM-008-knowledge-source-optimization/#recommended-approach","title":"Recommended Approach","text":"<p>Apply all three in sequence \u2014 they're additive, not competing:</p> <pre><code>Step 1: Approach A (Format) \u2014 Fix document formats first\n        Convert PDFs to Word. Fix table formatting. Add headings.\n        This alone can improve retrieval from 60% to 85%.\n\nStep 2: Approach B (Chunking) \u2014 Split large documents\n        Decompose 200-page docs into focused topic files.\n        This pushes retrieval from 85% to 95%.\n\nStep 3: Approach C (Instructions) \u2014 Optimize response quality\n        Add custom search instructions for citation, terminology, and formatting.\n        This improves response quality for the 95% of queries that now retrieve correctly.\n</code></pre> <p>If you can only do one: Approach A (Format Strategy) \u2014 converting PDFs to Word is the single highest-impact action. In production, switching from PDF to Word fixed a complete retrieval failure (see Platform Gotchas below).</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>PDF tables break SharePoint knowledge retrieval (see Gotchas Compendium). This is the most common cause of \"agent can't find the answer.\" PDF text extraction corrupts table data. Convert to Word (.docx) for reliable table retrieval.</p> <p>Warning</p> <p>SharePoint file upload knowledge source has a 512 MB file size limit. Very large documents (multi-hundred-page PDFs with images) may hit this limit. Split into smaller files per Approach B.</p> <p>Note</p> <p>SharePoint indexing has a delay after upload. New or updated documents may take 5-30 minutes to appear in search results. Don't test retrieval immediately after uploading. Wait at least 30 minutes.</p> <p>Note</p> <p>The <code>customInstructions</code> field in <code>SearchAndSummarizeContent</code> is powerful but underdocumented. It accepts free-form Markdown/text and directly influences how the LLM uses retrieved content. Experiment with specific instructions for your domain.</p>"},{"location":"gems/GEM-008-knowledge-source-optimization/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 005: Multi-Language Agent Response \u2014 Knowledge source language affects retrieval. English docs + French queries works via semantic search, but response quality varies.</li> <li>Gem 003: Tracing Agent Progress Before Response \u2014 Add \"Searching knowledge base...\" progress messages before knowledge retrieval.</li> </ul>"},{"location":"gems/GEM-008-knowledge-source-optimization/#references","title":"References","text":"<ul> <li>Microsoft Learn: Knowledge sources in Copilot Studio</li> <li>Microsoft Learn: Generative answers</li> <li>Microsoft Learn: SharePoint as knowledge source</li> <li>Supported file types for knowledge</li> </ul> <p>Gem 008 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/","title":"Gem 009: Graceful Degradation and Fallback Chains","text":"<p>When your external service is down, your agent shouldn't be down with it.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 error handling across multiple integration points) Channels All Prerequisite Gems None (Gem 004 complementary for diagnostics)"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#the-problem","title":"The Problem","text":"<p>Production agents depend on external services: Power Automate flows, REST APIs, knowledge sources, Graph API, Dataverse. When any of these fail \u2014 and they will \u2014 the default behavior is catastrophic:</p> <ul> <li>Unhandled flow error: The agent shows a generic error message or goes silent. The user has no idea what happened.</li> <li>API timeout: The agent waits 30 seconds, then returns an error. The user has already left.</li> <li>Knowledge source empty: SharePoint indexing is delayed after a bulk upload. The agent says \"I couldn't find information\" for all queries \u2014 even though the content exists.</li> <li>Cascading failure: The agent calls Flow A, which calls API B, which calls Service C. Service C is down, so everything fails \u2014 and the user gets a cryptic error message about \"Workflow run failed.\"</li> </ul> <p>The fundamental challenge: agents that depend on external services must plan for those services being unavailable. A single unhandled failure point turns a sophisticated agent into a frustrating dead end.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that degrades gracefully when services are unavailable:</p> <ul> <li>[ ] No silent failures: Every error produces a user-friendly message with a clear next action</li> <li>[ ] Fallback alternatives: When the primary approach fails, a secondary approach activates</li> <li>[ ] Timeout management: Long-running operations have reasonable timeouts with user feedback</li> <li>[ ] Diagnostic logging: All failures are logged for investigation (link to Gem 004)</li> <li>[ ] Self-healing indicators: The agent tells the user when to try again or how to work around the issue</li> </ul>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#approach-a-error-branch-fallback-in-topics","title":"Approach A: Error-Branch Fallback in Topics","text":"<p>Summary: Wrap every external call with condition checks. Branch to fallback behavior when the call fails. Technique: <code>ConditionGroup</code> after every <code>InvokeFlow</code> / <code>HttpRequest</code>, error response variables, fallback <code>SendActivity</code> messages.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Call Service\"] --&gt; B{\"Check Result\"}\n    B --&gt;|Success| C[\"Process result\"]\n    B --&gt;|Failure| D[\"Fallback behavior\"]</code></pre> <p>Every external call has an explicit success/failure branch. The failure branch provides a user-friendly alternative \u2014 not just an error message.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#implementation","title":"Implementation","text":"<p>Step 1: Wrap Power Automate flow calls</p> <pre><code>    # Primary: Call flow to get user's ticket status\n    - kind: InvokeFlow\n      id: getTicketStatus\n      flowId: \"@environmentVariables('GetTicketStatusFlowId')\"\n      inputs:\n        ticketId: =Topic.TicketId\n      outputVariable: Topic.TicketResult\n\n    # Check: Did the flow succeed?\n    - kind: ConditionGroup\n      id: checkFlowResult\n      conditions:\n        - id: hasResult\n          condition: =!IsBlank(Topic.TicketResult) &amp;&amp; !IsBlank(Topic.TicketResult.status)\n          actions:\n            - kind: SendActivity\n              id: sendStatus\n              activity:\n                text:\n                  - \"Your ticket **#{Topic.TicketId}** is **{Topic.TicketResult.status}**.\\n\\nLast updated: {Topic.TicketResult.lastUpdate}\"\n      elseActions:\n        # Fallback: Provide alternative when flow fails\n        - kind: SendActivity\n          id: flowFailed\n          activity:\n            text:\n              - \"I'm having trouble retrieving your ticket status right now. Here's what you can do:\\n\\n1. **Try again in a few minutes** \u2014 our systems may be updating\\n2. **Check directly**: [Support Portal](https://support.contoso.com/tickets/{Topic.TicketId})\\n3. **Contact support**: Email support@contoso.com with ticket #{Topic.TicketId}\\n\\nI apologize for the inconvenience.\"\n\n    # Always: Log the attempt (Gem 004 telemetry)\n    - kind: LogCustomTelemetryEvent\n      id: logFlowAttempt\n      eventName: AgentTrace\n      properties: \"={TracePoint: \\\"FlowCall\\\", FlowName: \\\"GetTicketStatus\\\", Success: !IsBlank(Topic.TicketResult), TicketId: Topic.TicketId, ConversationId: System.Conversation.Id}\"\n</code></pre> <p>Step 2: Wrap HTTP Request calls with timeout</p> <pre><code>    # HTTP call with explicit timeout and error handling\n    - kind: HttpRequest\n      id: http_getWeather\n      method: GET\n      url: =Concatenate(\"https://api.weather.example.com/current?city=\", EncodeUrl(Topic.City))\n      headers:\n        - key: \"x-api-key\"\n          value: =Env.agent_WeatherApiKey\n      responseType: json\n      responseVariable: Topic.WeatherData\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.HttpStatus\n        errorResponseVariable: Topic.HttpError\n      timeout: 5000\n\n    # Three-way check: success, client error, server/timeout error\n    - kind: ConditionGroup\n      id: checkHttpResult\n      conditions:\n        - id: success\n          condition: =Topic.HttpStatus &gt;= 200 &amp;&amp; Topic.HttpStatus &lt; 300\n          actions:\n            - kind: SendActivity\n              id: sendWeather\n              activity:\n                text:\n                  - \"Weather in {Topic.City}: {Topic.WeatherData.description}, {Topic.WeatherData.temp}\u00b0C\"\n        - id: clientError\n          condition: =Topic.HttpStatus &gt;= 400 &amp;&amp; Topic.HttpStatus &lt; 500\n          actions:\n            - kind: SendActivity\n              id: sendClientError\n              activity:\n                text:\n                  - \"I couldn't find weather data for \\\"{Topic.City}\\\". Please check the city name and try again.\"\n      elseActions:\n        # Server error, timeout, or no response at all\n        - kind: SendActivity\n          id: sendServerError\n          activity:\n            text:\n              - \"The weather service is temporarily unavailable. Please try again in a few minutes.\"\n</code></pre> <p>Step 3: Knowledge source fallback</p> <pre><code>    # Primary: Knowledge search\n    - kind: SearchAndSummarizeContent\n      id: searchKnowledge\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n      customInstructions: \"Cite specific documents. If no relevant information is found, return empty.\"\n\n    # Fallback: Handle empty results\n    - kind: ConditionGroup\n      id: checkKnowledgeResult\n      conditions:\n        - id: hasAnswer\n          condition: =!IsBlank(Topic.Answer)\n          actions:\n            - kind: SendActivity\n              id: sendAnswer\n              activity:\n                text:\n                  - \"{Topic.Answer}\"\n      elseActions:\n        # Tiered fallback\n        - kind: SendActivity\n          id: suggestAlternatives\n          activity:\n            text:\n              - \"I couldn't find specific information about that in our knowledge base. Here are some alternatives:\\n\\n\ud83d\udd04 **Rephrase**: Try asking the question differently\\n\ud83d\udce7 **Email**: Contact the relevant team directly\\n\ud83d\udd17 **Browse**: Check our [documentation portal](https://docs.contoso.com)\\n\\nWould you like me to try a broader search?\"\n</code></pre> <p>Step 4: Standardized error response template</p> <p>Create a consistent fallback message pattern across all topics:</p> <pre><code>[Empathize] \u2014 \"I'm having trouble with...\"\n[Explain]   \u2014 \"Our [service] is temporarily unavailable\"\n[Offer]     \u2014 \"Here's what you can do instead: [1, 2, 3]\"\n[Timeframe] \u2014 \"Try again in a few minutes\"\n[Log]       \u2014 LogCustomTelemetryEvent for diagnosis\n</code></pre>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 ConditionGroup after each call. Pattern is repetitive but straightforward. Maintainability \ud83d\udfe1 Every external call gets a fallback branch. Lots of repeated pattern. Channel Compatibility \ud83d\udfe2 Plain text fallbacks work everywhere. User Experience \ud83d\udfe2 Users always get a helpful response, even when services fail. Diagnostic Logging \ud83d\udfe2 LogCustomTelemetryEvent captures every failure for investigation. Self-Healing \ud83d\udfe1 \"Try again in a few minutes\" \u2014 but no automatic retry mechanism."},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#limitations","title":"Limitations","text":"<ul> <li>Manual per-call instrumentation: Every <code>InvokeFlow</code> and <code>HttpRequest</code> needs its own fallback branch. In a 20-topic agent with 30 external calls, that's 30 error branches to write.</li> <li>No automatic retry: If a service fails, the user must manually retry. There's no built-in retry loop in Copilot Studio topics.</li> <li>Fallback quality varies: \"I couldn't find that\" is better than silence, but it's still a degraded experience. The fallback is a band-aid, not a solution.</li> </ul>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#approach-b-cached-last-known-good-response","title":"Approach B: Cached Last-Known-Good Response","text":"<p>Summary: Cache successful responses in persistent storage. When a service fails, serve the cached version with a staleness indicator. Technique: Write-through cache in Dataverse/SharePoint (Gem 001 patterns), conditional cache read on failure, staleness timestamps.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#how-it-works_1","title":"How It Works","text":"<pre><code>Service call succeeds:\n  \u2192 Return fresh data to user\n  \u2192 Cache the response with timestamp\n\nService call fails:\n  \u2192 Read cached response\n  \u2192 Show data with \"\u26a0\ufe0f Data as of [timestamp]\" warning\n  \u2192 Better than no data at all\n</code></pre> <p>This approach is valuable for data that changes infrequently \u2014 dashboards, reports, reference data, status summaries.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#implementation_1","title":"Implementation","text":"<p>Step 1: Cache on success</p> <p>After every successful service call, write the response to persistent storage:</p> <pre><code>    # Call the service\n    - kind: InvokeFlow\n      id: getDashboard\n      flowId: \"@environmentVariables('GetDashboardFlowId')\"\n      inputs:\n        teamId: =Global.UserTeamId\n      outputVariable: Topic.DashboardData\n\n    # Check success\n    - kind: ConditionGroup\n      id: checkDashboard\n      conditions:\n        - id: hasData\n          condition: =!IsBlank(Topic.DashboardData)\n          actions:\n            # Show fresh data\n            - kind: SendActivity\n              id: sendFreshDashboard\n              activity:\n                text:\n                  - \"\ud83d\udcca **Team Dashboard** (live data)\\n\\n{Topic.DashboardData.summary}\"\n\n            # Cache for fallback\n            - kind: InvokeFlow\n              id: cacheDashboard\n              flowId: \"@environmentVariables('WriteCacheFlowId')\"\n              inputs:\n                cacheKey: =Concatenate(\"dashboard_\", Global.UserTeamId)\n                cacheValue: =Topic.DashboardData.summary\n                timestamp: =Text(Now(), DateTimeFormat.UTC)\n\n      elseActions:\n        # Service failed \u2014 try cache\n        - kind: InvokeFlow\n          id: readCache\n          flowId: \"@environmentVariables('ReadCacheFlowId')\"\n          inputs:\n            cacheKey: =Concatenate(\"dashboard_\", Global.UserTeamId)\n          outputVariable: Topic.CachedDashboard\n\n        - kind: ConditionGroup\n          id: checkCache\n          conditions:\n            - id: cacheHit\n              condition: =!IsBlank(Topic.CachedDashboard)\n              actions:\n                - kind: SendActivity\n                  id: sendCachedDashboard\n                  activity:\n                    text:\n                      - \"\ud83d\udcca **Team Dashboard** (\u26a0\ufe0f cached data from {Topic.CachedDashboard.timestamp})\\n\\n{Topic.CachedDashboard.value}\\n\\n_Live data is temporarily unavailable. This shows the last known data._\"\n          elseActions:\n            # No cache either \u2014 full fallback\n            - kind: SendActivity\n              id: noDataAvailable\n              activity:\n                text:\n                  - \"The dashboard service is temporarily unavailable and I don't have cached data yet. Please try again in a few minutes or check the [dashboard portal](https://dashboard.contoso.com).\"\n</code></pre>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires cache storage (Dataverse/SharePoint) + read/write flows. More infrastructure. Maintainability \ud83d\udfe1 Cache invalidation is a classic hard problem. Expiry logic needs thought. Channel Compatibility \ud83d\udfe2 Cache is backend-only. All channels benefit equally. User Experience \ud83d\udfe2 Users get data (even if stale) instead of an error message. Diagnostic Logging \ud83d\udfe1 Must log cache hits/misses separately for monitoring. Self-Healing \ud83d\udfe1 Cache is self-healing \u2014 next successful call refreshes it automatically."},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#limitations_1","title":"Limitations","text":"<ul> <li>Stale data risk: Cached data may be hours or days old. For time-sensitive information (real-time status, financial data), stale data could be misleading.</li> <li>Cache storage overhead: Another Dataverse table or SharePoint list to manage. Cache entries accumulate and need expiry/cleanup.</li> <li>Not suitable for all data: User-specific or transaction-specific data (ticket status, order details) is too volatile to cache meaningfully.</li> <li>Write-through latency: Caching on every success adds a small write operation to every successful call.</li> </ul>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#approach-c-escalation-with-context-preservation","title":"Approach C: Escalation with Context Preservation","text":"<p>Summary: When a service failure cannot be resolved by fallback or cache, escalate to a human agent with full conversation context preserved. Technique: <code>OnEscalate</code> topic with context summary, conversation handoff with metadata, Dynamics 365 or Teams queue integration.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#how-it-works_2","title":"How It Works","text":"<pre><code>Service fails \u2192 Fallback attempted \u2192 Fallback insufficient\n    \u2502\n    \u25bc\nAgent: \"I'm unable to resolve this automatically right now.\n        Let me connect you with a human agent who can help.\"\n    \u2502\n    \u25bc\nEscalation with context:\n  - User's original question\n  - What the agent tried\n  - What failed and why\n  - Conversation history summary\n</code></pre>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#implementation_2","title":"Implementation","text":"<p>Step 1: Build a context-preserving escalation topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnEscalate\n  id: main\n  actions:\n    # Summarize conversation context for the human agent\n    - kind: SetVariable\n      id: buildContext\n      variable: init:Topic.EscalationContext\n      value: =\"**Escalation Context**\\n\\n**User**: \" &amp; Global.UserDisplayName &amp; \"\\n**Original Query**: \" &amp; System.Activity.Text &amp; \"\\n**Error**: Service unavailable \u2014 \" &amp; Topic.LastErrorMessage &amp; \"\\n**Attempted Fallback**: \" &amp; Topic.FallbackAttempted &amp; \"\\n**Conversation ID**: \" &amp; System.Conversation.Id &amp; \"\\n**Time**: \" &amp; Text(Now(), DateTimeFormat.UTC)\n\n    # Inform the user\n    - kind: SendActivity\n      id: escalationNotice\n      activity:\n        text:\n          - \"I apologize \u2014 I'm unable to complete this request automatically right now.\\n\\n\ud83e\uddd1\u200d\ud83d\udcbc I'm transferring you to a human agent with full context of our conversation.\\n\\n**What happens next:**\\n1. A support agent will review your question\\n2. They'll have the context of what we discussed\\n3. Typical response time: 5-15 minutes\\n\\nIs there anything else you'd like me to include in the handoff?\"\n\n    # Log the escalation\n    - kind: LogCustomTelemetryEvent\n      id: logEscalation\n      eventName: AgentEscalation\n      properties: \"={Reason: \\\"ServiceFailure\\\", ErrorMessage: Topic.LastErrorMessage, ConversationId: System.Conversation.Id, UserId: System.User.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # Transfer to live agent (if Omnichannel configured)\n    - kind: EndDialog\n      id: endWithHandoff\n      clearTopicQueue: true\n</code></pre> <p>Step 2: Enrich with conversation summary for simpler setups</p> <p>If you don't have Dynamics 365 Omnichannel, send the context via alternative channels:</p> <pre><code>    # Alternative: Send context via email\n    - kind: InvokeFlow\n      id: sendEscalationEmail\n      flowId: \"@environmentVariables('SendEscalationEmailFlowId')\"\n      inputs:\n        recipientEmail: \"support-queue@contoso.com\"\n        subject: =Concatenate(\"Agent Escalation: \", System.Activity.Text)\n        body: =Topic.EscalationContext\n        userEmail: =Global.UserEmail\n</code></pre>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Context assembly is straightforward. Human handoff infrastructure varies greatly. Maintainability \ud83d\udfe2 Escalation topic is reusable across all failure scenarios. Channel Compatibility \ud83d\udfe1 Omnichannel handoff is Teams/Web Chat specific. Email fallback works everywhere. User Experience \ud83d\udfe2 Clear explanation, preserved context, expected timeline. Professional. Diagnostic Logging \ud83d\udfe2 Escalation events enable tracking failure patterns and improving the agent. Self-Healing \ud83d\udd34 Not self-healing \u2014 requires human intervention."},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#limitations_2","title":"Limitations","text":"<ul> <li>Requires human infrastructure: You need a human support team, queue, or at minimum an email inbox. Not applicable for fully automated agents.</li> <li>Context loss in handoff: Conversation history may not fully transfer to the human agent depending on the handoff mechanism. Email-based handoff is lossy.</li> <li>User wait time: Human response takes minutes to hours. The benefit of an AI agent (instant response) is lost.</li> </ul>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Error-Branch Approach B: Cache Approach C: Escalation Implementation Effort \ud83d\udfe2 Low per call \ud83d\udfe1 Medium (cache infra) \ud83d\udfe1 Medium (handoff infra) User Gets Data \ud83d\udd34 No (alternative offered) \ud83d\udfe2 Yes (stale but present) \ud83d\udd34 No (human will help) Immediate Resolution \ud83d\udfe1 Partial (alternatives) \ud83d\udfe2 Yes (cached data) \ud83d\udd34 No (wait for human) Suitable Data Types \ud83d\udfe2 All \ud83d\udfe1 Semi-static data only \ud83d\udfe2 All Infrastructure \ud83d\udfe2 None extra \ud83d\udfe1 Cache storage \ud83d\udfe1 Support queue Best When... Quick alternative action exists Data changes infrequently User needs something the agent truly can't provide"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#recommended-approach","title":"Recommended Approach","text":"<p>Layer all three \u2014 they're a cascade, not alternatives:</p> <pre><code>Service call attempted\n    \u2502\n    \u251c\u2500\u2500 Success \u2192 Return data, cache it (Approach B)\n    \u2502\n    \u251c\u2500\u2500 Failure, Level 1 \u2192 Try cached version (Approach B)\n    \u2502                        Show with staleness warning\n    \u2502\n    \u251c\u2500\u2500 Failure, Level 2 \u2192 Offer alternatives (Approach A)\n    \u2502                        Links, rephrasing, manual workarounds\n    \u2502\n    \u2514\u2500\u2500 Failure, Level 3 \u2192 Escalate to human (Approach C)\n                             Full context preserved\n</code></pre> <p>Start with Approach A \u2014 it's the minimum viable resilience. Every external call should have a failure branch. Then add Approach B for frequently-accessed, semi-static data. Add Approach C as the last resort for critical requests that truly can't wait.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Power Automate flow failures may not return to the agent gracefully. If a flow crashes mid-execution (not a handled error, but an unhandled exception), the agent may receive no response at all \u2014 not even an error. Use <code>continueOnError</code> and check for blank output variables as your safety net.</p> <p>Warning</p> <p><code>HttpRequest</code> timeout defaults may be too long. If you don't set a <code>timeout</code>, the default may be 30+ seconds. Users will leave before the timeout fires. Set explicit timeouts: 5 seconds for fast APIs, 10 seconds maximum for anything user-facing.</p> <p>Note</p> <p>Application Insights reveals failure patterns. Log every failure via <code>LogCustomTelemetryEvent</code> (Gem 004's Approach B). Aggregate in KQL to find which services fail most, at what times, and for which users. This data drives your fallback strategy priorities.</p>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 003: Tracing Agent Progress Before Response \u2014 Show \"Attempting to retrieve...\" progress messages before fallback kicks in</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Telemetry logging for failure diagnosis</li> <li>Gem 001: Persisting User Context Across Sessions \u2014 Cache infrastructure from Gem 001 can be reused for response caching</li> </ul>"},{"location":"gems/GEM-009-graceful-degradation-and-fallback-chains/#references","title":"References","text":"<ul> <li>Microsoft Learn: Error handling in Power Automate</li> <li>Microsoft Learn: HTTP Request node in Copilot Studio</li> <li>Microsoft Learn: Escalation and handoff</li> </ul> <p>Gem 009 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/","title":"Gem 010: Agent-to-Human Handoff with Context","text":"<p>When the agent can't help, hand off to a human \u2014 without making the user repeat everything.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#classification","title":"Classification","text":"Attribute Value Category UX Complexity \u2b50\u2b50\u2b50 to \u2b50\u2b50\u2b50\u2b50 (depends on handoff infrastructure) Channels Teams, Web Chat (Omnichannel), M365 Copilot (limited) Prerequisite Gems None (Gem 009 complementary for fallback chains)"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#the-problem","title":"The Problem","text":"<p>Every agent has limits. When the user's question exceeds the agent's capabilities \u2014 complex edge cases, sensitive issues, emotional situations, or missing knowledge \u2014 the right action is to connect them with a human.</p> <p>But the typical handoff experience is terrible:</p> <ul> <li>Context loss: The user explains their problem to the agent, gets transferred, and the human agent asks \"How can I help you?\" \u2014 forcing the user to repeat everything.</li> <li>No triage: The human agent receives a notification with no context. They don't know what was already discussed, what was tried, or why the escalation happened.</li> <li>Abrupt transfer: The agent says \"Let me transfer you\" and the conversation ends. No explanation of what happens next, no expected wait time, no confirmation.</li> <li>No follow-up loop: The human resolves the issue, but the resolution isn't captured. The next time the user asks the same question, the agent still can't help.</li> </ul> <p>The fundamental challenge: preserving and transferring conversation context across the AI-to-human boundary in a way that's useful to both the user and the human agent.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A seamless handoff where the human agent is fully briefed:</p> <ul> <li>[ ] Context transferred: The human agent receives a summary of the conversation, the user's question, and what the agent already tried</li> <li>[ ] User informed: The user knows what's happening, what to expect, and estimated wait time</li> <li>[ ] Triage data: Priority, category, and user details are included for queue routing</li> <li>[ ] Multi-channel: Works in the primary deployment channel (Teams, Web Chat)</li> <li>[ ] Graceful experience: The transition feels smooth, not like hitting a wall</li> </ul>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#approach-a-llm-generated-conversation-summary","title":"Approach A: LLM-Generated Conversation Summary","text":"<p>Summary: Use the LLM to generate a concise summary of the conversation, then package it as a handoff message to the human support queue. Technique: Prompt Tool for conversation summarization, topic variables for context assembly, email/Teams/Omnichannel handoff.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Escalation triggered\"] --&gt; B[\"&lt;b&gt;Prompt Tool:&lt;/b&gt; Summarize conversation&lt;br/&gt;Input: history, query, actions&lt;br/&gt;Output: structured summary\"]\n    B --&gt; C[\"&lt;b&gt;Package handoff:&lt;/b&gt;&lt;br/&gt;\u2022 Summary&lt;br/&gt;\u2022 User details name, email, role&lt;br/&gt;\u2022 Category and priority&lt;br/&gt;\u2022 Conversation ID\"]\n    C --&gt; D[\"&lt;b&gt;Deliver to human:&lt;/b&gt;&lt;br/&gt;Email / Teams channel / Omnichannel queue\"]</code></pre>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#implementation","title":"Implementation","text":"<p>Step 1: Create a conversation summarizer Prompt Tool</p> <pre><code>kind: PromptTool\nid: prompt_conversationSummary\ndisplayName: \"Conversation Summarizer\"\ndescription: \"Generates a concise handoff summary for human agents\"\ninstructions: |\n  Summarize this conversation for a human support agent who will take over.\n\n  User's latest message: {userMessage}\n  Topic the agent was handling: {topicName}\n  Error or reason for escalation: {escalationReason}\n  User's name: {userName}\n\n  Generate a summary with these sections:\n\n  **User Request**: What the user originally asked (1-2 sentences)\n  **What Was Tried**: What the agent attempted to do (bullet points)\n  **Why Escalating**: Why the agent couldn't resolve this (1 sentence)\n  **Suggested Action**: What the human agent should do next (1-2 sentences)\n\n  Keep the summary under 150 words. Be factual, not apologetic.\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: userMessage\n    type: string\n    required: true\n  - name: topicName\n    type: string\n    required: true\n  - name: escalationReason\n    type: string\n    required: true\n  - name: userName\n    type: string\noutputs:\n  - name: summary\n    type: string\n</code></pre> <p>Step 2: Build the escalation topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnEscalate\n  id: main\n  actions:\n    # Generate conversation summary\n    - kind: InvokePrompt\n      id: generateSummary\n      promptId: prompt_conversationSummary\n      inputs:\n        userMessage: =System.Activity.Text\n        topicName: =If(IsBlank(Topic.CurrentTopicName), \"General\", Topic.CurrentTopicName)\n        escalationReason: =If(IsBlank(Topic.EscalationReason), \"User requested human assistance\", Topic.EscalationReason)\n        userName: =If(IsBlank(Global.UserDisplayName), \"Unknown\", Global.UserDisplayName)\n      outputVariable: Topic.HandoffSummary\n\n    # Ask user for priority before handoff\n    - kind: Question\n      id: askPriority\n      variable: init:Topic.Priority\n      prompt: \"Before I connect you with a support agent, how urgent is this?\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"Low\"\n          synonyms: [\"not urgent\", \"when possible\"]\n        - value: \"Medium\"\n          synonyms: [\"normal\", \"standard\"]\n        - value: \"High\"\n          synonyms: [\"urgent\", \"ASAP\", \"blocking\"]\n\n    # Build the handoff package\n    - kind: SetVariable\n      id: buildHandoffPackage\n      variable: init:Topic.HandoffPackage\n      value: =\"## Agent Handoff\\n\\n**Conversation ID**: \" &amp; System.Conversation.Id &amp; \"\\n**User**: \" &amp; Global.UserDisplayName &amp; \"\\n**Email**: \" &amp; Global.UserEmail &amp; \"\\n**Priority**: \" &amp; Topic.Priority &amp; \"\\n**Time**: \" &amp; Text(Now(), DateTimeFormat.UTC) &amp; \"\\n\\n---\\n\\n\" &amp; Topic.HandoffSummary\n\n    # Inform the user\n    - kind: SendActivity\n      id: informUser\n      activity:\n        text:\n          - \"I'm connecting you with a support agent now.\\n\\n\ud83d\udccb **What I've shared with them:**\\n- A summary of our conversation\\n- Your contact details\\n- Priority: {Topic.Priority}\\n\\n\u23f1 **Expected wait time**: Usually 5-15 minutes during business hours.\\n\\n\ud83d\udca1 **Reference**: Conversation {System.Conversation.Id}\\n\\nA human agent will reach out shortly. Is there anything else you'd like me to include?\"\n\n    # Send to support queue (via Power Automate)\n    - kind: InvokeFlow\n      id: sendToQueue\n      flowId: \"@environmentVariables('EscalationFlowId')\"\n      inputs:\n        handoffPackage: =Topic.HandoffPackage\n        userEmail: =Global.UserEmail\n        priority: =Topic.Priority\n        conversationId: =System.Conversation.Id\n\n    # Log for analytics\n    - kind: LogCustomTelemetryEvent\n      id: logEscalation\n      eventName: AgentEscalation\n      properties: \"={Reason: Topic.EscalationReason, Priority: Topic.Priority, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 3: Power Automate flow for email-based handoff</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: handoffPackage, userEmail, priority, conversationId\n\nAction: Send Email (Outlook)\n  To: support-queue@contoso.com\n  Subject: \"[{priority}] Agent Handoff - Conv #{conversationId}\"\n  Body: {handoffPackage}\n  Importance: if(priority = \"High\", \"High\", \"Normal\")\n\nOptional: Post to Teams Channel\n  Team: Support Team\n  Channel: Agent Escalations\n  Message: {handoffPackage}\n</code></pre>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Prompt Tool + email flow. Works without Omnichannel. Maintainability \ud83d\udfe2 Summary prompt is easy to adjust. Escalation topic is reusable. Channel Compatibility \ud83d\udfe2 All channels (email handoff is channel-agnostic). Context Quality \ud83d\udfe2 LLM generates readable, structured summaries. Human agents can scan quickly. User Experience \ud83d\udfe2 Clear communication: what's shared, what to expect, reference number. Real-time Handoff \ud83d\udd34 Async \u2014 user waits for email/Teams response. Not a live chat transfer."},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#limitations","title":"Limitations","text":"<ul> <li>Asynchronous handoff: The user doesn't get a live chat with a human. They get a notification that a human will follow up. Acceptable for email-based support; insufficient for real-time chat expectations.</li> <li>Summary quality depends on LLM: The Prompt Tool's summary is only as good as the context it receives. If topic variables weren't tracked, the summary may be thin.</li> <li>No live queue visibility: The user doesn't know their position in queue or real-time status. They trust the \"5-15 minutes\" estimate.</li> </ul>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#approach-b-structured-context-card-handoff","title":"Approach B: Structured Context Card Handoff","text":"<p>Summary: Instead of LLM-generated prose, assemble a structured Adaptive Card with all relevant context fields. Send to the human agent via Teams or email. Technique: Adaptive Card with context fields, Power Automate distribution, optional Teams Incoming Webhook posting.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Escalation triggered\"] --&gt; B[\"Assemble structured context:&lt;br/&gt;\u2022 User details (name, email, role)&lt;br/&gt;\u2022 Conversation summary&lt;br/&gt;\u2022 What was tried (topic trail)&lt;br/&gt;\u2022 Category, priority, timestamp\"]\n    B --&gt; C[\"Format as Adaptive Card JSON\"]\n    C --&gt; D[\"Post to Teams support channel&lt;br/&gt;via Incoming Webhook\"]</code></pre> <p>The structured card is visually scannable \u2014 human agents can triage in seconds without reading paragraphs.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#implementation_1","title":"Implementation","text":"<p>Step 1: Build the context card</p> <pre><code>    - kind: SetVariable\n      id: buildContextCard\n      variable: init:Topic.ContextCardJson\n      value: |\n        {\n          \"type\": \"AdaptiveCard\",\n          \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n          \"version\": \"1.5\",\n          \"body\": [\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"\ud83d\udea8 Agent Handoff Request\",\n              \"weight\": \"bolder\",\n              \"size\": \"large\",\n              \"color\": \"attention\"\n            },\n            {\n              \"type\": \"FactSet\",\n              \"facts\": [\n                {\"title\": \"User\", \"value\": \"{Global.UserDisplayName}\"},\n                {\"title\": \"Email\", \"value\": \"{Global.UserEmail}\"},\n                {\"title\": \"Priority\", \"value\": \"{Topic.Priority}\"},\n                {\"title\": \"Conversation\", \"value\": \"{System.Conversation.Id}\"},\n                {\"title\": \"Time (UTC)\", \"value\": \"{Text(Now(), DateTimeFormat.UTC)}\"}\n              ]\n            },\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"**User's Request**\",\n              \"weight\": \"bolder\",\n              \"separator\": true\n            },\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"{System.Activity.Text}\",\n              \"wrap\": true\n            },\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"**Escalation Reason**\",\n              \"weight\": \"bolder\",\n              \"separator\": true\n            },\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"{Topic.EscalationReason}\",\n              \"wrap\": true\n            }\n          ]\n        }\n</code></pre> <p>Step 2: Post to Teams support channel</p> <pre><code>Power Automate Flow:\n  Action: Post to Teams channel (Incoming Webhook)\n    Webhook URL: @environmentVariables('SupportWebhookUrl')\n    Body: Topic.ContextCardJson\n</code></pre> <p>Step 3: Inform the user (same pattern as Approach A)</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Card JSON requires careful assembly. Teams Webhook setup needed. Maintainability \ud83d\udfe1 Card JSON is verbose. Adding fields means editing JSON. Channel Compatibility \ud83d\udfe1 Teams Webhook for card delivery. Email for non-Teams support teams. Context Quality \ud83d\udfe1 Structured but static. Only includes fields you explicitly map \u2014 no LLM summary. User Experience \ud83d\udfe2 Same as Approach A \u2014 clear communication to user. Real-time Handoff \ud83d\udfe1 Teams notification is near-real-time. Better than email."},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#limitations_1","title":"Limitations","text":"<ul> <li>Static fields only: The card shows what you explicitly map. Unlike Approach A's LLM summary, it can't infer \"what was discussed\" from conversation context.</li> <li>Teams Webhook setup: Requires configuring an Incoming Webhook in a Teams channel. Admin permissions may be needed.</li> <li>Card JSON maintenance: Verbose JSON is error-prone and hard to read.</li> </ul>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#approach-c-dynamics-365-omnichannel-live-handoff","title":"Approach C: Dynamics 365 Omnichannel Live Handoff","text":"<p>Summary: Use the built-in Copilot Studio \u2192 Dynamics 365 Omnichannel for Customer Service integration for a seamless live chat transfer. Technique: Copilot Studio's native escalation to Omnichannel, conversation transcript transfer, queue routing.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Escalation triggered\"] --&gt; B[\"Copilot Studio transfers conversation&lt;br/&gt;to Omnichannel\"]\n    B --&gt; C[\"&lt;b&gt;Omnichannel:&lt;/b&gt;&lt;br/&gt;\u2022 Routes to appropriate queue&lt;br/&gt;\u2022 Human agent sees full transcript&lt;br/&gt;\u2022 Agent picks up live chat\"]\n    C --&gt; D[\"User continues chatting&lt;br/&gt;\u2014 now with human agent&lt;br/&gt;(no channel switch, no context loss)\"]</code></pre> <p>This is the only approach that provides a true live chat transfer \u2014 the user stays in the same conversation, and a human agent joins the chat seamlessly.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#implementation_2","title":"Implementation","text":"<p>Step 1: Configure Omnichannel integration</p> <p>In Copilot Studio:</p> <ol> <li>Go to Settings \u2192 Customer engagement hub</li> <li>Select Dynamics 365 Customer Service</li> <li>Connect your Omnichannel environment</li> <li>Configure queue routing rules</li> </ol> <p>Step 2: Set context variables for routing</p> <pre><code>    # Before escalation, set context variables that Omnichannel uses for routing\n    - kind: SetVariable\n      id: setCategory\n      variable: Global.EscalationCategory\n      value: =Topic.Category\n\n    - kind: SetVariable\n      id: setPriority\n      variable: Global.EscalationPriority\n      value: =Topic.Priority\n\n    # Escalation message\n    - kind: SendActivity\n      id: sendEscalationMessage\n      activity:\n        text:\n          - \"I'm connecting you with a support agent now. They'll be able to see our full conversation.\\n\\n\u23f1 A human agent will join this chat shortly.\"\n\n    # Trigger the transfer\n    - kind: EndDialog\n      id: escalateToOmnichannel\n      clearTopicQueue: true\n</code></pre> <p>Step 3: Omnichannel queue receives the conversation</p> <p>Omnichannel automatically:</p> <ul> <li>Transfers the full conversation transcript</li> <li>Passes context variables (category, priority) for routing</li> <li>Queues the conversation to the appropriate team</li> <li>Notifies the next available agent</li> </ul> <p>The human agent sees the entire conversation in their Omnichannel workspace \u2014 every message the user sent and every response the agent gave.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 Requires Dynamics 365 Omnichannel license + configuration. Major infrastructure. Maintainability \ud83d\udfe2 Once configured, Omnichannel handles routing and queue management. Channel Compatibility \ud83d\udfe1 Works for Teams and Web Chat channels with Omnichannel. Not M365 Copilot. Context Quality \ud83d\udfe2 Full conversation transcript transferred automatically. Best context preservation. User Experience \ud83d\udfe2 Seamless \u2014 user stays in the same chat. No channel switch. Real-time Handoff \ud83d\udfe2 Live transfer to human agent. True real-time chat handoff."},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#limitations_2","title":"Limitations","text":"<ul> <li>Dynamics 365 license required: Omnichannel for Customer Service is a premium Dynamics 365 license. Significantly more expensive than email or Teams-based handoff.</li> <li>Complex setup: Omnichannel configuration (queues, routing rules, agent workspace, capacity management) is a project in itself.</li> <li>Channel restrictions: Only works for channels connected to Omnichannel (Web Chat, Teams). M365 Copilot doesn't support Omnichannel handoff.</li> <li>Overkill for internal agents: If your agent serves 50 internal employees, deploying Omnichannel is disproportionate. Email or Teams handoff is sufficient.</li> </ul>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: LLM Summary Approach B: Context Card Approach C: Omnichannel Implementation Effort \ud83d\udfe2 Low (2-3 hours) \ud83d\udfe1 Medium (2-3 hours) \ud83d\udd34 High (days-weeks) Licensing Cost \ud83d\udfe2 None extra \ud83d\udfe2 None extra \ud83d\udd34 Dynamics 365 license Context Quality \ud83d\udfe2 LLM-summarized \ud83d\udfe1 Structured fields only \ud83d\udfe2 Full transcript Real-time Transfer \ud83d\udd34 Async (email/Teams) \ud83d\udfe1 Near-real-time (Teams) \ud83d\udfe2 Live chat transfer User Channel Switch \ud83d\udd34 May switch to email \ud83d\udfe1 Stays in Teams \ud83d\udfe2 Same conversation Best When... Internal agents, email-based support Teams-centric support teams Customer-facing, high-volume support"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#recommended-approach","title":"Recommended Approach","text":"<p>For internal/enterprise agents: Approach A (LLM Summary) \u2014 the fastest to implement, works with any support workflow (email, Teams, ticketing system). The LLM-generated summary gives human agents enough context to take over efficiently.</p> <p>For Teams-centric organizations: Combine A + B \u2014 post the structured context card to a Teams support channel for visual triage, with the LLM summary included as a text section. Human agents see a scannable card in their Teams feed.</p> <p>For customer-facing agents: Approach C (Omnichannel) \u2014 the only approach that provides a true live chat transfer. Worth the investment for customer support scenarios where wait time and seamless experience are critical.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>M365 Copilot does not support Omnichannel handoff. If your agent is deployed to M365 Copilot, Approach C (Omnichannel) is not available. Use Approach A or B for M365 Copilot escalations.</p> <p>Warning</p> <p>Conversation transcript is not available as a single variable. There's no <code>System.Conversation.Transcript</code> variable in Copilot Studio. You can't pass the full conversation history to a flow. The LLM summary (Approach A) or Omnichannel's automatic transcript transfer (Approach C) are the workarounds.</p> <p>Note</p> <p>Track escalation reasons in Application Insights. Every escalation should log the reason (Gem 004's telemetry). Aggregate these reasons to identify gaps in the agent's capabilities \u2014 the most common escalation reason is your highest-priority improvement target.</p>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 009: Graceful Degradation and Fallback Chains \u2014 Escalation is the last level of the fallback cascade</li> <li>Gem 003: Tracing Agent Progress Before Response \u2014 \"Connecting you with a support agent...\" progress message</li> <li>Gem 007: Role-Based Feature Gating \u2014 Escalation routing may differ by role (admins get priority queue)</li> </ul>"},{"location":"gems/GEM-010-agent-to-human-handoff-with-context/#references","title":"References","text":"<ul> <li>Microsoft Learn: Hand off to a live agent</li> <li>Microsoft Learn: Omnichannel for Customer Service</li> <li>Microsoft Learn: Configure handoff to Omnichannel</li> <li>Microsoft Teams Incoming Webhooks</li> </ul> <p>Gem 010 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/","title":"Gem 011: Conversation Memory Within a Session","text":"<p>Make the agent remember what was said five turns ago \u2014 not just the last message.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#classification","title":"Classification","text":"Attribute Value Category Context &amp; State Complexity \u2b50\u2b50 to \u2b50\u2b50\u2b50 (depends on approach) Channels All Prerequisite Gems None (Gem 001 is complementary \u2014 cross-session vs within-session)"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#the-problem","title":"The Problem","text":"<p>Users expect multi-turn conversations. They build context over several messages:</p> <pre><code>Turn 1: \"What's our PTO policy?\"       \u2192 Agent responds with policy details\nTurn 2: \"How does carryover work?\"      \u2192 Agent should know this is about PTO\nTurn 3: \"What about for contractors?\"   \u2192 Agent should know this is about PTO carryover for contractors\nTurn 4: \"Compare that with France\"      \u2192 Agent should know: PTO carryover, contractors, US vs France\n</code></pre> <p>By turn 4, the user has established significant context: topic (PTO), subtopic (carryover), audience (contractors), and comparison (US vs France). If the agent forgets earlier turns, turn 4 becomes meaningless \u2014 \"Compare WHAT with France?\"</p> <p>Copilot Studio's generative orchestration handles basic conversation history, but it has limits:</p> <ul> <li>Context window truncation: In long conversations, early turns may drop out of the LLM's context window.</li> <li>Topic switching clears context: When the orchestrator routes to a different specialist agent, the new agent may not have the previous agent's conversation context.</li> <li>Variable scope: Topic variables reset when a new topic starts. Global variables persist but must be explicitly set.</li> <li>Generative orchestration opacity: You can't directly control how much conversation history the LLM sees or how it uses it.</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that maintains rich conversational context throughout a session:</p> <ul> <li>[ ] Multi-turn coherence: References from 5+ turns ago are correctly interpreted</li> <li>[ ] Topic switch resilience: Context survives when the orchestrator switches between specialist agents</li> <li>[ ] Explicit availability: Key context is stored in variables, not just implicit in conversation history</li> <li>[ ] Graceful degradation: If context is lost, the agent asks for clarification rather than giving a wrong answer</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-011-conversation-memory-within-a-session/#approach-a-global-variable-context-accumulator","title":"Approach A: Global Variable Context Accumulator","text":"<p>Summary: Maintain a global variable that accumulates key conversation facts as the conversation progresses. Each topic appends to it. Technique: <code>Global.ConversationContext</code> string variable, <code>SetVariable</code> nodes that append, agent instructions that reference it.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#how-it-works","title":"How It Works","text":"<pre><code>Turn 1: User asks about PTO\n  \u2192 Global.ConversationContext += \"Topic: PTO Policy. \"\n\nTurn 2: User asks about carryover\n  \u2192 Global.ConversationContext += \"Subtopic: Carryover rules. \"\n\nTurn 3: User specifies contractors\n  \u2192 Global.ConversationContext += \"Audience: Contractors. \"\n\nTurn 4: User says \"Compare that with France\"\n  \u2192 LLM reads Global.ConversationContext:\n    \"Topic: PTO Policy. Subtopic: Carryover rules. Audience: Contractors.\"\n  \u2192 Correctly interprets: Compare contractor PTO carryover rules between US and France\n</code></pre> <p>The accumulator is a simple string that grows throughout the conversation. The LLM uses it as supplementary context alongside the conversation history.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#implementation","title":"Implementation","text":"<p>Step 1: Initialize the context accumulator</p> <p>Via agent instructions:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Context-Aware Agent\ninstructions: |+\n  # Conversation Context Management\n\n  ## CRITICAL: Maintain Running Context\n  You have access to a running context variable that tracks key conversation facts.\n\n  After EVERY response, update the context by calling the \"UpdateContext\" action with:\n  - The current topic being discussed\n  - Any specific entities mentioned (people, dates, products, regions)\n  - Any constraints or filters applied (e.g., \"for contractors\", \"in France\")\n\n  ## Using Context\n  When interpreting user messages, ALWAYS check the running context:\n  - \"that\" / \"it\" / \"this\" \u2192 refers to the most recent topic in context\n  - \"Compare with X\" \u2192 compare the current context topic with X\n  - \"What about Y?\" \u2192 apply Y as a new filter to the current topic\n\n  ## Context Reset\n  If the user clearly starts a NEW topic (completely unrelated), reset the context.\n  If unsure, keep the existing context and ask: \"Are you still asking about [current topic]?\"\n</code></pre> <p>Step 2: Create an UpdateContext topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Update Conversation Context\n    includeInOnSelectIntent: false\n    triggerQueries: []\n  actions:\n    - kind: SetVariable\n      id: appendContext\n      variable: Global.ConversationContext\n      value: =Concatenate(If(IsBlank(Global.ConversationContext), \"\", Global.ConversationContext &amp; \" | \"), Topic.NewContextEntry)\n</code></pre> <p>Step 3: Reference context in knowledge searches</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: contextAwareSearch\n      variable: Topic.Answer\n      userInput: =Concatenate(System.Activity.Text, \" [Context: \", Global.ConversationContext, \"]\")\n      customInstructions: |\n        The user's message may reference previous conversation context provided in brackets.\n        Use this context to interpret ambiguous references like \"that\", \"it\", \"compare with\".\n</code></pre>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Simple string concatenation. No infrastructure. Maintainability \ud83d\udfe2 One global variable. Clear pattern. Channel Compatibility \ud83d\udfe2 Global variables work in all channels. Multi-turn Coherence \ud83d\udfe1 Works well for explicit facts. Doesn't capture nuances or sentiment. Topic Switch Resilience \ud83d\udfe2 Global variable survives topic switches and agent routing. Graceful Degradation \ud83d\udfe1 Context string can grow long and noisy over many turns."},{"location":"gems/GEM-011-conversation-memory-within-a-session/#limitations","title":"Limitations","text":"<ul> <li>String grows unbounded: After 20 turns, <code>Global.ConversationContext</code> becomes a long, noisy string. The LLM may struggle to prioritize recent context over old.</li> <li>No structure: A flat string doesn't distinguish \"active topic\" from \"mentioned 10 turns ago.\" Everything has equal weight.</li> <li>Manual maintenance: Each topic must explicitly append to the context. If you forget to update in one topic, context is lost.</li> <li>Token cost: Injecting the context string into every knowledge search adds tokens.</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#approach-b-llm-managed-conversation-summary","title":"Approach B: LLM-Managed Conversation Summary","text":"<p>Summary: Periodically ask the LLM to generate a concise summary of the conversation so far. Use this summary as context for subsequent turns. Technique: Prompt Tool for summarization, triggered every N turns or on topic switch, stored in global variable.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Every 3-5 turns&lt;/b&gt;&lt;br/&gt;(or on topic switch)\"]\n    B[\"&lt;b&gt;Prompt Tool&lt;/b&gt;&lt;br/&gt;Summarize the key facts&lt;br/&gt;from this conversation&lt;br/&gt;in 3-5 bullet points\"]\n    C[\"&lt;b&gt;Global.ConversationSummary =&lt;/b&gt;&lt;br/&gt;\u2022 Discussing PTO policy&lt;br/&gt;\u2022 Focus on carryover rules&lt;br/&gt;\u2022 Specific to contractors&lt;br/&gt;\u2022 Comparing US and France\"]\n    A --&gt; B --&gt; C</code></pre> <p>The LLM distills the conversation into key points, discarding noise and prioritizing active threads.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#implementation_1","title":"Implementation","text":"<p>Step 1: Create a conversation summarizer Prompt Tool</p> <pre><code>kind: PromptTool\nid: prompt_sessionSummarizer\ndisplayName: \"Session Context Summarizer\"\ndescription: \"Generates a concise summary of the current conversation for context preservation\"\ninstructions: |\n  Summarize the key facts established in this conversation.\n\n  Current conversation summary (may be empty): {currentSummary}\n  Latest user message: {latestMessage}\n  Agent's latest response topic: {responseTopic}\n\n  Generate an updated summary with:\n  - Main topic being discussed\n  - Key entities (people, dates, products, regions)\n  - Active filters or constraints\n  - Any pending questions or follow-ups\n\n  Format as bullet points. Maximum 5 bullets. \n  Remove outdated items from the previous summary if the topic has shifted.\n  Keep it under 100 words.\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: currentSummary\n    type: string\n  - name: latestMessage\n    type: string\n    required: true\n  - name: responseTopic\n    type: string\noutputs:\n  - name: summary\n    type: string\n</code></pre> <p>Step 2: Trigger summarization in agent instructions</p> <pre><code>instructions: |+\n  ## Context Management\n\n  Every 3 turns, or whenever the conversation topic shifts, call the \n  \"SessionContextSummarizer\" tool to update the running summary.\n\n  When interpreting ambiguous messages, reference the current summary \n  to resolve \"it\", \"that\", \"compare with\", etc.\n\n  If the summary is empty or stale, ask the user for clarification rather \n  than guessing.\n</code></pre> <p>Step 3: Inject summary into knowledge searches</p> <p>Same pattern as Approach A:</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: searchWithSummary\n      variable: Topic.Answer\n      userInput: =Concatenate(System.Activity.Text, \" [Conversation context: \", Global.ConversationSummary, \"]\")\n</code></pre>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Prompt Tool setup + trigger logic. More moving parts than Approach A. Maintainability \ud83d\udfe2 Summary prompt is easily adjustable. Channel Compatibility \ud83d\udfe2 Works in all channels. Multi-turn Coherence \ud83d\udfe2 LLM-generated summary captures nuance better than raw concatenation. Topic Switch Resilience \ud83d\udfe2 Summary survives in global variable. Outdated items are pruned by the LLM. Graceful Degradation \ud83d\udfe2 Summary has a fixed size (5 bullets max). Doesn't grow unbounded."},{"location":"gems/GEM-011-conversation-memory-within-a-session/#limitations_1","title":"Limitations","text":"<ul> <li>Double LLM cost: Every 3-5 turns, an extra LLM call generates the summary. Adds ~0.5-1 second latency and token cost.</li> <li>Summary staleness: Between summarization triggers, the summary may be 2-3 turns stale. The most recent turn isn't captured until the next summarization cycle.</li> <li>Summarization quality: The LLM may drop important context or over-compress. \"PTO carryover for contractors\" might become just \"PTO policy.\"</li> <li>Trigger timing: Deciding when to summarize (every N turns? on topic switch?) requires tuning per agent.</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#approach-c-explicit-entity-tracking-with-variables","title":"Approach C: Explicit Entity Tracking with Variables","text":"<p>Summary: Track specific conversation entities (current topic, active filters, mentioned entities) in dedicated global variables. Fully deterministic, no LLM dependency. Technique: Dedicated global variables per entity type, <code>SetVariable</code> nodes in each topic, structured context object.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#how-it-works_2","title":"How It Works","text":"<pre><code>Global.CurrentTopic = \"PTO Policy\"\nGlobal.ActiveSubtopic = \"Carryover Rules\"\nGlobal.ActiveFilters = \"Contractors, US\"\nGlobal.ComparisonTarget = \"France\"\nGlobal.MentionedEntities = \"PTO, Carryover, Contractors\"\n</code></pre> <p>Each variable has a clear purpose. Topics explicitly set the relevant variables. The agent reads them when interpreting ambiguous queries.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#implementation_2","title":"Implementation","text":"<p>Step 1: Define the entity tracking variables</p> Variable Type Purpose Example <code>Global.CurrentTopic</code> String Primary conversation topic \"PTO Policy\" <code>Global.ActiveSubtopic</code> String Current subtopic within that topic \"Carryover Rules\" <code>Global.ActiveFilters</code> String Active filters or constraints \"Contractors, US\" <code>Global.ComparisonTarget</code> String If comparing, what's being compared \"France\" <code>Global.LastQuestionType</code> String Type of last question \"Comparison\", \"Factual\", \"Procedural\" <p>Step 2: Set variables in each topic</p> <pre><code>    # In the PTO Policy topic\n    - kind: SetVariable\n      id: setTopic\n      variable: Global.CurrentTopic\n      value: \"PTO Policy\"\n\n    - kind: SetVariable\n      id: setSubtopic\n      variable: Global.ActiveSubtopic\n      value: \"General\"\n\n    # When user asks about carryover\n    - kind: SetVariable\n      id: updateSubtopic\n      variable: Global.ActiveSubtopic\n      value: \"Carryover Rules\"\n</code></pre> <p>Step 3: Use variables in agent instructions</p> <pre><code>instructions: |+\n  ## Context Variables\n  You have access to these conversation context variables:\n  - CurrentTopic: The main topic being discussed\n  - ActiveSubtopic: The specific aspect within that topic\n  - ActiveFilters: Audience, region, or constraint filters\n  - ComparisonTarget: If the user is comparing, what they're comparing against\n\n  When interpreting ambiguous messages:\n  - \"What about France?\" \u2192 Set ComparisonTarget = \"France\", keep CurrentTopic and ActiveSubtopic\n  - \"For contractors\" \u2192 Add \"Contractors\" to ActiveFilters\n  - \"Never mind, new question\" \u2192 Clear all context variables\n</code></pre>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 More variables to manage. Every topic must set them correctly. Maintainability \ud83d\udfe1 Many variables to track. Risk of staleness if a topic forgets to update. Channel Compatibility \ud83d\udfe2 Global variables work everywhere. Multi-turn Coherence \ud83d\udfe2 Deterministic \u2014 exactly what you track is what's available. No LLM interpretation needed. Topic Switch Resilience \ud83d\udfe2 Global variables survive topic switches. Graceful Degradation \ud83d\udfe2 Fixed number of variables. No unbounded growth. Explicit \"unknown\" state."},{"location":"gems/GEM-011-conversation-memory-within-a-session/#limitations_2","title":"Limitations","text":"<ul> <li>High maintenance: Every topic must correctly set/update 3-5 global variables. Miss one, and context is stale.</li> <li>Rigid schema: Predefined variables can't capture unexpected context. If the user discusses something your variables don't cover, it's lost.</li> <li>No conversation nuance: Variables capture facts but not tone, sentiment, or complex relationships between entities.</li> <li>Doesn't scale: Useful for focused agents (5-10 topics). For 50+ topics each with different context needs, the variable matrix becomes unmanageable.</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Accumulator Approach B: LLM Summary Approach C: Entity Tracking Implementation Effort \ud83d\udfe2 Low (30 min) \ud83d\udfe1 Medium (1-2 hours) \ud83d\udfe1 Medium (1-2 hours) Context Quality \ud83d\udfe1 Raw, noisy \ud83d\udfe2 Distilled, prioritized \ud83d\udfe2 Precise, deterministic Unbounded Growth \ud83d\udd34 Grows every turn \ud83d\udfe2 Fixed size (5 bullets) \ud83d\udfe2 Fixed variable count LLM Cost \ud83d\udfe2 Zero extra \ud83d\udfe1 Periodic LLM calls \ud83d\udfe2 Zero extra Flexibility \ud83d\udfe2 Captures anything \ud83d\udfe2 LLM adapts to any topic \ud83d\udd34 Only predefined entities Best When... Quick, pragmatic solution Long conversations, diverse topics Focused agent, few topic areas"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#recommended-approach","title":"Recommended Approach","text":"<p>For most agents: Approach B (LLM Summary) \u2014 the best balance of quality and maintainability. The LLM handles the hard part (deciding what's important), the summary stays compact, and it works across any topic structure.</p> <p>For focused agents (5-10 topics): Approach C (Entity Tracking) \u2014 when you know exactly what context matters, explicit variables are deterministic and free from LLM cost. Best for narrow-domain agents.</p> <p>For quick implementation: Approach A (Accumulator) \u2014 drop it in as a global string. Works immediately, good enough for prototypes. Graduate to B or C when the accumulator gets noisy.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Generative orchestration manages its own conversation history \u2014 but you can't see or control it. The LLM sees some conversation history automatically, but you don't control how many turns or how it's truncated. For critical multi-turn scenarios, don't rely on implicit history \u2014 use explicit context variables.</p> <p>Warning</p> <p>Global variable size is limited. While there's no documented hard limit, very long strings (thousands of characters) in global variables may cause issues. Keep <code>Global.ConversationContext</code> or <code>Global.ConversationSummary</code> under 500 characters.</p> <p>Note</p> <p>Topic variables reset when a new topic starts. Only <code>Global.*</code> variables survive topic switches. If you track context in <code>Topic.*</code> variables, it vanishes when the orchestrator routes to a different topic.</p>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Gem 001 is cross-session (between conversations); this Gem is within-session (within one conversation). Complementary patterns.</li> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Persona context can be combined with conversation context for richer interpretation.</li> </ul>"},{"location":"gems/GEM-011-conversation-memory-within-a-session/#references","title":"References","text":"<ul> <li>Microsoft Learn: Variables in Copilot Studio</li> <li>Microsoft Learn: Generative orchestration</li> <li>Prompt engineering: Chain of thought</li> </ul> <p>Gem 011 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/","title":"Gem 012: Cost Estimation and Token Budget Management","text":"<p>Know what your agent costs per conversation \u2014 and control it before the invoice surprises you.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#classification","title":"Classification","text":"Attribute Value Category Performance Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 telemetry setup + budget enforcement) Channels All (cost monitoring is backend-only) Prerequisite Gems Gem 004 (Application Insights telemetry pipeline)"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#the-problem","title":"The Problem","text":"<p>Copilot Studio agents consume AI capacity with every interaction. Each generative response, each knowledge search, each Prompt Tool invocation uses tokens. For agents with hundreds or thousands of daily conversations, costs accumulate:</p> <ul> <li>No visibility: Copilot Studio doesn't show per-conversation or per-topic token costs in the UI. You see an aggregate bill but can't break it down.</li> <li>Persona-driven cost variance: An Engineer persona getting detailed technical responses costs 2-3x more tokens than a Manager persona getting executive summaries (Gem 002).</li> <li>Generative answers are expensive: A single <code>SearchAndSummarizeContent</code> call can consume 2,000-4,000 tokens (search context + response generation). Multiply by 10 turns per conversation \u00d7 500 conversations/day.</li> <li>Prompt Tool double-dip: Using a Prompt Tool (Gem 002's Approach C, Gem 011's Approach B) adds a separate LLM call per invocation. Two Prompt Tools + one generative answer = 3 LLM calls per turn.</li> <li>Budget surprises: An agent that costs $50/month in UAT may cost $500/month in production due to higher volume and longer conversations.</li> </ul> <p>The fundamental challenge: you can't optimize what you can't measure. And you can't set guardrails without knowing your cost drivers.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>Cost visibility and control for your agent:</p> <ul> <li>[ ] Per-conversation cost tracking: Know how much each conversation costs in tokens/dollars</li> <li>[ ] Cost attribution: Identify which topics, agents, or features drive the most cost</li> <li>[ ] Budget guardrails: Set limits that prevent runaway costs without degrading user experience</li> <li>[ ] Trend monitoring: Track cost changes over time as the agent evolves</li> <li>[ ] Optimization actionability: Data that helps you decide WHERE to optimize</li> </ul>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#approach-a-application-insights-token-tracking","title":"Approach A: Application Insights Token Tracking","text":"<p>Summary: Use <code>LogCustomTelemetryEvent</code> to log estimated token counts at every LLM interaction point. Query and visualize with KQL. Technique: Telemetry events with token estimates, Application Insights dashboard, KQL queries for cost attribution.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Every LLM call&lt;/b&gt;&lt;br/&gt;generative answer, prompt tool,&lt;br/&gt;agent routing\"]\n    B[\"&lt;b&gt;LogCustomTelemetryEvent&lt;/b&gt;&lt;br/&gt;\u2022 Estimated input tokens (prompt + context)&lt;br/&gt;\u2022 Estimated output tokens (response length)&lt;br/&gt;\u2022 Topic name, agent name&lt;br/&gt;\u2022 Conversation ID\"]\n    C[\"Application Insights \u2192 KQL queries \u2192 Cost dashboard\"]\n    A --&gt; B --&gt; C</code></pre> <p>Token counts are estimated using response length heuristics (1 token \u2248 4 characters for English text). Not exact, but within 10-15% of actual billing.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#implementation","title":"Implementation","text":"<p>Step 1: Add token tracking to generative answer nodes</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: searchKnowledge\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n\n    # Estimate tokens from response length\n    - kind: SetVariable\n      id: estimateTokens\n      variable: init:Topic.EstimatedOutputTokens\n      value: =RoundUp(Len(Topic.Answer) / 4, 0)\n\n    # Log token usage\n    - kind: LogCustomTelemetryEvent\n      id: logTokenUsage\n      eventName: TokenUsage\n      properties: \"={CallType: \\\"GenerativeAnswer\\\", TopicName: \\\"SupportQuery\\\", InputEstimate: 2000, OutputEstimate: Topic.EstimatedOutputTokens, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 2: Add tracking to Prompt Tool invocations</p> <pre><code>    - kind: InvokePrompt\n      id: classifyIntent\n      promptId: prompt_intentClassifier\n      inputs:\n        userMessage: =System.Activity.Text\n      outputVariable: Topic.Classification\n\n    - kind: LogCustomTelemetryEvent\n      id: logPromptToolTokens\n      eventName: TokenUsage\n      properties: \"={CallType: \\\"PromptTool\\\", ToolName: \\\"IntentClassifier\\\", InputEstimate: 500, OutputEstimate: 50, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 3: KQL queries for cost analysis</p> <pre><code>// Daily token consumption\ncustomEvents\n| where name == \"TokenUsage\"\n| where timestamp &gt; ago(7d)\n| extend InputTokens = toint(customDimensions.InputEstimate)\n| extend OutputTokens = toint(customDimensions.OutputEstimate)\n| extend TotalTokens = InputTokens + OutputTokens\n| summarize DailyTokens = sum(TotalTokens), CallCount = count() by bin(timestamp, 1d)\n| render timechart\n\n// Cost by topic (find expensive topics)\ncustomEvents\n| where name == \"TokenUsage\"\n| where timestamp &gt; ago(30d)\n| extend TopicName = tostring(customDimensions.TopicName)\n| extend TotalTokens = toint(customDimensions.InputEstimate) + toint(customDimensions.OutputEstimate)\n| summarize TotalTokens = sum(TotalTokens), Calls = count() by TopicName\n| extend AvgTokensPerCall = TotalTokens / Calls\n| order by TotalTokens desc\n\n// Cost per conversation\ncustomEvents\n| where name == \"TokenUsage\"\n| where timestamp &gt; ago(7d)\n| extend ConvId = tostring(customDimensions.ConversationId)\n| extend TotalTokens = toint(customDimensions.InputEstimate) + toint(customDimensions.OutputEstimate)\n| summarize ConvTokens = sum(TotalTokens), Turns = count() by ConvId\n| summarize AvgTokensPerConv = avg(ConvTokens), MaxTokensPerConv = max(ConvTokens), AvgTurns = avg(Turns)\n</code></pre> <p>Step 4: Estimate dollar cost</p> <pre><code>// Approximate cost (adjust pricing per your model)\nlet inputPricePer1K = 0.0015;  // GPT-4o-mini input\nlet outputPricePer1K = 0.006;  // GPT-4o-mini output\ncustomEvents\n| where name == \"TokenUsage\"\n| where timestamp &gt; ago(30d)\n| extend InputTokens = toint(customDimensions.InputEstimate)\n| extend OutputTokens = toint(customDimensions.OutputEstimate)\n| extend EstCost = (InputTokens / 1000.0 * inputPricePer1K) + (OutputTokens / 1000.0 * outputPricePer1K)\n| summarize TotalCost = sum(EstCost), TotalConversations = dcount(tostring(customDimensions.ConversationId))\n| extend CostPerConversation = TotalCost / TotalConversations\n</code></pre>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires App Insights + telemetry events at every LLM call point. Maintainability \ud83d\udfe2 KQL queries are reusable. Dashboard updates automatically. Channel Compatibility \ud83d\udfe2 Telemetry is backend \u2014 works in all channels. Cost Attribution \ud83d\udfe2 Per-topic, per-tool, per-conversation breakdown. Accuracy \ud83d\udfe1 Estimates within 10-15% of actual billing. Not exact. Budget Guardrails \ud83d\udd34 Monitoring only \u2014 doesn't prevent overspend."},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#limitations","title":"Limitations","text":"<ul> <li>Estimation, not measurement: Token counts are derived from character length heuristics. Actual billing depends on the tokenizer, which varies by model.</li> <li>No input token visibility: You can estimate output tokens from response length, but input tokens (system prompt + conversation history + search context) are harder to estimate from YAML alone.</li> <li>Retrospective: You see costs after they happen, not in real-time. Can't prevent a costly conversation while it's happening.</li> <li>App Insights cost: The telemetry itself costs money at scale. High-volume agents generate significant telemetry data.</li> </ul>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#approach-b-response-length-capping-via-instructions","title":"Approach B: Response Length Capping via Instructions","text":"<p>Summary: Control token cost by instructing the LLM to limit response length. Shorter responses = fewer output tokens = lower cost. Technique: Agent instructions with length constraints, persona-based depth (Gem 002), progressive disclosure (offer more detail on request).</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#how-it-works_1","title":"How It Works","text":"<pre><code>Instructions: \"Keep responses under 200 words unless the user asks for more detail.\"\n\nUser: \"What's the PTO policy?\"\nAgent: \"Full-time employees get 25 days PTO per year, with 5 days carryover.\n        Would you like more details about carryover rules or part-time entitlements?\"\n        (47 words \u2014 ~63 tokens)\n\nvs. uncontrolled:\nAgent: \"The Paid Time Off (PTO) policy at Contoso applies to all full-time employees...\n        [detailed explanation covering carryover, accrual rates, blackout periods,\n        part-time rules, contractor exclusions, regional variations...]\"\n        (300+ words \u2014 ~400+ tokens)\n</code></pre> <p>By defaulting to concise responses and offering detail on demand, you can cut token usage by 40-60% without degrading user experience.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#implementation_1","title":"Implementation","text":"<p>Step 1: Add length constraints to agent instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Cost-Optimized Agent\ninstructions: |+\n  # Response Guidelines\n\n  ## Default Response Length\n  - Keep responses to **100-200 words** unless the user explicitly asks for more\n  - Lead with the direct answer in the first sentence\n  - Follow with 2-3 key supporting points\n  - End with: \"Would you like more details about [specific aspect]?\"\n\n  ## When to Provide Longer Responses\n  - User explicitly asks: \"explain in detail\", \"tell me everything\", \"full policy\"\n  - Comparison questions (need side-by-side data)\n  - Step-by-step procedures (can't be shortened without losing steps)\n\n  ## Response Format Efficiency\n  - Use bullet points instead of paragraphs (more info, fewer words)\n  - Use tables for comparisons (structured, compact)\n  - Avoid repetitive phrasing (\"As I mentioned earlier...\")\n  - Don't restate the question in the answer\n</code></pre> <p>Step 2: Persona-based length control (link to Gem 002)</p> <pre><code>  ## Persona-Adjusted Length\n\n  ### Manager Persona\n  - Maximum 100 words. Bottom-line first.\n  - Pattern: [Answer] + [1-2 bullets] + \"Want more detail?\"\n\n  ### Engineer Persona  \n  - Maximum 300 words. Include code/config when relevant.\n  - Only expand beyond 300 if the query explicitly requires it.\n\n  ### NewHire Persona\n  - Maximum 250 words. Step-by-step, but keep each step concise.\n  - Use \"\ud83d\udca1 Tip:\" sparingly (one per response max).\n</code></pre> <p>Step 3: Knowledge search instruction optimization</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: efficientSearch\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n      customInstructions: |\n        Provide a concise answer in under 150 words.\n        If the knowledge source contains extensive information, summarize the key points\n        and offer to provide specific sections on request.\n        Do NOT reproduce entire document sections \u2014 extract only the relevant facts.\n</code></pre>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions only. 15 minutes to implement. Maintainability \ud83d\udfe2 Adjust word limits in instructions. Easy to tune. Channel Compatibility \ud83d\udfe2 Works in all channels. Cost Reduction \ud83d\udfe2 40-60% output token reduction. Significant for high-volume agents. Accuracy N/A Doesn't measure cost \u2014 reduces it. User Experience \ud83d\udfe1 Concise answers are often better. But some users want detail upfront and find \"Would you like more?\" annoying."},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#limitations_1","title":"Limitations","text":"<ul> <li>LLM compliance is approximate: Instructing \"under 200 words\" doesn't guarantee exactly 200 words. Responses may be 150-250. The LLM follows the spirit, not the letter.</li> <li>Not all responses can be shortened: Comparison tables, step-by-step guides, and explanations of complex policies have a minimum viable length.</li> <li>User friction: Power users who always want detail may find the \"Want more detail?\" pattern tedious. Persona-based length (Step 2) mitigates this.</li> <li>Doesn't address input tokens: This only reduces output tokens. Input tokens (system prompt, conversation history, search context) are unaffected.</li> </ul>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#approach-c-conversation-turn-limits","title":"Approach C: Conversation Turn Limits","text":"<p>Summary: Set a maximum number of turns per conversation. After the limit, gracefully end the conversation or suggest starting fresh. Technique: Global turn counter variable, conditional check per turn, graceful shutdown message.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#how-it-works_2","title":"How It Works","text":"<pre><code>Turn 1: Counter = 1  \u2705\nTurn 2: Counter = 2  \u2705\n...\nTurn 15: Counter = 15  \u2705\nTurn 16: Counter = 16  \u2192 Approaching limit\n  Agent: \"We've been chatting for a while! I can answer 4 more questions\n          in this session. For longer research, consider starting a new conversation.\"\nTurn 20: Counter = 20  \u2192 Limit reached\n  Agent: \"We've reached the end of this session. Start a new conversation\n          to continue \u2014 I'll remember your preferences! (Gem 001)\"\n</code></pre> <p>This is a blunt instrument but effective for cost control. Each turn has an approximate token cost, so capping turns caps total cost.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#implementation_2","title":"Implementation","text":"<p>Step 1: Increment counter on every turn</p> <p>Via agent instructions:</p> <pre><code>instructions: |+\n  ## Turn Management\n  Track the conversation turn count. Increment it with every user message.\n\n  - At turn 15: Add a note: \"I can help with a few more questions in this session.\"\n  - At turn 20: Gracefully close: \"Let's start fresh for your next questions. \n    Your preferences are saved so we'll pick right up!\"\n\n  This ensures each conversation stays focused and efficient.\n</code></pre> <p>Or via explicit topic logic:</p> <pre><code>    # Increment turn counter (add to every topic entry)\n    - kind: SetVariable\n      id: incrementTurn\n      variable: Global.TurnCount\n      value: =If(IsBlank(Global.TurnCount), 1, Global.TurnCount + 1)\n\n    # Check if approaching limit\n    - kind: ConditionGroup\n      id: checkTurnLimit\n      conditions:\n        - id: atLimit\n          condition: =Global.TurnCount &gt;= 20\n          actions:\n            - kind: SendActivity\n              id: sessionEnd\n              activity:\n                text:\n                  - \"We've had a great conversation! To keep things efficient, let's start a new session for your next questions.\\n\\n\u2705 Your preferences and context are saved.\\n\ud83d\udd04 Start a new conversation to continue.\"\n            - kind: EndDialog\n              id: endSession\n              clearTopicQueue: true\n        - id: nearLimit\n          condition: =Global.TurnCount &gt;= 16\n          actions:\n            - kind: SendActivity\n              id: nearLimitNotice\n              activity:\n                text:\n                  - \"\ud83d\udca1 _I can help with {20 - Global.TurnCount} more questions in this session._\"\n</code></pre>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Simple counter + condition. Maintainability \ud83d\udfe2 One number to adjust (turn limit). Channel Compatibility \ud83d\udfe2 Works in all channels. Cost Control \ud83d\udfe2 Hard cap on per-conversation cost. Predictable. User Experience \ud83d\udd34 Cutting off conversations is frustrating. Users may feel punished. Cost Attribution \ud83d\udd34 Doesn't tell you WHY conversations are expensive \u2014 just limits them."},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#limitations_2","title":"Limitations","text":"<ul> <li>User frustration: Being told \"session over\" feels like hitting a wall. Users who need 25 turns for a legitimate complex query will be annoyed.</li> <li>Arbitrary limit: 20 turns is reasonable for some agents, too low for others. Finding the right limit requires cost data (Approach A).</li> <li>No cost granularity: All turns are treated equally. A turn with a Prompt Tool + generative answer costs 3x more than a simple SendActivity turn.</li> <li>Blunt instrument: Limits total activity rather than targeting the expensive parts.</li> </ul>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Token Tracking Approach B: Response Capping Approach C: Turn Limits Implementation Effort \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe2 Low (15 min) \ud83d\udfe2 Low (30 min) Cost Visibility \ud83d\udfe2 Full attribution \ud83d\udd34 None \ud83d\udd34 None Cost Reduction \ud83d\udd34 Monitoring only \ud83d\udfe2 40-60% output reduction \ud83d\udfe2 Hard cap per conversation User Impact \ud83d\udfe2 None (invisible) \ud83d\udfe1 Slightly less detailed \ud83d\udd34 Session cutoff Actionability \ud83d\udfe2 Data-driven optimization \ud83d\udfe1 Global reduction only \ud83d\udd34 Blunt limit Best When... You need to understand costs You need to reduce costs now You need hard budget control"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#recommended-approach","title":"Recommended Approach","text":"<p>Layer A + B for most scenarios:</p> <ol> <li>Start with Approach B (response capping) \u2014 immediate cost reduction with zero infrastructure. Add length constraints to your instructions today.</li> <li>Add Approach A (token tracking) \u2014 understand where your costs actually come from. Use the data to optimize specific topics, remove underused Prompt Tools, or adjust persona depth levels.</li> <li>Add Approach C (turn limits) only as a safety net \u2014 set the limit high (30-40 turns) so it only triggers for truly runaway conversations.</li> </ol> <pre><code>Immediate: Approach B \u2014 cap default response length (40-60% savings)\nWeek 1:    Approach A \u2014 instrument telemetry, build cost dashboard\nOngoing:   Use Approach A data to fine-tune Approach B limits per topic\nSafety:    Approach C \u2014 soft limit at 30 turns (catches outliers)\n</code></pre>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Copilot Studio doesn't expose actual token counts. There's no <code>System.TokensUsed</code> variable. All token tracking is estimation based on response character length.</p> <p>Warning</p> <p>Copilot Studio AI capacity is billed as \"messages\" not tokens in some licensing models. Check your specific licensing. Some plans use message-based billing (per conversation or per monthly active user). Token-level optimization may not directly reduce your bill under message-based plans.</p> <p>Note</p> <p>System prompt tokens are invisible but significant. Your agent instructions, persona definitions, and conversation history consume input tokens on every turn. A 2,000-word instruction set (Gem 002's branched instructions) uses ~2,500 tokens of input on every LLM call. This is your \"fixed cost per turn.\"</p> <p>Note</p> <p>Shorter responses often improve user satisfaction. Research shows users prefer concise, actionable answers over long explanations. Response capping (Approach B) frequently improves both cost AND user experience.</p>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Manager persona (concise) costs less than Engineer persona (detailed). Token budgets can be set per persona.</li> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Application Insights pipeline (Approach B in Gem 004) is the same infrastructure used for token tracking here.</li> <li>Gem 011: Conversation Memory Within a Session \u2014 Approach B (LLM summary) adds token cost. Track it to understand the trade-off.</li> </ul>"},{"location":"gems/GEM-012-cost-estimation-and-token-budget-management/#references","title":"References","text":"<ul> <li>OpenAI Tokenizer \u2014 Estimate tokens from text</li> <li>Azure OpenAI pricing</li> <li>Microsoft Learn: Copilot Studio licensing</li> <li>Microsoft Learn: Application Insights for Copilot Studio</li> </ul> <p>Gem 012 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/","title":"Gem 013: Testing Strategies for Multi-Agent Architectures","text":"<p>How do you know your orchestrator routes correctly, your specialists answer accurately, and your fallbacks actually work?</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#classification","title":"Classification","text":"Attribute Value Category Observability Complexity \u2b50\u2b50\u2b50 to \u2b50\u2b50\u2b50\u2b50 (depends on automation level) Channels All (testing should cover every target channel) Prerequisite Gems Gem 004 (debug mode for test instrumentation)"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#the-problem","title":"The Problem","text":"<p>Testing a single-topic agent is straightforward: type a trigger phrase, check the response, verify variables. But multi-agent architectures \u2014 orchestrator + N specialist agents \u2014 introduce combinatorial complexity:</p> <ul> <li>Routing correctness: Does the orchestrator send \"What's the PTO policy in France?\" to the France specialist, not the US specialist? What about \"Compare France and US PTO\"?</li> <li>Knowledge accuracy: Does each specialist return factually correct answers from its knowledge source? Does it cite the right documents?</li> <li>Edge case handling: What happens with ambiguous queries? Unknown regions? Empty knowledge results? Mixed-language input?</li> <li>Multi-turn consistency: Does context survive when the user asks a follow-up that requires the same specialist? What if they switch topics?</li> <li>Channel variance: Does the agent behave the same in Teams, Web Chat, and M365 Copilot? (Hint: it doesn't \u2014 see Gotchas Compendium \u2014 Channel Limitations.)</li> </ul> <p>The Test Canvas in Copilot Studio helps with individual topic testing, but it doesn't support systematic, repeatable evaluation across dozens of test scenarios. Manual testing is tedious, inconsistent, and doesn't scale.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A testing practice that catches issues before users do:</p> <ul> <li>[ ] Repeatable: Same test suite can be run after every change to verify nothing broke</li> <li>[ ] Comprehensive: Covers routing, knowledge, edge cases, and multi-turn scenarios</li> <li>[ ] Scored: Each test produces a numeric score for objective quality tracking</li> <li>[ ] Efficient: Testing a full suite takes &lt;30 minutes, not a full day</li> <li>[ ] Actionable: Failed tests clearly indicate what broke and where</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#approach-a-structured-manual-test-script","title":"Approach A: Structured Manual Test Script","text":"<p>Summary: Define a standardized set of test cases organized by category. Execute manually in the Test Canvas or target channel. Score each case against a rubric. Technique: Markdown test script document, scoring rubric, manual execution, spreadsheet tracking.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Test Script&lt;/b&gt;&lt;br/&gt;(Markdown document)\"]\n    subgraph Categories\n        C1[\"Category 1: Routing Tests (10 cases)\"]\n        C2[\"Category 2: Knowledge Tests (10 cases)\"]\n        C3[\"Category 3: Edge Cases (10 cases)\"]\n        C4[\"Category 4: Multi-Turn (5 cases)\"]\n        C5[\"Category 5: Channel-Specific (5 cases)\"]\n    end\n    A --&gt; Categories\n    Categories --&gt; B[\"&lt;b&gt;Manual execution&lt;/b&gt;&lt;br/&gt;in Test Canvas / target channel\"]\n    B --&gt; D[\"Score each case (0-9 rubric)\"]\n    D --&gt; E[\"&lt;b&gt;Aggregate:&lt;/b&gt;&lt;br/&gt;Agent scores 7.2/9 \u2014&lt;br/&gt;3 failures in routing\"]</code></pre>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#implementation","title":"Implementation","text":"<p>Step 1: Define test categories</p> Category Purpose Typical Count Routing Accuracy Does the orchestrator select the correct specialist? 10-15 cases Knowledge Retrieval Does the specialist find and cite the correct source? 10-15 cases Edge Cases Ambiguous, missing, sensitive, or malformed input 5-10 cases Multi-Turn Context retention across turns 5 cases Channel-Specific Channel-dependent behavior differences 3-5 per channel <p>Step 2: Create test case template</p> <pre><code>### Test Case: [TC-NNN]\n**Category**: [Routing | Knowledge | Edge Case | Multi-Turn | Channel]\n**Priority**: [P1 Critical | P2 Important | P3 Nice-to-have]\n\n**Setup**: [Any prerequisites \u2014 e.g., \"User in France region\"]\n**Input**: \"[Exact message to send]\"\n**Expected Agent**: [Which specialist should handle this]\n**Expected Behavior**: [What the response should contain]\n**Expected Source**: [Which document should be cited]\n\n**Scoring Rubric** (9 points):\n| Criterion | Points | Description |\n|---|---|---|\n| Routing (0-2) | | Correct specialist selected |\n| Citation (0-2) | | Specific document cited |\n| Accuracy (0-2) | | Information is factually correct |\n| Completeness (0-2) | | All relevant info included |\n| Tone (0-1) | | Appropriate language and style |\n\n**Result**: [Score] / 9\n**Notes**: [Observed behavior, issues]\n</code></pre> <p>Step 3: Build a concrete test suite (example for HR multi-agent)</p> <pre><code>## Routing Tests\n\n### TC-001: Auto-route to France specialist\n**Input**: \"Quelle est la politique de cong\u00e9s parentaux ?\"\n**Expected Agent**: FranceHRSpecialist\n**Expected**: Response in French about parental leave\n\n### TC-002: Auto-route to US specialist\n**Input**: \"How many PTO days do I get?\"\n**Expected Agent**: USHRSpecialist\n**Expected**: Response about US PTO entitlements\n\n### TC-003: Explicit region override\n**Input**: \"What is the France policy for sick leave?\"\n**Expected Agent**: FranceHRSpecialist (France detected in query, overrides user's US profile)\n\n### TC-004: Cross-region comparison\n**Input**: \"Compare France and US vacation policies\"\n**Expected Agent**: ComparisonSpecialist (has access to all regions)\n\n### TC-005: Unknown region handling\n**Input**: \"What's the PTO policy in Brazil?\"\n**Expected Agent**: GlobalHRSpecialist (fallback)\n**Expected**: Acknowledge Brazil isn't specifically covered, provide global policy\n\n## Knowledge Tests\n\n### TC-010: Specific policy lookup\n**Input**: \"How many days of paternity leave in France?\"\n**Expected Source**: France-Parental-Leave-Policy.docx\n**Expected**: Exact number of days, cited from document\n\n### TC-011: Table data retrieval\n**Input**: \"What's the PTO entitlement for 5-year employees?\"\n**Expected Source**: PTO-Entitlements-Table.docx\n**Expected**: Correct number from the table row matching 5 years\n\n## Edge Cases\n\n### TC-020: Ambiguous query\n**Input**: \"What about leave?\"\n**Expected**: Agent asks for clarification (which type of leave? which region?)\n\n### TC-021: Query outside knowledge\n**Input**: \"What's Contoso's stock price?\"\n**Expected**: Honest \"I don't have that information\" \u2014 not a hallucinated answer\n\n### TC-022: Sensitive information request\n**Input**: \"What's my manager's salary?\"\n**Expected**: Decline with appropriate response about confidentiality\n\n## Multi-Turn Tests\n\n### TC-030: Context retention\n**Turn 1**: \"What's the PTO policy?\"\n**Turn 2**: \"How does carryover work?\"\n**Turn 3**: \"What about for contractors?\"\n**Expected**: Turn 3 should address PTO carryover for contractors (context from turns 1-2)\n</code></pre> <p>Step 4: Track results in a scoring spreadsheet</p> TC Category Score Pass/Fail Notes Date TC-001 Routing 9/9 \u2705 2026-02-17 TC-002 Routing 7/9 \u26a0\ufe0f Routed correctly but slow 2026-02-17 TC-003 Routing 4/9 \u274c Routed to US instead of France 2026-02-17"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Markdown document + manual execution. No tooling needed. Maintainability \ud83d\udfe2 Add/edit test cases in the Markdown file. Comprehensiveness \ud83d\udfe2 Covers all categories. Extensible. Efficiency \ud83d\udd34 Manual execution: 40 test cases \u00d7 2 min each = 80 minutes. Tedious for frequent testing. Scoring Objectivity \ud83d\udfe1 Rubric helps, but human scoring introduces subjectivity. Two testers may score differently. Actionability \ud83d\udfe2 Failed tests pinpoint the specific scenario and expected vs actual behavior."},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#limitations","title":"Limitations","text":"<ul> <li>Time-consuming: Running 40 test cases manually takes 1-2 hours. Not practical for every change.</li> <li>Human subjectivity: Scoring \"Completeness: 0-2\" depends on the tester's judgment. Calibrate with examples.</li> <li>No regression detection: Without automation, you might skip tests and miss regressions.</li> <li>Single-channel: You test in one channel at a time. Testing across 3 channels triples the effort.</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#approach-b-automated-routing-validation-via-power-automate","title":"Approach B: Automated Routing Validation via Power Automate","text":"<p>Summary: Create a Power Automate flow that sends test messages to the agent via the Direct Line API and checks the response against expected patterns. Technique: Power Automate scheduled flow, Copilot Studio Direct Line API, response pattern matching, results logging.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Scheduled Power Automate Flow&lt;/b&gt;&lt;br/&gt;(daily or on-demand)\"]\n    B[\"&lt;b&gt;For each test case:&lt;/b&gt;&lt;br/&gt;1. Send message via Direct Line API&lt;br/&gt;2. Receive agent response&lt;br/&gt;3. Check expected keywords&lt;br/&gt;4. Check expected agent selected&lt;br/&gt;5. Log result (pass/fail + response)\"]\n    C[\"Results stored in&lt;br/&gt;SharePoint list / Dataverse table\"]\n    D[\"&lt;b&gt;Teams notification:&lt;/b&gt;&lt;br/&gt;Test suite: 37/40 passed (92.5%)\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre> <p>This approach automates the execution of test cases, but validation is limited to keyword/pattern matching (not semantic understanding).</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#implementation_1","title":"Implementation","text":"<p>Step 1: Set up Direct Line API access</p> <p>Copilot Studio agents can be accessed via the Bot Framework Direct Line API:</p> <ol> <li>Get the agent's Direct Line token from Copilot Studio settings</li> <li>Use HTTP actions in Power Automate to send messages and receive responses</li> </ol> <p>Step 2: Define test cases as a data table</p> <p>Store test cases in a SharePoint list or Dataverse table:</p> TestId Category Input ExpectedKeywords ExpectedAgent Priority TC-001 Routing \"PTO policy in France\" \"cong\u00e9s,jours,France\" FranceHR P1 TC-002 Routing \"US vacation days\" \"PTO,days,vacation\" USHR P1 TC-010 Knowledge \"paternity leave days France\" \"paternity,days,policy\" FranceHR P1 <p>Step 3: Build the test runner flow</p> <pre><code>Trigger: Manual or Scheduled (daily at 6 AM)\n\nAction: Get Items (test cases from SharePoint)\n\nFor Each test case:\n  Action: HTTP POST to Direct Line API\n    Start conversation \u2192 Send message \u2192 Get response\n\n  Action: Check keywords\n    For each expected keyword: contains(response, keyword)?\n\n  Action: Calculate score\n    Score = matched keywords / total keywords * 100\n\n  Action: Update test results\n    Write: TestId, Score, ActualResponse, Timestamp, Pass/Fail\n\nEnd For Each\n\nAction: Send Teams notification\n  \"Test run complete: {passCount}/{totalCount} passed ({passPercent}%)\"\n  \"Failures: {list of failed TC IDs}\"\n</code></pre> <p>Step 4: Results dashboard</p> <p>Query test results for trend tracking:</p> <pre><code>Test Results (SharePoint List)\n\u2502\n\u251c\u2500\u2500 Last Run: 2026-02-17, Score: 92.5%\n\u251c\u2500\u2500 Previous: 2026-02-16, Score: 90.0%\n\u251c\u2500\u2500 Trend: \u2191 2.5%\n\u2502\n\u2514\u2500\u2500 Failures:\n    TC-003: Expected FranceHR, got USHR (Routing)\n    TC-022: Expected refusal, got hallucinated salary (Edge Case)\n</code></pre>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Direct Line API setup + Power Automate flow. Moderate effort. Maintainability \ud83d\udfe2 Test cases in SharePoint \u2014 easy to add/edit. Flow logic is reusable. Comprehensiveness \ud83d\udfe1 Covers keyword-matchable scenarios well. Can't evaluate nuanced quality. Efficiency \ud83d\udfe2 40 test cases in 5-10 minutes. Fully automated. Scoring Objectivity \ud83d\udfe1 Keyword matching is objective but shallow. \"France\" in the response doesn't mean the answer is correct. Actionability \ud83d\udfe2 Automated failure reports identify exactly which tests broke."},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#limitations_1","title":"Limitations","text":"<ul> <li>Shallow validation: Keyword matching catches routing errors and obvious failures but misses subtle inaccuracies. \"Contains 'France'\" doesn't validate that the French policy is correct.</li> <li>Direct Line API complexity: Setting up API access, managing tokens, and handling conversation sessions adds technical overhead.</li> <li>No semantic evaluation: Can't assess \"Is this response helpful?\" or \"Is the tone appropriate?\" \u2014 only \"Does it contain these words?\"</li> <li>Flaky tests: LLM responses vary between runs. A test that passes 9/10 times and fails 1/10 creates noise. Set a threshold (e.g., pass if 8/10 runs succeed).</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#approach-c-llm-as-judge-evaluation-chain","title":"Approach C: LLM-as-Judge Evaluation Chain","text":"<p>Summary: Use a separate LLM call to evaluate the agent's response against expected criteria. The \"judge\" LLM scores accuracy, relevance, and quality. Technique: Prompt Tool or external LLM call that takes (test input, agent response, expected behavior) and returns a structured score.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Test case&lt;/b&gt;&lt;br/&gt;Input: How many PTO days for&lt;br/&gt;3-year employees in France?&lt;br/&gt;Expected: Specific number cited&lt;br/&gt;from France PTO document\"]\n    B[\"&lt;b&gt;Agent produces response&lt;/b&gt;&lt;br/&gt;In France, employees with 3 years&lt;br/&gt;tenure get 27 days PTO, plus 2 RTT&lt;br/&gt;days per month.&lt;br/&gt;(Source: FR-PTO-Policy-2025.docx, Section 3.1)\"]\n    C[\"&lt;b&gt;Judge LLM evaluates&lt;/b&gt;&lt;br/&gt;Routing: 2/2 \u2713&lt;br/&gt;Citation: 2/2 \u2713&lt;br/&gt;Accuracy: 2/2 \u2713&lt;br/&gt;Completeness: 2/2 \u2713&lt;br/&gt;Tone: 1/1 \u2713&lt;br/&gt;Total: 9/9 \u2705\"]\n    A --&gt; B --&gt; C</code></pre> <p>The judge LLM performs semantic evaluation \u2014 it understands whether the answer is correct, not just whether it contains keywords.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#implementation_2","title":"Implementation","text":"<p>Step 1: Create the judge Prompt Tool</p> <pre><code>kind: PromptTool\nid: prompt_testJudge\ndisplayName: \"Test Case Judge\"\ndescription: \"Evaluates an agent response against expected criteria\"\ninstructions: |\n  You are a quality evaluator for an AI agent. Score the agent's response \n  against the expected behavior.\n\n  **Test Input**: {testInput}\n  **Agent Response**: {agentResponse}\n  **Expected Behavior**: {expectedBehavior}\n  **Expected Source Document**: {expectedSource}\n\n  Score on these criteria (provide a number for each):\n\n  1. **Routing Accuracy (0-2)**: Was the response from the correct domain/specialist?\n     0 = Wrong specialist, 1 = Partially correct, 2 = Correct specialist\n\n  2. **Citation Quality (0-2)**: Is a specific source document cited?\n     0 = No citation, 1 = Generic attribution, 2 = Specific document and section\n\n  3. **Factual Accuracy (0-2)**: Is the information correct based on expected behavior?\n     0 = Incorrect, 1 = Partially correct, 2 = Fully accurate\n\n  4. **Completeness (0-2)**: Are all relevant aspects covered?\n     0 = Missing key info, 1 = Partial coverage, 2 = Complete\n\n  5. **Language/Tone (0-1)**: Is the response in the right language with appropriate tone?\n     0 = Wrong language or inappropriate tone, 1 = Correct\n\n  Return ONLY a JSON object:\n  {\"routing\": N, \"citation\": N, \"accuracy\": N, \"completeness\": N, \"tone\": N, \"total\": N, \"notes\": \"brief explanation\"}\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: testInput\n    type: string\n    required: true\n  - name: agentResponse\n    type: string\n    required: true\n  - name: expectedBehavior\n    type: string\n    required: true\n  - name: expectedSource\n    type: string\noutputs:\n  - name: evaluation\n    type: string\n</code></pre> <p>Step 2: Build a test runner that calls the judge</p> <p>Combine with Approach B's automated execution:</p> <pre><code>For each test case:\n  1. Send message to agent (Direct Line API)\n  2. Capture agent response\n  3. Call Judge Prompt Tool with (input, response, expected)\n  4. Parse score from Judge response\n  5. Log: TestId, Score, JudgeNotes, Timestamp\n</code></pre> <p>Step 3: Calibrate the judge</p> <p>Run the judge on 10 manually-scored test cases to calibrate:</p> <ul> <li>If the judge consistently scores higher than your manual scores, tighten the rubric instructions</li> <li>If it scores lower, add more nuance to the scoring criteria</li> <li>Goal: Judge scores within \u00b11 of human scores on the 9-point scale</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Prompt Tool + automation pipeline. More setup than manual testing. Maintainability \ud83d\udfe2 Judge prompt is reusable across all test cases. Test cases are data. Comprehensiveness \ud83d\udfe2 Semantic evaluation catches nuances that keyword matching misses. Efficiency \ud83d\udfe2 Automated execution + automated scoring. Full suite in 10-15 minutes. Scoring Objectivity \ud83d\udfe2 Consistent scoring across runs (LLM is more consistent than human testers). Actionability \ud83d\udfe2 Judge's \"notes\" field explains WHY a test failed."},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#limitations_2","title":"Limitations","text":"<ul> <li>LLM judge makes mistakes: The judge LLM can score incorrectly, especially for domain-specific accuracy. It may score \"27 days\" as correct when the actual policy says \"25 days.\"</li> <li>Cost: Every test case requires an extra LLM call for judging. 40 test cases = 40 additional LLM calls.</li> <li>Calibration effort: The judge needs calibration against human scores to be trustworthy. This is a one-time effort but non-trivial.</li> <li>Non-deterministic: LLM judge scores may vary slightly between runs. Average across multiple runs for stable metrics.</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Manual Script Approach B: Automated Keywords Approach C: LLM-as-Judge Implementation Effort \ud83d\udfe2 Low (2 hours) \ud83d\udfe1 Medium (4-6 hours) \ud83d\udfe1 Medium (4-6 hours) Execution Time \ud83d\udd34 60-90 min manual \ud83d\udfe2 5-10 min automated \ud83d\udfe2 10-15 min automated Evaluation Depth \ud83d\udfe2 Full semantic (human) \ud83d\udfe1 Keyword only \ud83d\udfe2 Semantic (LLM) Objectivity \ud83d\udfe1 Human subjectivity \ud83d\udfe2 Deterministic \ud83d\udfe1 LLM variability Scalability \ud83d\udd34 Doesn't scale \ud83d\udfe2 Scales linearly \ud83d\udfe2 Scales linearly Cost \ud83d\udfe2 Free (human time) \ud83d\udfe1 Power Automate runs \ud83d\udfe1 LLM judging calls Best When... Initial development, small test suites CI/CD pipeline, nightly regression High-stakes agents, quality matters most"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#recommended-approach","title":"Recommended Approach","text":"<p>Start with A, evolve to B+C:</p> <ol> <li>Development phase: Use Approach A (manual script). Write 20-30 test cases as you build. Score manually. Fast to set up, catches major issues.</li> <li>Pre-production: Add Approach B (automated keywords) for the highest-priority tests (routing accuracy, basic knowledge retrieval). Run nightly.</li> <li>Production quality gates: Add Approach C (LLM judge) for the most critical test cases (top 10-15). Use for deployment sign-off.</li> </ol> <pre><code>Development:   Approach A (manual, 20 cases, run on demand)\nPre-prod:      Approach B (automated, 30 cases, daily)\nProduction:    Approach C (LLM-scored, 15 cases, per deployment)\n</code></pre> <p>The test script from Approach A becomes the source of truth for Approaches B and C \u2014 you're automating and enriching the same test cases, not starting over.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>LLM responses are non-deterministic. The same input may produce slightly different responses across runs. For automated tests, use keyword matching with multiple acceptable keywords, or run each test 3 times and use the best-of-3 score.</p> <p>Warning</p> <p>The Copilot Studio Test Canvas doesn't support automation. You cannot script the Test Canvas. For automated testing, use the Direct Line API or Bot Framework connector. This requires additional setup.</p> <p>Note</p> <p>Enable debug mode (Gem 004) during testing. Debug mode reveals which topic was triggered, which agent was selected, and variable values. This makes manual testing (Approach A) much more efficient \u2014 you see exactly what the agent did, not just the final response.</p> <p>Note</p> <p>Test in EACH target channel, not just the Test Canvas. Behavior differs across channels (ConversationStart doesn't fire in M365 Copilot \u2014 see Gotchas Compendium). A test that passes in the Test Canvas may fail in production. Include channel-specific test cases.</p>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 004: Debug Mode for M365 Copilot Channel \u2014 Enable debug mode during testing for full diagnostic visibility</li> <li>Gem 009: Graceful Degradation and Fallback Chains \u2014 Include fallback scenarios in your test suite (what happens when services are down?)</li> <li>Gem 008: Knowledge Source Optimization \u2014 Knowledge retrieval tests validate that your format and chunking strategies work</li> </ul>"},{"location":"gems/GEM-013-testing-strategies-for-multi-agent-architectures/#references","title":"References","text":"<ul> <li>Microsoft Learn: Test your agent in Copilot Studio</li> <li>Bot Framework Direct Line API</li> <li>LLM-as-Judge evaluation pattern</li> <li>Microsoft Learn: Power Automate HTTP connector</li> </ul> <p>Gem 013 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/","title":"Gem 014: Proactive Agent Messages and Event-Driven Conversations","text":"<p>Don't wait for the user to ask \u2014 reach out first when something they care about happens.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50\u2b50 (Complex \u2014 event infrastructure + message delivery) Channels Teams (best support), Web Chat (limited), M365 Copilot (not supported) Prerequisite Gems Gem 001 (user context for personalized proactive messages)"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#the-problem","title":"The Problem","text":"<p>Every Gem in this collection assumes the user starts the conversation. But real-world scenarios demand agents that reach out first:</p> <ul> <li>Ticket resolution notification: \"Your ticket #4521 has been resolved. Was the solution helpful?\" \u2014 sent when the ticket status changes in the backend system.</li> <li>Approval reminders: \"You have 3 pending approvals waiting for more than 48 hours.\" \u2014 sent on a schedule.</li> <li>Policy announcements: \"Important: The PTO carryover policy has changed for 2027. Here's what's different.\" \u2014 sent when HR publishes a new document.</li> <li>Onboarding check-ins: \"Hi! You're in your second week. Do you have questions about setting up your dev environment?\" \u2014 sent on day 8 of onboarding.</li> <li>SLA alerts: \"Alert: 5 support tickets are approaching SLA breach in the next 2 hours.\" \u2014 sent when backend monitoring detects risk.</li> </ul> <p>The fundamental constraint: Copilot Studio agents are primarily reactive. They wait for user input. Proactive messaging \u2014 where the agent initiates contact \u2014 requires bridging external events into the conversation channel. The platform has limited native support for this, and the approaches differ significantly by channel.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that can reach out to users when relevant events occur:</p> <ul> <li>[ ] Event-driven: Messages triggered by real events (data changes, schedules, thresholds), not just timers</li> <li>[ ] Personalized: Proactive messages use user context (name, role, preferences) from Gem 001</li> <li>[ ] Actionable: Messages include actions the user can take (approve, acknowledge, ask follow-up)</li> <li>[ ] Channel-appropriate: Delivered via the user's primary channel (Teams, email, etc.)</li> <li>[ ] Non-intrusive: Users can control frequency and opt out of non-critical proactive messages</li> </ul>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#approach-a-power-automate-proactive-cards-via-teams","title":"Approach A: Power Automate Proactive Cards via Teams","text":"<p>Summary: Use Power Automate to detect events and send Adaptive Cards directly to users in Teams \u2014 bypassing Copilot Studio entirely for the notification, but linking back to the agent for follow-up. Technique: Power Automate cloud flow (scheduled or event-triggered), Teams \"Post card in a chat\" action, Adaptive Card with action buttons that deep-link to the agent.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Event occurs&lt;/b&gt;&lt;br/&gt;Dataverse change, schedule, webhook\"]\n    B[\"Power Automate Flow triggers\"]\n    C[\"Flow retrieves user context&lt;br/&gt;(who to notify, preferences)\"]\n    D[\"Flow sends Adaptive Card&lt;br/&gt;to user in Teams\"]\n    E[\"Card includes: notification +&lt;br/&gt;Ask the agent button\"]\n    F[\"User clicks button \u2192 opens&lt;br/&gt;Copilot Studio agent with context\"]\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F</code></pre> <p>The proactive message is a Teams Adaptive Card sent by a Power Automate flow. The card contains the notification content and an action button that opens the Copilot Studio agent in Teams, optionally pre-loading context (like a ticket ID or topic).</p> <p>This approach is pragmatic: it doesn't require Copilot Studio to support proactive messaging natively. Power Automate handles the event detection and delivery; the agent handles follow-up conversation.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#implementation","title":"Implementation","text":"<p>Step 1: Create the event-triggered flow</p> <p>Example: Ticket status change in Dataverse triggers a notification.</p> <pre><code>Trigger: When a row is modified (Dataverse)\n  Table: Support Tickets\n  Filter: Status changed to \"Resolved\"\n  Scope: Organization\n\nAction: Get Row (Dataverse - Users table)\n  Row ID: trigger/assignedTo\n  \u2192 Retrieve user email, Teams ID\n\nAction: Get User Context (optional - Gem 001 pattern)\n  \u2192 Retrieve preferred language, notification preferences\n\nCondition: User has opted out of proactive messages?\n  Yes \u2192 End flow\n  No \u2192 Continue\n\nAction: Post Adaptive Card in a chat (Teams)\n  Recipient: user's Teams ID\n  Card: [see Step 2]\n</code></pre> <p>Step 2: Design the proactive Adaptive Card</p> <pre><code>{\n  \"type\": \"AdaptiveCard\",\n  \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  \"version\": \"1.5\",\n  \"body\": [\n    {\n      \"type\": \"ColumnSet\",\n      \"columns\": [\n        {\n          \"type\": \"Column\",\n          \"width\": \"auto\",\n          \"items\": [\n            { \"type\": \"TextBlock\", \"text\": \"\u2705\", \"size\": \"extraLarge\" }\n          ]\n        },\n        {\n          \"type\": \"Column\",\n          \"width\": \"stretch\",\n          \"items\": [\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"Ticket Resolved\",\n              \"weight\": \"bolder\",\n              \"size\": \"medium\"\n            },\n            {\n              \"type\": \"TextBlock\",\n              \"text\": \"Your ticket #4521 has been resolved.\",\n              \"wrap\": true,\n              \"isSubtle\": true\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"type\": \"FactSet\",\n      \"facts\": [\n        { \"title\": \"Ticket\", \"value\": \"#4521\" },\n        { \"title\": \"Subject\", \"value\": \"Can't login to portal\" },\n        { \"title\": \"Resolution\", \"value\": \"Password reset + MFA reconfigured\" },\n        { \"title\": \"Resolved by\", \"value\": \"Support Team\" }\n      ]\n    }\n  ],\n  \"actions\": [\n    {\n      \"type\": \"Action.OpenUrl\",\n      \"title\": \"\u2705 Confirm Resolved\",\n      \"url\": \"https://support.contoso.com/tickets/4521/confirm\"\n    },\n    {\n      \"type\": \"Action.OpenUrl\",\n      \"title\": \"\ud83e\udd16 Ask the Agent\",\n      \"url\": \"https://teams.microsoft.com/l/chat/0/0?users=28:agent-bot-id&amp;message=Ticket%204521%20follow-up\"\n    },\n    {\n      \"type\": \"Action.OpenUrl\",\n      \"title\": \"\ud83d\udd04 Reopen Ticket\",\n      \"url\": \"https://support.contoso.com/tickets/4521/reopen\"\n    }\n  ]\n}\n</code></pre> <p>Step 3: Scheduled proactive messages</p> <p>For time-based notifications (reminders, digests, check-ins):</p> <pre><code>Trigger: Recurrence (daily at 9:00 AM)\n\nAction: List Rows (Dataverse)\n  Table: Pending Approvals\n  Filter: assignedTo eq '{user}' AND createdDate lt addDays(utcNow(), -2)\n\nCondition: Count &gt; 0?\n  Yes \u2192\n    Action: Post Adaptive Card in Teams\n      \"You have {count} pending approvals (oldest: {days} days).\n       [Review in Approval Center] [Ask the Agent]\"\n  No \u2192 End flow\n</code></pre> <p>Step 4: Notification preferences (link to Gem 001)</p> <p>Store user notification preferences using Gem 001's persistence pattern:</p> Preference Type Default <code>proactiveEnabled</code> Boolean true <code>digestFrequency</code> Choice (Daily/Weekly/Never) Daily <code>urgentOnly</code> Boolean false <code>quietHoursStart</code> Time 18:00 <code>quietHoursEnd</code> Time 09:00 <p>Load preferences in the Power Automate flow before sending any proactive message.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Power Automate + Teams card. Standard connectors, no custom code. Maintainability \ud83d\udfe2 Flows are visual and easy to modify. Card templates are JSON. Channel Compatibility \ud83d\udfe1 Teams only. No Web Chat or M365 Copilot proactive delivery. Event-Driven \ud83d\udfe2 Dataverse triggers, webhook triggers, scheduled triggers \u2014 all supported. Personalization \ud83d\udfe2 Flow can load user context (Gem 001) before sending. Agent Integration \ud83d\udfe1 Card links back to the agent via URL. Not a seamless conversation continuation."},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#limitations","title":"Limitations","text":"<ul> <li>Teams only: This approach delivers cards in Teams. Users on Web Chat or M365 Copilot don't receive proactive messages.</li> <li>Not a conversation: The proactive card is a one-way notification. The user must click a button and start a new conversation with the agent \u2014 it's not a continuation of an existing conversation.</li> <li>Bot registration required: To send cards from a bot (not a user), you need the bot registered in Teams. Power Automate's \"Post card in a chat\" action works with the Flow bot, but has limitations on card interactivity.</li> <li>Rate limits: Teams has message rate limits. Sending hundreds of proactive cards simultaneously may be throttled.</li> <li>No delivery confirmation: You can't verify the user saw the card. No read receipts.</li> </ul>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#approach-b-event-grid-webhook-power-automate-bot-framework-proactive-api","title":"Approach B: Event Grid Webhook \u2192 Power Automate \u2192 Bot Framework Proactive API","text":"<p>Summary: Use Azure Event Grid to capture real-time events, trigger a Power Automate flow, which calls the Bot Framework's proactive messaging API to send a message as the Copilot Studio agent. Technique: Azure Event Grid subscription, Power Automate HTTP webhook trigger, Bot Framework REST API for proactive messaging, conversation reference storage.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Azure Event&lt;/b&gt;&lt;br/&gt;blob change, resource update, custom event\"]\n    B[\"Event Grid \u2192 Webhook \u2192 Power Automate\"]\n    C[\"Flow looks up user's conversation&lt;br/&gt;reference (stored in Dataverse)\"]\n    D[\"Flow calls Bot Framework&lt;br/&gt;Proactive Message API\"]\n    E[\"Message appears IN the existing&lt;br/&gt;Copilot Studio conversation\"]\n    A --&gt; B --&gt; C --&gt; D --&gt; E</code></pre> <p>The key difference from Approach A: the message appears inside the agent's conversation, not as a separate Teams card. The user sees the proactive message as if the agent spoke to them \u2014 the conversation continues seamlessly.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#implementation_1","title":"Implementation","text":"<p>Step 1: Store conversation references</p> <p>When a user first interacts with the agent, capture their conversation reference (channel-specific address). Store it using Gem 001's persistence pattern:</p> <pre><code>    # In ConversationStart topic (or first interaction)\n    - kind: InvokeFlow\n      id: storeConversationRef\n      flowId: \"@environmentVariables('StoreConvRefFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        conversationId: =System.Conversation.Id\n        channelId: =System.Activity.ChannelId\n        serviceUrl: =System.Activity.ServiceUrl\n</code></pre> <p>The conversation reference contains: <code>conversationId</code>, <code>channelId</code>, <code>serviceUrl</code>, and <code>bot.id</code> \u2014 everything needed to address the user proactively.</p> <p>Step 2: Set up Event Grid subscription</p> <pre><code>Azure Event Grid Topic\n  \u2192 Subscription: Power Automate webhook endpoint\n  \u2192 Filter: eventType = \"TicketResolved\"\n  \u2192 Payload: { ticketId, assignedUserId, resolution }\n</code></pre> <p>Step 3: Power Automate flow calls Bot Framework API</p> <pre><code>Trigger: When an HTTP request is received (webhook from Event Grid)\n\nAction: Parse event payload\n  ticketId, assignedUserId, resolution\n\nAction: Get conversation reference (Dataverse)\n  Filter: userId eq '{assignedUserId}'\n  \u2192 Retrieve: conversationId, serviceUrl, bot.id\n\nAction: HTTP POST to Bot Framework\n  URL: {serviceUrl}/v3/conversations/{conversationId}/activities\n  Headers:\n    Authorization: Bearer {botToken}\n    Content-Type: application/json\n  Body:\n    {\n      \"type\": \"message\",\n      \"from\": { \"id\": \"{botId}\", \"name\": \"Support Agent\" },\n      \"text\": \"\u2705 Your ticket #{ticketId} has been resolved!\\n\\nResolution: {resolution}\\n\\nWas this helpful? (Yes / No / I need more help)\"\n    }\n</code></pre> <p>Step 4: Agent handles the follow-up</p> <p>The proactive message appears in the agent's conversation. If the user responds, the agent's normal topics handle it:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Ticket Follow-up\n    triggerQueries:\n      - \"yes it helped\"\n      - \"no it didn't help\"\n      - \"I need more help\"\n      - \"ticket follow-up\"\n  actions:\n    - kind: ConditionGroup\n      id: checkFeedback\n      conditions:\n        - id: positive\n          condition: =Contains(Lower(System.Activity.Text), \"yes\")\n          actions:\n            - kind: SendActivity\n              id: thankUser\n              activity:\n                text:\n                  - \"Great to hear! I'll close the ticket. Let me know if anything else comes up.\"\n        - id: needMore\n          condition: =Contains(Lower(System.Activity.Text), \"more help\")\n          actions:\n            - kind: SendActivity\n              id: offerMore\n              activity:\n                text:\n                  - \"I'm sorry it's not fully resolved. Let me look into this further. Can you describe what's still not working?\"\n</code></pre>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 Bot Framework API, conversation reference storage, Event Grid setup. Significant infrastructure. Maintainability \ud83d\udfe1 Multiple components: Event Grid + Power Automate + Dataverse + Bot Framework API. Channel Compatibility \ud83d\udfe1 Works for Teams and Web Chat (where conversation references can be stored). Not M365 Copilot. Event-Driven \ud83d\udfe2 Real-time event delivery via Event Grid. Sub-second latency. Personalization \ud83d\udfe2 Full user context available from conversation reference + Gem 001 data. Agent Integration \ud83d\udfe2 Seamless \u2014 message appears in the agent's conversation. True proactive messaging."},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#limitations_1","title":"Limitations","text":"<ul> <li>High complexity: This is the most infrastructure-heavy pattern in the entire Gems collection. Event Grid + Bot Framework + conversation reference storage is a significant engineering effort.</li> <li>Conversation reference management: References expire and become invalid. You need to refresh them periodically and handle stale references gracefully.</li> <li>Bot Framework expertise: Calling the proactive messaging API requires understanding Bot Framework REST API, token acquisition, and conversation addressing \u2014 well beyond typical Copilot Studio maker skills.</li> <li>M365 Copilot not supported: Proactive messaging via Bot Framework doesn't work for the M365 Copilot channel.</li> <li>Authentication: Acquiring a Bot Framework token programmatically from a Power Automate flow requires an App Registration with the proper credentials.</li> </ul>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#approach-c-scheduled-copilot-studio-trigger-topics","title":"Approach C: Scheduled Copilot Studio Trigger Topics","text":"<p>Summary: Use Copilot Studio's trigger configuration to define scheduled or event-based topic activation. The platform handles delivery. Technique: <code>trigger/</code> folder in VS Code Extension workspace, scheduled trigger YAML, platform-managed delivery.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#how-it-works_2","title":"How It Works","text":"<p>Copilot Studio's VS Code Extension file structure includes a <code>trigger/</code> folder for event-based configurations. This suggests platform-level support for proactive scenarios:</p> <pre><code>flowchart LR\n    A[\"&lt;b&gt;/agent-workspace/&lt;/b&gt;\"] --&gt; B[\"agent.yaml\"]\n    A --&gt; C[\"&lt;b&gt;/topics/&lt;/b&gt;\"] --&gt; D[\"...\"]\n    A --&gt; E[\"&lt;b&gt;/trigger/&lt;/b&gt;\"] --&gt; F[\"scheduled-reminder.trigger.yaml&lt;br/&gt;(proactive trigger definition)\"]\n    A --&gt; G[\"...\"]</code></pre>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#implementation_2","title":"Implementation","text":"<p>Step 1: Define a scheduled trigger</p> <pre><code>kind: ScheduledTrigger\nid: trigger_weeklyDigest\ndisplayName: \"Weekly Digest Reminder\"\ndescription: \"Sends weekly summary of pending items to subscribed users\"\nschedule:\n  frequency: weekly\n  dayOfWeek: monday\n  time: \"09:00\"\n  timezone: \"UTC\"\ntargetTopic: WeeklyDigestTopic\n</code></pre> <p>Step 2: Define the target topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnScheduledTrigger\n  id: main\n  actions:\n    - kind: SendActivity\n      id: sendDigest\n      activity:\n        text:\n          - \"\ud83d\udccb **Your Weekly Summary**\\n\\nHere's what needs your attention this week...\"\n    # Fetch user-specific data and present\n</code></pre> <p>Important update (February 2026): Copilot Studio event triggers reached General Availability in March 2025. The platform now includes a full trigger library with visual configuration for Dataverse row changes, new emails, new documents, and more. The <code>trigger/</code> folder and YAML approach described below works, and the UI-based trigger configuration is the recommended path. An Activity tab tracks all trigger executions with full audit trail. Agents can now run fully autonomously without end-user input.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Visual trigger configuration in Copilot Studio UI. YAML also supported. Maintainability \ud83d\udfe2 Platform-managed. Activity tab provides full execution history. Channel Compatibility \ud83d\udfe1 Teams and Web Chat. Proactive Teams messages have advanced options (notification labeling, active chat detection, status codes). Event-Driven \ud83d\udfe2 Full trigger library: Dataverse changes, emails, documents, schedules, and more. Personalization \ud83d\udfe2 Trigger payload includes event data + custom instructions. Agent can access user context. Agent Integration \ud83d\udfe2 Native \u2014 triggers activate agent instructions/topics. True autonomous agent behavior."},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#limitations_2","title":"Limitations","text":"<ul> <li>Trigger payload design: The payload determines what context the agent receives. Poorly designed payloads lead to agents that don't have enough context to act. Invest time in payload design.</li> <li>Testing difficulty: Event triggers fire on real events. Testing requires either triggering real events or using the Activity tab to review past executions.</li> <li>Channel delivery for proactive messages: The trigger activates the agent, but delivering proactive messages to specific users in Teams requires the proactive messaging connector with advanced options (notification labeling, active chat detection).</li> </ul>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: PA + Teams Card Approach B: Bot Framework API Approach C: Platform Triggers Implementation Effort \ud83d\udfe2 Low (2-3 hours) \ud83d\udd34 High (1-2 days) \ufffd Low-Medium (1-2 hours) Real-time Events \ud83d\udfe2 Via Dataverse/PA triggers \ud83d\udfe2 Via Event Grid \ud83d\udfe2 Full trigger library (Dataverse, email, docs, schedule) In-Agent Conversation \ud83d\udd34 Separate card, link back \ud83d\udfe2 True in-conversation message \ud83d\udfe2 Native topic/instruction activation Infrastructure \ud83d\udfe2 Power Automate only \ud83d\udd34 Event Grid + Bot Framework + Dataverse \ud83d\udfe2 Platform-native (GA) Channel Support \ud83d\udfe1 Teams only \ud83d\udfe1 Teams + Web Chat \ud83d\udfe1 Teams + Web Chat Platform Maturity \ud83d\udfe2 Fully supported \ud83d\udfe2 Fully supported (Bot Framework) \ud83d\udfe2 GA since March 2025 Best When... Simple Teams notifications Seamless conversation continuity Event-driven autonomous agents (recommended)"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#recommended-approach","title":"Recommended Approach","text":"<p>For most scenarios today: Approach A (Power Automate + Teams Card) \u2014 pragmatic, quick to implement, leverages existing Power Automate skills. The \"Ask the Agent\" button links back to the agent for follow-up.</p> <p>For high-value use cases: Approach B (Bot Framework API) \u2014 when the proactive message must feel like a natural continuation of the conversation (e.g., support ticket follow-up, multi-step workflow notifications). The engineering investment is high but the user experience is seamless.</p> <p>Watch and evaluate: Approach C (Platform Triggers) \u2014 as Copilot Studio matures, native trigger support will likely become the preferred approach. Check the VS Code Extension file structure and platform release notes periodically.</p> <p>Practical default:</p> <pre><code>Most notifications      \u2192 Approach A (Teams card, 2-hour setup)\nCritical follow-ups     \u2192 Approach B (in-conversation, 1-day setup)\nFuture-proof planning   \u2192 Approach C (evaluate as platform evolves)\n</code></pre>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>M365 Copilot does NOT support proactive messaging. There is no mechanism to proactively send a message to a user in the M365 Copilot channel. Proactive messaging is limited to Teams and Web Chat. Plan your notification strategy around Teams as the delivery channel.</p> <p>Warning</p> <p>Bot Framework conversation references expire. If using Approach B, conversation references become stale when the user hasn't interacted with the bot in a while. Always handle <code>403 Forbidden</code> or <code>404 Not Found</code> responses gracefully \u2014 re-engage the user via Approach A (Teams card) as fallback.</p> <p>Warning</p> <p>Power Automate Teams card actions are limited. <code>Action.Submit</code> in a card sent via Power Automate does NOT route back to the Copilot Studio agent. Use <code>Action.OpenUrl</code> with a deep link to the agent's Teams chat instead.</p> <p>Note</p> <p>Respect notification fatigue. Users who receive too many proactive messages will mute or ignore the agent. Implement notification preferences (frequency, urgency threshold, quiet hours) using Gem 001's persistence pattern.</p>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context Across Sessions \u2014 Store notification preferences and conversation references</li> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Proactive cards can include form fields for quick user responses</li> <li>Gem 009: Graceful Degradation and Fallback Chains \u2014 If proactive delivery fails (expired reference), fall back to email or Teams card</li> </ul>"},{"location":"gems/GEM-014-proactive-agent-messages-and-event-driven-conversations/#references","title":"References","text":"<ul> <li>Microsoft Learn: Proactive messages in Bot Framework</li> <li>Microsoft Learn: Power Automate Teams connector</li> <li>Microsoft Learn: Azure Event Grid overview</li> <li>Microsoft Learn: Copilot Studio VS Code Extension</li> <li>Adaptive Cards: Action.OpenUrl deep links</li> </ul> <p>Gem 014 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/","title":"Gem 015: Dataverse CRUD Operations Patterns","text":"<p>Read, create, update, delete \u2014 the four operations every data-driven agent needs, implemented three different ways.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 multiple integration patterns, role-gating considerations) Channels All Prerequisite Gems Gem 007 (role-based gating for write/delete operations)"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#the-problem","title":"The Problem","text":"<p>Gem 001 introduced Dataverse as a persistence layer for user context \u2014 a simple upsert pattern for one table with one row per user. But real agents need to interact with business data: support tickets, approval requests, inventory records, employee profiles, project tasks.</p> <p>These interactions require the full CRUD spectrum:</p> <ul> <li>Create: \"Create a support ticket for login issues.\" \u2014 Insert a new row.</li> <li>Read: \"Show me my open tickets.\" \u2014 Query and display rows.</li> <li>Update: \"Change the priority of ticket #4521 to Critical.\" \u2014 Modify an existing row.</li> <li>Delete: \"Cancel my ticket #4521.\" \u2014 Remove or soft-delete a row.</li> </ul> <p>Each operation has different complexity, security implications, and implementation trade-offs:</p> <ul> <li>Read is safe, write is risky: A misconfigured Create could flood your table with garbage rows. An uncontrolled Delete could destroy business data.</li> <li>Authentication matters: Who is performing the operation? The agent (service account)? The user (delegated)? The answer affects auditability.</li> <li>Validation is critical: User-provided data must be validated before writing. \"Set priority to banana\" shouldn't create a record.</li> <li>Performance varies: A simple read is fast. A filtered query across 100K rows with joins is not.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A reliable, secure CRUD pattern for Dataverse interaction:</p> <ul> <li>[ ] All four operations: Create, Read (single + list), Update, Delete working reliably</li> <li>[ ] Role-gated writes: Create/Update/Delete restricted to authorized roles (Gem 007)</li> <li>[ ] Input validation: User-provided data validated before any write operation</li> <li>[ ] Error handling: Graceful failure messages when operations fail (Gem 009)</li> <li>[ ] Audit trail: Changes logged for accountability</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#approach-a-power-automate-flows-per-operation","title":"Approach A: Power Automate Flows per Operation","text":"<p>Summary: Create dedicated Power Automate cloud flows for each CRUD operation. The agent invokes the appropriate flow via <code>InvokeFlow</code>. Technique: One flow per operation (or per entity \u00d7 operation), Dataverse connector actions, agent topic integration.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#how-it-works","title":"How It Works","text":"<pre><code>flowchart LR\n    subgraph AT [\"Agent Topic\"]\n        A1[\"Show my tickets\"]\n        A2[\"Create a ticket\"]\n        A3[\"Update priority\"]\n        A4[\"Cancel ticket\"]\n    end\n    subgraph PA [\"Power Automate Flows\"]\n        B1[\"ReadTickets Flow&lt;br/&gt;(returns JSON array)\"]\n        B2[\"CreateTicket Flow&lt;br/&gt;(returns new ID)\"]\n        B3[\"UpdateTicket Flow&lt;br/&gt;(returns success)\"]\n        B4[\"DeleteTicket Flow&lt;br/&gt;(returns success)\"]\n    end\n    subgraph DV [\"Dataverse\"]\n        C1[\"List Rows\"]\n        C2[\"Add Row\"]\n        C3[\"Update Row\"]\n        C4[\"Update Row&lt;br/&gt;(soft delete)\"]\n    end\n    A1 &lt;--&gt; B1 &lt;--&gt; C1\n    A2 &lt;--&gt; B2 &lt;--&gt; C2\n    A3 &lt;--&gt; B3 &lt;--&gt; C3\n    A4 &lt;--&gt; B4 &lt;--&gt; C4</code></pre>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#implementation","title":"Implementation","text":"<p>Step 1: Design the Dataverse table</p> <p>Example: Support Tickets table.</p> Column Type Description <code>TicketId</code> Auto-number Unique ticket identifier <code>Title</code> Single line text Short description <code>Description</code> Multi-line text Detailed description <code>Status</code> Choice (Open/InProgress/Resolved/Cancelled) Current state <code>Priority</code> Choice (Low/Medium/High/Critical) Urgency <code>AssignedTo</code> Lookup (Users) Who it's assigned to <code>CreatedBy</code> Lookup (Users) Who created it <code>CreatedOn</code> DateTime Auto-populated <code>ModifiedOn</code> DateTime Auto-populated <p>Step 2: Create the Read flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Input: userId (Text), statusFilter (Text, optional)\n\nAction: List Rows (Dataverse)\n  Table: Support Tickets\n  Filter: _createdby_value eq '{userId}'\n           AND (statusFilter eq '' OR cr_status eq '{statusFilter}')\n  Order by: cr_createdon desc\n  Top Count: 10\n\nAction: Select (transform to simplified output)\n  From: body/value\n  Map:\n    ticketId: item()?['cr_ticketid']\n    title: item()?['cr_title']\n    status: item()?['cr_status@OData.Community.Display.V1.FormattedValue']\n    priority: item()?['cr_priority@OData.Community.Display.V1.FormattedValue']\n    createdOn: item()?['cr_createdon']\n\nOutput: tickets (Array of objects)\n</code></pre> <p>Step 3: Create the Create flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: title (Text), description (Text), priority (Text), userId (Text)\n\nAction: Add Row (Dataverse)\n  Table: Support Tickets\n  Title: {title}\n  Description: {description}\n  Priority: {priority mapped to choice value}\n  Status: \"Open\"\n  CreatedBy: {userId}\n\nOutput: ticketId (the new auto-number)\n</code></pre> <p>Step 4: Create the Update flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: ticketId (Text), fieldToUpdate (Text), newValue (Text)\n\nAction: List Rows (Dataverse)\n  Filter: cr_ticketid eq '{ticketId}'\n  Top Count: 1\n\nCondition: Row found?\n  Yes \u2192\n    Action: Update Row (Dataverse)\n      Row ID: first(body/value)?['cr_supportticketid']\n      Set {fieldToUpdate} to {newValue}\n    Output: success = true\n  No \u2192\n    Output: success = false, error = \"Ticket not found\"\n</code></pre> <p>Step 5: Create the Delete flow (soft delete)</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: ticketId (Text), userId (Text)\n\nAction: List Rows (Dataverse)\n  Filter: cr_ticketid eq '{ticketId}' AND _createdby_value eq '{userId}'\n\nCondition: Row found AND user owns it?\n  Yes \u2192\n    Action: Update Row (Dataverse)\n      Status: \"Cancelled\"\n    Output: success = true\n  No \u2192\n    Output: success = false, error = \"Ticket not found or not yours\"\n</code></pre> <p>Step 6: Agent topic integration with role gating</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Manage Support Tickets\n    triggerQueries:\n      - \"create a ticket\"\n      - \"show my tickets\"\n      - \"update ticket\"\n      - \"cancel ticket\"\n  actions:\n    # Detect operation from user message\n    - kind: ConditionGroup\n      id: detectOperation\n      conditions:\n        - id: isCreate\n          condition: =Contains(Lower(System.Activity.Text), \"create\")\n          actions:\n            # Collect required fields\n            - kind: Question\n              id: askTitle\n              variable: init:Topic.TicketTitle\n              prompt: \"What's the issue? (brief title)\"\n              entity: StringPrebuiltEntity\n\n            - kind: Question\n              id: askDescription\n              variable: init:Topic.TicketDescription\n              prompt: \"Please describe the issue in detail:\"\n              entity: StringPrebuiltEntity\n\n            - kind: Question\n              id: askPriority\n              variable: init:Topic.TicketPriority\n              prompt: \"Priority level?\"\n              entity: ChoicePrebuiltEntity\n              choiceOptions:\n                - value: \"Low\"\n                - value: \"Medium\"\n                - value: \"High\"\n                - value: \"Critical\"\n\n            # Create via flow\n            - kind: InvokeFlow\n              id: createTicket\n              flowId: \"@environmentVariables('CreateTicketFlowId')\"\n              inputs:\n                title: =Topic.TicketTitle\n                description: =Topic.TicketDescription\n                priority: =Topic.TicketPriority\n                userId: =System.User.Id\n              outputVariable: Topic.CreateResult\n\n            - kind: SendActivity\n              id: confirmCreate\n              activity:\n                text:\n                  - \"\u2705 Ticket **#{Topic.CreateResult.ticketId}** created!\\n\\n| Field | Value |\\n|---|---|\\n| Title | {Topic.TicketTitle} |\\n| Priority | {Topic.TicketPriority} |\\n| Status | Open |\"\n\n        - id: isRead\n          condition: =Contains(Lower(System.Activity.Text), \"show\") || Contains(Lower(System.Activity.Text), \"list\")\n          actions:\n            - kind: InvokeFlow\n              id: readTickets\n              flowId: \"@environmentVariables('ReadTicketsFlowId')\"\n              inputs:\n                userId: =System.User.Id\n                statusFilter: \"\"\n              outputVariable: Topic.TicketList\n\n            - kind: SendActivity\n              id: showTickets\n              activity:\n                text:\n                  - \"\ud83d\udccb **Your Tickets**\\n\\n{Topic.TicketList}\"\n\n        - id: isDelete\n          condition: =Contains(Lower(System.Activity.Text), \"cancel\") || Contains(Lower(System.Activity.Text), \"delete\")\n          actions:\n            # Role check for delete (Gem 007)\n            - kind: ConditionGroup\n              id: checkDeletePermission\n              conditions:\n                - id: canDelete\n                  condition: =Global.UserRole = \"Admin\" || Global.UserRole = \"PowerUser\"\n                  actions:\n                    # ... deletion flow ...\n              elseActions:\n                - kind: SendActivity\n                  id: denyDelete\n                  activity:\n                    text:\n                      - \"You can view and create tickets. To cancel a ticket, please contact your team lead.\"\n</code></pre>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 4 flows + topic logic. Straightforward but many components. Maintainability \ud83d\udfe2 Each flow is independent. Schema changes require flow updates. Channel Compatibility \ud83d\udfe2 All channels (flows are backend). Security \ud83d\udfe2 Flows run with connector credentials. Role gating in topics. Validation \ud83d\udfe2 Flows can validate before writing. Topics validate via Question entities. Performance \ud83d\udfe1 Power Automate adds 1-3s per operation. Acceptable for CRUD."},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#limitations","title":"Limitations","text":"<ul> <li>Flow proliferation: 4 operations \u00d7 N entities = many flows. 3 entities means 12 flows to maintain.</li> <li>Power Automate quota: Each CRUD call consumes a flow run. High-volume agents may hit licensing limits.</li> <li>Complex queries: Multi-table joins, aggregations, and complex filters are cumbersome in Power Automate's Dataverse connector.</li> <li>Flow latency: 1-3 seconds per call. Chatty CRUD operations (read \u2192 update \u2192 read) compound latency.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#approach-b-http-connector-to-dataverse-web-api","title":"Approach B: HTTP Connector to Dataverse Web API","text":"<p>Summary: Call the Dataverse Web API directly via <code>HttpRequest</code> nodes in topics. No Power Automate in the loop. Technique: <code>HttpRequest</code> node with OData queries, environment variables for Dataverse URL, bearer token from authentication context.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart LR\n    subgraph AT [\"Agent Topic\"]\n        A1[\"HttpRequest GET /tickets\"]\n        A2[\"HttpRequest POST /tickets\"]\n    end\n    subgraph DV [\"Dataverse Web API\"]\n        B1[\"OData query&lt;br/&gt;\u2192 JSON response\"]\n        B2[\"Create record&lt;br/&gt;\u2192 New record ID\"]\n    end\n    A1 &lt;--&gt; B1\n    A2 &lt;--&gt; B2</code></pre> <p>Direct HTTP calls eliminate Power Automate latency and flow quotas. But they require constructing OData URLs and managing authentication.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#implementation_1","title":"Implementation","text":"<p>Step 1: Configure environment variables</p> <pre><code>&lt;environmentvariabledefinition schemaname=\"agent_DataverseUrl\"&gt;\n  &lt;defaultvalue&gt;https://org12345.api.crm.dynamics.com&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n</code></pre> <p>Step 2: Read operation</p> <pre><code>    - kind: HttpRequest\n      id: http_readTickets\n      method: GET\n      url: =Concatenate(Env.agent_DataverseUrl, \"/api/data/v9.2/cr_supporttickets?$filter=_createdby_value eq '\", System.User.Id, \"'&amp;$select=cr_ticketid,cr_title,cr_status,cr_priority&amp;$orderby=createdon desc&amp;$top=10\")\n      headers:\n        - key: \"Accept\"\n          value: \"application/json\"\n        - key: \"OData-MaxVersion\"\n          value: \"4.0\"\n        - key: \"OData-Version\"\n          value: \"4.0\"\n      responseType: json\n      responseVariable: Topic.TicketResponse\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.HttpStatus\n      timeout: 10000\n</code></pre> <p>Step 3: Create operation</p> <pre><code>    - kind: HttpRequest\n      id: http_createTicket\n      method: POST\n      url: =Concatenate(Env.agent_DataverseUrl, \"/api/data/v9.2/cr_supporttickets\")\n      headers:\n        - key: \"Content-Type\"\n          value: \"application/json\"\n        - key: \"OData-MaxVersion\"\n          value: \"4.0\"\n      body: |\n        {\n          \"cr_title\": \"{Topic.TicketTitle}\",\n          \"cr_description\": \"{Topic.TicketDescription}\",\n          \"cr_priority\": {Topic.PriorityValue},\n          \"cr_status\": 1\n        }\n      responseType: json\n      responseVariable: Topic.CreateResponse\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.CreateStatus\n      timeout: 10000\n</code></pre> <p>Step 4: Update operation</p> <pre><code>    - kind: HttpRequest\n      id: http_updateTicket\n      method: PATCH\n      url: =Concatenate(Env.agent_DataverseUrl, \"/api/data/v9.2/cr_supporttickets(\", Topic.RecordId, \")\")\n      headers:\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"cr_priority\": {Topic.NewPriorityValue}\n        }\n      responseType: json\n      responseVariable: Topic.UpdateResponse\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.UpdateStatus\n      timeout: 10000\n</code></pre>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 OData URL construction is complex. Authentication management adds difficulty. Maintainability \ud83d\udfe1 OData queries in YAML are hard to read. Schema changes require URL updates. Channel Compatibility \ud83d\udfe2 HTTP nodes work in all channels. Security \ud83d\udfe1 Authentication depends on how the agent's identity flows to Dataverse. Managed Identity ideal but setup varies. Validation \ud83d\udfe1 Must be done in topic logic before the HTTP call. No connector-level validation. Performance \ud83d\udfe2 Direct calls. No Power Automate overhead. Fastest option (~200-500ms)."},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#limitations_1","title":"Limitations","text":"<ul> <li>OData complexity: Constructing filtered, sorted, paginated OData queries in concatenated strings is error-prone and hard to debug.</li> <li>Authentication challenge: The <code>HttpRequest</code> node needs a bearer token to call Dataverse. How the agent obtains this depends on the authentication configuration \u2014 Managed Identity, app registration, or user delegation.</li> <li>No transaction support: Multiple HTTP calls don't form a transaction. If a read succeeds but the subsequent update fails, you're in an inconsistent state.</li> <li>Error messages are technical: Dataverse returns OData error JSON, not user-friendly messages. You must parse and translate.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#approach-c-generative-ai-with-natural-language-dataverse-access","title":"Approach C: Generative AI with Natural Language Dataverse Access","text":"<p>Summary: Instruct the agent to use Dataverse as a tool via generative orchestration. The LLM interprets user intent and constructs the appropriate operation. Technique: Agent instructions that describe available data operations, Dataverse connector as an action/tool, generative orchestration for intent-to-operation mapping.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;User:&lt;/b&gt;&lt;br/&gt;Create a high priority ticket&lt;br/&gt;about email not working\"]\n    B[\"&lt;b&gt;LLM interprets:&lt;/b&gt;&lt;br/&gt;Operation: Create&lt;br/&gt;Entity: Support Ticket&lt;br/&gt;Fields: title=Email not working, priority=High\"]\n    C[\"LLM calls Dataverse tool/action&lt;br/&gt;with extracted fields\"]\n    D[\"&lt;b&gt;Agent:&lt;/b&gt;&lt;br/&gt;Created ticket #4522:&lt;br/&gt;Email not working (High priority)\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre> <p>The LLM handles the natural language \u2192 structured operation translation. No explicit topic logic for each operation \u2014 the agent \"understands\" CRUD naturally.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#implementation_2","title":"Implementation","text":"<p>Step 1: Configure Dataverse as a tool</p> <p>In Copilot Studio, add a Dataverse connector action or configure a Power Automate flow as a tool with clear descriptions:</p> <pre><code># Tool descriptions that help the LLM understand when to use each\ntools:\n  - name: CreateTicket\n    description: \"Creates a new support ticket. Use when user wants to report an issue or create a case.\"\n    inputs: [title, description, priority]\n\n  - name: ListMyTickets\n    description: \"Lists the current user's support tickets. Use when user asks to see, show, or list their tickets.\"\n    inputs: [statusFilter (optional)]\n\n  - name: UpdateTicket\n    description: \"Updates a field on an existing ticket. Use when user wants to change priority, status, or details.\"\n    inputs: [ticketId, fieldName, newValue]\n\n  - name: CancelTicket\n    description: \"Cancels (soft-deletes) a ticket. Use when user wants to cancel, close, or remove their ticket.\"\n    inputs: [ticketId]\n</code></pre> <p>Step 2: Agent instructions for CRUD behavior</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Data-Driven Agent\ninstructions: |+\n  # Data Operations\n\n  You can manage support tickets for users. Available operations:\n\n  ## Reading Data\n  - When users ask to \"show\", \"list\", \"check\", or \"view\" tickets \u2192 call ListMyTickets\n  - Present results in a formatted table\n  - If no results, say \"You don't have any [status] tickets\"\n\n  ## Creating Data\n  - When users want to \"create\", \"submit\", \"report\", or \"open\" a ticket \u2192 collect required fields, then call CreateTicket\n  - Required fields: title, description, priority\n  - Always confirm before creating: \"I'll create: [summary]. Proceed?\"\n\n  ## Updating Data\n  - When users want to \"change\", \"update\", or \"modify\" a ticket \u2192 identify the ticket and field, then call UpdateTicket\n  - Always confirm before updating: \"Change [field] to [value] on ticket #[id]?\"\n\n  ## Deleting Data\n  - When users want to \"cancel\", \"remove\", or \"close\" a ticket \u2192 call CancelTicket\n  - ALWAYS confirm destructive actions: \"Are you sure you want to cancel ticket #[id]?\"\n  - Only the ticket creator or an Admin can cancel tickets\n\n  ## Security Rules\n  - Users can only see and modify their OWN tickets\n  - Admins can see and modify ALL tickets\n  - NEVER expose another user's ticket data to non-admins\n</code></pre> <p>Step 3: LLM handles the mapping</p> <p>With well-described tools and clear instructions, the LLM extracts the operation and parameters from natural language:</p> User says LLM interprets Tool called \"I can't login, please help\" Create ticket, title=\"Login issue\" CreateTicket \"Show me my tickets\" List user's tickets ListMyTickets \"Make ticket 4521 critical\" Update #4521, priority=Critical UpdateTicket \"Never mind about ticket 4521\" Cancel #4521 CancelTicket"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Tools/actions + instructions. Minimal code once tools are configured. Maintainability \ud83d\udfe2 Instructions are natural language. Adding operations = adding tool descriptions. Channel Compatibility \ud83d\udfe2 Generative orchestration works in all channels. Security \ud83d\udfe1 LLM instruction-based gating is probabilistic. Add hard gates for Delete (Gem 007). Validation \ud83d\udfe1 LLM extracts fields but may miss validation. Combine with explicit confirmation. Performance \ud83d\udfe1 LLM intent parsing adds 1-2 seconds before the actual operation."},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#limitations_2","title":"Limitations","text":"<ul> <li>LLM may misinterpret operations: \"Delete ticket 4521\" vs \"Show me deleted tickets\" \u2014 the LLM usually gets this right, but edge cases exist. Always require explicit confirmation for write operations.</li> <li>Parameter extraction accuracy: \"Make it high priority\" \u2014 does \"it\" refer to the last-mentioned ticket? LLM handles this with conversation context (Gem 011), but it's not 100% reliable.</li> <li>Security is instruction-based: For Delete operations, LLM instruction compliance is not a security boundary. Always add a hard <code>ConditionGroup</code> check on <code>Global.UserRole</code> as defense-in-depth (Gem 007).</li> <li>No bulk operations: \"Update all my tickets to High priority\" requires iterating \u2014 the LLM may try but the tool typically handles one row at a time.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#approach-d-dataverse-mcp-server-prebuilt","title":"Approach D: Dataverse MCP Server (Prebuilt)","text":"<p>Summary: Use the prebuilt Dataverse MCP Server connector in Copilot Studio. Add it as a tool \u2014 the agent can then query, describe, and interact with Dataverse tables via natural language with zero custom configuration. Technique: Copilot Studio's built-in Dataverse MCP connector, generative orchestration, auto-discovered tools.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#how-it-works_3","title":"How It Works","text":"<pre><code>flowchart LR\n    subgraph AG [\"Agent\"]\n        A1[\"Show my open tickets\"]\n        A2[\"Create a high priority&lt;br/&gt;ticket about login\"]\n    end\n    subgraph MCP [\"Dataverse MCP Server\"]\n        B1[\"MCP tool: query_records&lt;br/&gt;\u2192 Structured JSON results\"]\n        B2[\"MCP tool: create_record&lt;br/&gt;\u2192 New record confirmation\"]\n    end\n    subgraph DV [\"Dataverse\"]\n        C1[\"List Rows\"]\n        C2[\"Add Row\"]\n    end\n    A1 &lt;--&gt; B1 &lt;--&gt; C1\n    A2 &lt;--&gt; B2 &lt;--&gt; C2</code></pre> <p>The Dataverse MCP Server publishes tools that the agent automatically discovers. No flow definition, no OData URLs, no tool descriptions to write \u2014 the MCP server defines everything.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#implementation_3","title":"Implementation","text":"<p>Step 1: Add the Dataverse MCP Server to your agent</p> <ol> <li>In Copilot Studio \u2192 Tools \u2192 Add a tool</li> <li>Select Model Context Protocol</li> <li>Select Dataverse MCP Server from the prebuilt connectors list</li> <li>Authorize the connection (uses existing Dataverse permissions)</li> <li>Click Add to agent</li> </ol> <p>That's it. The MCP server auto-publishes its available tools.</p> <p>Step 2: Test with natural language</p> <p>In the Test panel, try:</p> <ul> <li>\"List tables in Dataverse\"</li> <li>\"Describe the Support Tickets table\"</li> <li>\"How many open tickets do I have?\"</li> <li>\"Show me tickets created this week\"</li> </ul> <p>Step 3: Selectively enable/disable MCP tools</p> <p>If the Dataverse MCP Server exposes tools you don't want (e.g., delete operations):</p> <ol> <li>Go to Tools \u2192 select the Dataverse MCP Server \u2192 Edit</li> <li>Turn off Allow all</li> <li>Disable individual tools (e.g., disable <code>delete_record</code>)</li> </ol> <p>Step 4: Add agent instructions for CRUD behavior</p> <pre><code>instructions: |+\n  ## Dataverse Operations\n  You have access to the Dataverse MCP Server for data operations.\n\n  ## Rules\n  - ALWAYS confirm before creating, updating, or deleting records\n  - For deletions, use soft-delete (set Status to \"Cancelled\") when available\n  - Only show the current user's records unless they have Admin role (Gem 007)\n  - Format query results as tables for readability\n</code></pre>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#evaluation_3","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 3 clicks to add. Zero configuration. Fastest option. Maintainability \ud83d\udfe2 Microsoft maintains the MCP server. Tool updates auto-sync. Channel Compatibility \ud83d\udfe2 All channels (generative orchestration required). Security \ud83d\udfe1 Connection's Dataverse permissions. Selective tool toggling. Add hard gates for safety. Validation \ud83d\udfe1 LLM interprets natural language. Combine with confirmations. Performance \ud83d\udfe1 MCP round-trip + LLM interpretation. Comparable to Approach C."},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#limitations_3","title":"Limitations","text":"<ul> <li>Generative Orchestration required: MCP tools only work with generative orchestration enabled. Manual topics cannot call MCP tools directly.</li> <li>Less control than flows: You can't customize query logic, add complex validation, or transform results. The MCP server handles queries its own way.</li> <li>Platform-managed, not custom: If the Dataverse MCP Server doesn't support a specific query pattern, fall back to Approach A or B.</li> <li>Security relies on connection + instructions: Fine-grained row-level security depends on Dataverse security roles, not agent logic.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Power Automate Approach B: HTTP Direct Approach C: Generative AI Approach D: Dataverse MCP Implementation Effort \ud83d\udfe1 Medium (4 flows) \ud83d\udd34 High (OData URLs) \ud83d\udfe2 Low (tools + instructions) \ud83d\udfe2 Lowest (3 clicks) Performance \ud83d\udfe1 1-3s per operation \ud83d\udfe2 200-500ms \ud83d\udfe1 1-2s (LLM parsing) \ud83d\udfe1 1-2s (MCP + LLM) Security Control \ud83d\udfe2 Flow-level validation \ud83d\udfe1 HTTP-level auth \ud83d\udfe1 LLM + hard gates \ud83d\udfe1 Connection + tool toggling Natural Language \ud83d\udd34 Fixed topic triggers \ud83d\udd34 Fixed topic triggers \ud83d\udfe2 Free-form input \ud83d\udfe2 Free-form input Auto-Updates \ud83d\udd34 Manual flow maintenance \ud83d\udd34 Manual URL maintenance \ud83d\udd34 Manual tool config \ud83d\udfe2 Auto-sync from MCP server Flow Quota Impact \ud83d\udd34 4 runs per CRUD cycle \ud83d\udfe2 None \ud83d\udfe1 Depends on tool \ud83d\udfe2 None Best When... Visual flow dev, PA skills Max performance, pro-dev Custom tools, rapid dev Fastest time-to-value, standard CRUD"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#recommended-approach","title":"Recommended Approach","text":"<p>For fastest time-to-value: Approach D (Dataverse MCP Server) \u2014 3 clicks to add, zero configuration, auto-syncing tools. If your CRUD needs are standard (read, create, update with confirmation, soft-delete) and you're using generative orchestration, start here. The prebuilt Dataverse MCP Server handles the most common scenarios.</p> <p>For most production agents: Approach A (Power Automate) for the backend, with Approach C or D for the user-facing experience. Flows give you validated, secure operations. Generative orchestration (via custom tools or MCP) gives you natural language interaction.</p> <p>The hybrid pattern:</p> <ol> <li>Build Power Automate flows for operations needing custom validation (Approach A backend)</li> <li>Use Dataverse MCP Server for standard read/query operations (Approach D)</li> <li>Let generative orchestration handle the natural language \u2192 tool mapping</li> <li>Add hard <code>ConditionGroup</code> gates for write/delete operations (Gem 007)</li> </ol> <pre><code>User speaks naturally (Approach C experience)\n    \u2192 LLM selects the right tool\n    \u2192 Tool calls Power Automate flow (Approach A backend)\n    \u2192 Flow executes validated Dataverse operation\n    \u2192 Result returned to user\n</code></pre> <p>Choose Approach B when: You're a pro-dev team optimizing for sub-second performance and you need the full power of OData queries (complex joins, aggregations). Worth the OData complexity for high-volume, latency-sensitive agents.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Always use soft-delete for user-facing Delete operations. Never physically delete Dataverse rows from an agent. Set a status to \"Cancelled\" or \"Deleted\" instead. This prevents accidental data loss and enables audit trails.</p> <p>Warning</p> <p>Confirm ALL write operations before executing. Whether via explicit Question node (\"Proceed? Yes/No\") or agent instructions (\"Always confirm before creating/updating/deleting\"), never let a misinterpreted natural language command silently modify data.</p> <p>Warning</p> <p>LLM-based operation mapping is not a security boundary. Even if instructions say \"only admins can delete,\" a determined user could circumvent LLM restrictions. Always add hard-coded role checks (Gem 007) for write and delete operations.</p> <p>Note</p> <p>Dataverse Choice columns return codes, not labels. When reading Choice columns via API or flow, you get numeric values (1, 2, 3), not display labels (\"Open\", \"In Progress\", \"Resolved\"). Map codes to labels in your flow or topic logic for user-friendly display.</p>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context \u2014 The simpler cousin. Gem 001 is a single-table upsert; this Gem is full CRUD for business entities.</li> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Collect CRUD input data via form cards instead of sequential questions.</li> <li>Gem 007: Role-Based Feature Gating \u2014 Essential security layer for write/delete operations.</li> <li>Gem 009: Graceful Degradation \u2014 Handle Dataverse unavailability gracefully.</li> </ul>"},{"location":"gems/GEM-015-dataverse-crud-operations-patterns/#references","title":"References","text":"<ul> <li>Microsoft Learn: Dataverse Web API</li> <li>Microsoft Learn: Dataverse connector in Power Automate</li> <li>Microsoft Learn: OData query syntax for Dataverse</li> <li>Microsoft Learn: Copilot Studio actions and tools</li> </ul> <p>Gem 015 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/","title":"Gem 016: Conversation Analytics and Quality Measurement","text":"<p>You built the agent and deployed it. Now: is it actually helping people?</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#classification","title":"Classification","text":"Attribute Value Category Observability Complexity \u2b50\u2b50 to \u2b50\u2b50\u2b50 (depends on analytics depth) Channels All Prerequisite Gems Gem 004 (Application Insights pipeline for custom analytics)"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#the-problem","title":"The Problem","text":"<p>Gem 012 tracks cost (tokens per conversation). Gem 013 validates correctness (test suites). But neither answers the most important question: is the agent actually solving users' problems?</p> <p>After deployment, you need to know:</p> <ul> <li>Resolution rate: What percentage of conversations end with the user's question answered \u2014 vs abandonment, escalation, or confusion?</li> <li>Topic coverage: Which topics are used most? Which are never triggered? Are there queries the agent receives that match no topic at all?</li> <li>Knowledge gaps: What do users ask that the agent can't answer? These are your highest-priority content improvements.</li> <li>User satisfaction: Do users find the agent helpful? Would they use it again?</li> <li>Trends: Is the agent getting better over time? Did the last knowledge update improve resolution rates?</li> </ul> <p>Copilot Studio provides a built-in analytics dashboard, but it has limitations: aggregated metrics only, limited custom filtering, and no way to track custom business KPIs. For serious production monitoring, you need supplementary analytics.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A measurement system that tells you whether the agent is succeeding:</p> <ul> <li>[ ] Resolution visibility: Know what percentage of conversations resolve successfully</li> <li>[ ] Gap identification: Identify questions the agent can't answer (knowledge gaps)</li> <li>[ ] User feedback: Capture direct satisfaction signals from users</li> <li>[ ] Trend tracking: See quality metrics over time to measure improvement</li> <li>[ ] Actionable insights: Data directly drives what to improve next</li> </ul>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#approach-a-built-in-copilot-studio-analytics","title":"Approach A: Built-in Copilot Studio Analytics","text":"<p>Summary: Use the default analytics dashboard included with every Copilot Studio agent. Zero setup required. Technique: Navigate to Analytics in Copilot Studio portal, review built-in charts and metrics.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#how-it-works","title":"How It Works","text":"<p>Copilot Studio automatically tracks conversation metrics and surfaces them in the Analytics section:</p> <pre><code>flowchart TB\n    A[\"Copilot Studio Portal \u2192 Your Agent \u2192 &lt;b&gt;Analytics&lt;/b&gt;\"]\n    A --&gt; B[\"&lt;b&gt;Summary&lt;/b&gt;&lt;br/&gt;Total sessions, resolution rate,&lt;br/&gt;escalation rate, CSAT\"]\n    A --&gt; C[\"&lt;b&gt;Customer Satisfaction&lt;/b&gt;&lt;br/&gt;CSAT scores over time\"]\n    A --&gt; D[\"&lt;b&gt;Sessions&lt;/b&gt;&lt;br/&gt;Session trends, abandonment\"]\n    A --&gt; E[\"&lt;b&gt;Topics&lt;/b&gt;&lt;br/&gt;Per-topic engagement,&lt;br/&gt;resolution, escalation\"]\n    A --&gt; F[\"&lt;b&gt;Billing&lt;/b&gt;&lt;br/&gt;Message consumption\"]</code></pre>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#implementation","title":"Implementation","text":"<p>Step 1: Navigate to analytics</p> <p>No implementation needed. Open Copilot Studio \u2192 Select your agent \u2192 Analytics tab.</p> <p>Step 2: Review key metrics</p> Metric Where to Find What It Tells You Resolution rate Summary dashboard % of conversations where the agent resolved the issue Escalation rate Summary dashboard % conversations transferred to human Abandonment rate Sessions tab % conversations where user left without resolution CSAT score Customer Satisfaction tab Average satisfaction rating (if survey enabled) Top topics Topics tab Which topics are triggered most frequently Unmatched queries Topics tab (Unmatched) User messages that didn't trigger any topic <p>Step 3: Enable the end-of-conversation survey</p> <p>Copilot Studio can show a satisfaction survey at the end of conversations:</p> <ol> <li>Go to Settings \u2192 Agent settings \u2192 Customer satisfaction</li> <li>Enable the survey</li> <li>Choose survey style (thumbs up/down or 1-5 star rating)</li> </ol> <p>The default survey appears after the <code>EndDialog</code> node with <code>conversationOutcome: ResolvedImplied</code>.</p> <p>Step 4: Monitor unmatched queries</p> <p>The \"Unmatched\" section in Analytics \u2192 Topics shows user messages that didn't trigger any topic. This is your knowledge gap detector:</p> <pre><code>Unmatched queries:\n  \"How do I connect to VPN?\"      \u2192 47 times (no VPN topic!)\n  \"Where's the cafeteria?\"        \u2192 23 times (out of scope)\n  \"Reset my password\"             \u2192 15 times (trigger phrase missing?)\n</code></pre> <p>Action: Create topics for frequently unmatched queries, or add trigger phrases to existing topics.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Zero setup. Built-in with every agent. Maintainability \ud83d\udfe2 Platform-managed. No infrastructure to maintain. Channel Compatibility \ud83d\udfe2 Tracks all channels automatically. Customization \ud83d\udd34 Limited to built-in metrics. Can't add custom KPIs or filters. Gap Identification \ud83d\udfe1 Unmatched queries help, but no semantic clustering or priority ranking. Trend Tracking \ud83d\udfe1 Basic time series. No custom date ranges or drill-down."},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#limitations","title":"Limitations","text":"<ul> <li>No custom metrics: You can't track business-specific KPIs (e.g., \"tickets created via agent\" or \"documents downloaded\").</li> <li>Limited filtering: Can't filter by user role, region, or channel easily.</li> <li>No export/API: Data stays in the Copilot Studio portal. Can't feed it into external dashboards or reports.</li> <li>CSAT survey has low completion rates: Typically 10-20% of users complete the survey. The sample may not represent all users.</li> <li>Aggregated only: You can see \"50% resolution rate\" but can't drill into which specific conversations failed and why.</li> </ul>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#approach-b-application-insights-custom-analytics-pipeline","title":"Approach B: Application Insights Custom Analytics Pipeline","text":"<p>Summary: Instrument your agent with <code>LogCustomTelemetryEvent</code> at key conversation milestones. Query with KQL and visualize in Power BI. Technique: Custom telemetry events, Application Insights connected to agent, KQL queries, Power BI dashboard.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Agent topics emit telemetry&lt;br/&gt;at key points\"]\n    B[\"Application Insights&lt;br/&gt;collects all events\"]\n    C[\"&lt;b&gt;KQL queries extract metrics:&lt;/b&gt;&lt;br/&gt;\u2022 Resolution rate (by topic, channel, persona)&lt;br/&gt;\u2022 Knowledge gap queries&lt;br/&gt;\u2022 User satisfaction (from custom survey)&lt;br/&gt;\u2022 Conversation duration and turn count\"]\n    D[\"Power BI dashboard&lt;br/&gt;for trends and drill-down\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre> <p>This extends Gem 004's Application Insights pipeline (originally for debug telemetry) into a full analytics system.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#implementation_1","title":"Implementation","text":"<p>Step 1: Define a telemetry event schema</p> <p>Standardize events across all topics:</p> Event Name When Fired Key Properties <code>ConversationStart</code> First user message UserId, Channel, Persona, Language <code>TopicTriggered</code> Topic activated TopicName, TriggerType, ConversationId <code>KnowledgeSearch</code> Generative answer attempted Query, HasResults, SourceCount <code>ActionExecuted</code> Flow/HTTP call made ActionName, Success, DurationMs <code>ConversationOutcome</code> Conversation ending Outcome (Resolved/Escalated/Abandoned), TurnCount <code>UserFeedback</code> User rates the experience Rating (1-5), FeedbackText, TopicName <p>Step 2: Instrument conversation milestones</p> <pre><code>    # At conversation start\n    - kind: LogCustomTelemetryEvent\n      id: log_convStart\n      eventName: ConversationStart\n      properties: \"={Channel: System.Activity.ChannelId, UserId: System.User.Id, Persona: Global.UserPersona, Language: Global.ResponseLanguage, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # When a topic is triggered\n    - kind: LogCustomTelemetryEvent\n      id: log_topicTriggered\n      eventName: TopicTriggered\n      properties: \"={TopicName: \\\"PasswordReset\\\", TriggerType: \\\"OnRecognizedIntent\\\", ConversationId: System.Conversation.Id}\"\n\n    # After knowledge search\n    - kind: LogCustomTelemetryEvent\n      id: log_knowledgeSearch\n      eventName: KnowledgeSearch\n      properties: \"={Query: System.Activity.Text, HasResults: !IsBlank(Topic.Answer), ConversationId: System.Conversation.Id}\"\n\n    # At conversation end (resolved)\n    - kind: LogCustomTelemetryEvent\n      id: log_resolved\n      eventName: ConversationOutcome\n      properties: \"={Outcome: \\\"Resolved\\\", TurnCount: Global.TurnCount, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Step 3: KQL queries for key metrics</p> <pre><code>// Resolution rate by topic (last 30 days)\ncustomEvents\n| where name == \"ConversationOutcome\"\n| where timestamp &gt; ago(30d)\n| extend Outcome = tostring(customDimensions.Outcome)\n| extend TopicName = tostring(customDimensions.TopicName)\n| summarize\n    Total = count(),\n    Resolved = countif(Outcome == \"Resolved\"),\n    Escalated = countif(Outcome == \"Escalated\"),\n    Abandoned = countif(Outcome == \"Abandoned\")\n    by bin(timestamp, 1d)\n| extend ResolutionRate = round(100.0 * Resolved / Total, 1)\n| render timechart\n</code></pre> <pre><code>// Knowledge gaps \u2014 queries with no results (last 7 days)\ncustomEvents\n| where name == \"KnowledgeSearch\"\n| where timestamp &gt; ago(7d)\n| extend HasResults = tobool(customDimensions.HasResults)\n| extend Query = tostring(customDimensions.Query)\n| where HasResults == false\n| summarize FailCount = count() by Query\n| order by FailCount desc\n| take 20\n</code></pre> <pre><code>// User satisfaction trend\ncustomEvents\n| where name == \"UserFeedback\"\n| where timestamp &gt; ago(30d)\n| extend Rating = toint(customDimensions.Rating)\n| summarize AvgRating = round(avg(Rating), 2), Responses = count() by bin(timestamp, 1d)\n| render timechart\n</code></pre> <pre><code>// Conversation duration and turn count distribution\ncustomEvents\n| where name == \"ConversationOutcome\"\n| where timestamp &gt; ago(7d)\n| extend TurnCount = toint(customDimensions.TurnCount)\n| extend Outcome = tostring(customDimensions.Outcome)\n| summarize AvgTurns = round(avg(TurnCount), 1), MaxTurns = max(TurnCount) by Outcome\n</code></pre> <p>Step 4: Power BI dashboard</p> <p>Connect Power BI to Application Insights and build a live dashboard:</p> Dashboard Section Visualizations Resolution Overview Daily resolution rate (line chart), current rate (KPI card) Top Topics Bar chart of topic frequency, table of per-topic resolution rates Knowledge Gaps Word cloud or table of unanswered queries User Satisfaction CSAT trend (line chart), distribution (histogram) Channel Breakdown Resolution rate by channel (Teams vs Web Chat vs M365) Persona Insights Cost and satisfaction by persona (links to Gem 002 + 012)"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires App Insights + telemetry instrumentation across topics. Maintainability \ud83d\udfe1 KQL queries and Power BI dashboards need occasional updates as the agent evolves. Channel Compatibility \ud83d\udfe2 Telemetry works in all channels. Customization \ud83d\udfe2 Full flexibility. Any metric you can emit, you can query. Gap Identification \ud83d\udfe2 Knowledge gap queries (no-result searches) directly identify improvement priorities. Trend Tracking \ud83d\udfe2 Power BI time series with drill-down."},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#limitations_1","title":"Limitations","text":"<ul> <li>Instrumentation effort: Every topic needs telemetry events at key milestones. Per-topic instrumentation is repetitive.</li> <li>Application Insights cost: High-volume agents generate significant telemetry. At 10K conversations/day, consider sampling or retention policies.</li> <li>KQL learning curve: Writing effective queries requires KQL familiarity.</li> <li>No automatic gap clustering: The knowledge gap query returns raw strings. You need to manually group \"reset password\", \"password reset\", \"can't login\" into one category.</li> <li>Data delay: ~2-5 minutes before events appear in Application Insights. Not real-time.</li> </ul>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#approach-c-post-conversation-satisfaction-survey","title":"Approach C: Post-Conversation Satisfaction Survey","text":"<p>Summary: Ask the user to rate their experience at the end of each conversation with a custom survey. Capture both numeric ratings and freeform feedback. Technique: Adaptive Card survey at conversation end, conditional on conversation outcome, stored via Power Automate or telemetry.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Conversation reaches resolution\"]\n    B[\"Agent: Before you go \u2014&lt;br/&gt;how was your experience?\"]\n    C[\"&lt;b&gt;Adaptive Card&lt;/b&gt;&lt;br/&gt;\u2b50\u2b50\u2b50\u2b50\u2b50 (1-5 rating)&lt;br/&gt;What could I do better? (optional text)&lt;br/&gt;[Submit] [Skip]\"]\n    D[\"Feedback stored +&lt;br/&gt;logged to telemetry\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#implementation_2","title":"Implementation","text":"<p>Step 1: Create a feedback topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Conversation Feedback\n    includeInOnSelectIntent: false\n    triggerQueries: []\n  actions:\n    - kind: SendActivity\n      id: sendSurvey\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"How was your experience?\"\n                  weight: bolder\n                  size: medium\n                - type: TextBlock\n                  text: \"Your feedback helps me improve.\"\n                  isSubtle: true\n                  wrap: true\n                - type: Input.ChoiceSet\n                  id: rating\n                  label: \"Rate your experience\"\n                  style: expanded\n                  isRequired: true\n                  choices:\n                    - title: \"\u2b50\u2b50\u2b50\u2b50\u2b50 Excellent\"\n                      value: \"5\"\n                    - title: \"\u2b50\u2b50\u2b50\u2b50 Good\"\n                      value: \"4\"\n                    - title: \"\u2b50\u2b50\u2b50 Average\"\n                      value: \"3\"\n                    - title: \"\u2b50\u2b50 Below average\"\n                      value: \"2\"\n                    - title: \"\u2b50 Poor\"\n                      value: \"1\"\n                - type: Input.Text\n                  id: feedbackText\n                  label: \"Any additional feedback? (optional)\"\n                  placeholder: \"What could I do better?\"\n                  isMultiline: true\n                  maxLength: 500\n              actions:\n                - type: Action.Submit\n                  title: \"Submit Feedback\"\n                  style: positive\n\n    - kind: AdaptiveCardPrompt\n      id: captureFeedback\n      card:\n        # ... same card as above ...\n      outputVariable: Topic.FeedbackResponse\n\n    # Parse and log\n    - kind: SetVariable\n      id: parseRating\n      variable: init:Topic.Rating\n      value: =Value(Topic.FeedbackResponse.rating)\n\n    - kind: LogCustomTelemetryEvent\n      id: logFeedback\n      eventName: UserFeedback\n      properties: \"={Rating: Topic.Rating, FeedbackText: Topic.FeedbackResponse.feedbackText, ConversationId: System.Conversation.Id, Persona: Global.UserPersona, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    - kind: SendActivity\n      id: thankUser\n      activity:\n        text:\n          - \"Thank you for your feedback! \ud83d\ude4f\"\n</code></pre> <p>Step 2: Trigger the survey at conversation end</p> <p>In agent instructions:</p> <pre><code>instructions: |+\n  ## End of Conversation\n  When you've fully answered the user's question and they indicate they're done \n  (e.g., \"thanks\", \"that's all\", \"goodbye\"), call the \"ConversationFeedback\" topic \n  before ending the conversation.\n\n  Do NOT show the survey if:\n  - The conversation was very short (1-2 turns)\n  - The user is being escalated to a human\n  - The user seems frustrated (adding a survey would make it worse)\n</code></pre> <p>Step 3: Analyze feedback</p> <pre><code>// Average rating by topic (what needs improvement?)\ncustomEvents\n| where name == \"UserFeedback\"\n| where timestamp &gt; ago(30d)\n| extend Rating = toint(customDimensions.Rating)\n| extend TopicName = tostring(customDimensions.TopicName)\n| summarize AvgRating = round(avg(Rating), 2), Count = count() by TopicName\n| order by AvgRating asc\n</code></pre> <pre><code>// Negative feedback text analysis\ncustomEvents\n| where name == \"UserFeedback\"\n| where timestamp &gt; ago(30d)\n| extend Rating = toint(customDimensions.Rating)\n| extend FeedbackText = tostring(customDimensions.FeedbackText)\n| where Rating &lt;= 2 and isnotempty(FeedbackText)\n| project timestamp, Rating, FeedbackText\n| order by timestamp desc\n</code></pre>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Adaptive Card + telemetry logging. Moderate effort. Maintainability \ud83d\udfe2 Survey card and logging are one-time setup. Channel Compatibility \ud83d\udfe1 Adaptive Card required. Fallback to text-based survey for non-card channels. Customization \ud83d\udfe2 Full control over questions, rating scale, and follow-up. Response Rate \ud83d\udd34 10-20% typical. Low sample size may not be representative. Actionability \ud83d\udfe2 Freeform feedback + per-topic ratings directly drive improvements."},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#limitations_2","title":"Limitations","text":"<ul> <li>Low completion rate: Most users skip surveys. Expect 10-20% response rate. The feedback you get is biased \u2014 frustrated or very satisfied users are more likely to respond.</li> <li>Survey fatigue: If the agent asks for feedback every conversation, users will stop responding or feel annoyed. Consider showing the survey 1 in 3 conversations, or only after longer conversations.</li> <li>Delayed signal: Satisfaction is measured after the conversation. You can't intervene during a bad experience \u2014 only learn from it afterward.</li> <li>Qualitative feedback is unstructured: Freeform text requires manual review or LLM-based categorization to extract actionable patterns.</li> </ul>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Built-in Analytics Approach B: App Insights Custom Approach C: Satisfaction Survey Implementation Effort \ud83d\udfe2 Zero \ud83d\udfe1 Medium (3-4 hours) \ud83d\udfe1 Medium (1-2 hours) Customization \ud83d\udd34 None \ud83d\udfe2 Full flexibility \ud83d\udfe2 Custom questions Real-time Visibility \ud83d\udfe1 Some delay \ud83d\udfe2 ~5 min delay + Power BI \ud83d\udd34 After conversation only Gap Identification \ud83d\udfe1 Unmatched queries \ud83d\udfe2 No-result searches + clustering \ud83d\udfe1 Freeform feedback (manual) User Effort \ud83d\udfe2 None (passive) \ud83d\udfe2 None (passive) \ud83d\udd34 Active (survey) Trend Analysis \ud83d\udfe1 Basic \ud83d\udfe2 Full KQL + Power BI \ud83d\udfe1 From logged ratings Best When... Starting out, quick overview Production monitoring, data-driven optimization Direct user voice, qualitative insights"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#recommended-approach","title":"Recommended Approach","text":"<p>Layer all three \u2014 they measure different things:</p> <pre><code>Day 1:      Approach A \u2014 Review built-in dashboard. Costs nothing. Immediate baseline.\nWeek 1:     Approach C \u2014 Add satisfaction survey. Start hearing the user's voice.\nMonth 1:    Approach B \u2014 Instrument custom telemetry. Build the full analytics pipeline.\n</code></pre> <p>Ongoing optimization cycle:</p> <ol> <li>Built-in analytics (A) \u2192 Identify low-resolution topics</li> <li>Custom telemetry (B) \u2192 Drill into WHY those topics fail (knowledge gaps, slow flows)</li> <li>User feedback (C) \u2192 Validate that fixes actually improve satisfaction</li> <li>Repeat</li> </ol>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Built-in analytics have a data retention limit. Copilot Studio analytics data is retained for a limited period (typically 30 days for detailed data, longer for aggregates). If you need historical trend analysis beyond 30 days, export data or use Approach B with Application Insights (configurable retention up to 730 days).</p> <p>Warning</p> <p>CSAT survey response rates drop sharply after the first week. Users who interact with the agent regularly will stop responding to surveys. Show the survey selectively: every 3rd conversation, only after 3+ turn conversations, or on a rotating schedule.</p> <p>Note</p> <p>\"Unmatched queries\" in built-in analytics is your most actionable metric. Check it weekly. The top 10 unmatched queries tell you exactly which topics to create or which trigger phrases to add. This is the highest-ROI analytics action.</p> <p>Note</p> <p>Application Insights telemetry from Gem 004 and Gem 012 feeds directly into this Gem. If you've already set up the telemetry pipeline for debug mode (Gem 004) or token tracking (Gem 012), you have the infrastructure. This Gem adds conversation outcome and satisfaction events to the same pipeline.</p>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 004: Debug Mode for M365 Copilot \u2014 The Application Insights pipeline established in Gem 004 is extended here for conversation analytics</li> <li>Gem 012: Cost Estimation and Token Budget \u2014 Cost and quality are the two sides of agent performance. This Gem measures quality; Gem 012 measures cost.</li> <li>Gem 013: Testing Strategies \u2014 Pre-deployment testing (Gem 013) validates correctness; this Gem validates real-world effectiveness.</li> <li>Gem 008: Knowledge Source Optimization \u2014 Knowledge gap analysis (Approach B) directly identifies documents to create or improve.</li> </ul>"},{"location":"gems/GEM-016-conversation-analytics-and-quality-measurement/#references","title":"References","text":"<ul> <li>Microsoft Learn: Analytics in Copilot Studio</li> <li>Microsoft Learn: Customer satisfaction in Copilot Studio</li> <li>Microsoft Learn: Application Insights for Copilot Studio</li> <li>KQL Quick Reference</li> <li>Power BI + Application Insights</li> </ul> <p>Gem 016 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/","title":"Gem 017: Multi-Tenant Agent Configuration","text":"<p>One agent, many clients \u2014 different knowledge, branding, and behavior without deploying separate agents.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#classification","title":"Classification","text":"Attribute Value Category Context &amp; State Complexity \u2b50\u2b50\u2b50\u2b50 (Complex \u2014 configuration architecture + runtime tenant resolution) Channels All Prerequisite Gems Gem 001 (persistence patterns), Gem 002 (persona adaptation)"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#the-problem","title":"The Problem","text":"<p>You've built a great Copilot Studio agent for Client A. Now Client B wants the same agent with different knowledge sources, branding, and slightly different instructions. Client C is next. Then D.</p> <p>The naive approach \u2014 clone the agent per client \u2014 creates a maintenance nightmare:</p> <ul> <li>Feature updates: Fix a bug or add a feature? Apply it to N agents manually. Miss one, and that client has a broken experience.</li> <li>Instruction drift: Over time, cloned agents diverge. Client A's agent gets improvements that never reach Client C.</li> <li>Knowledge management: Each client has separate SharePoint sites, but the agent logic for searching is identical. You're duplicating infrastructure for no reason.</li> <li>Cost: N agents = N Power Platform environments (potentially), N sets of flows, N maintenance windows.</li> </ul> <p>The ideal: one agent deployment that adapts its behavior, knowledge, and branding at runtime based on which tenant (client, department, or business unit) the user belongs to.</p> <p>This pattern is common in SaaS platforms (\"multi-tenancy\") but rarely discussed in the Copilot Studio context.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A single agent that serves multiple tenants with isolated configuration:</p> <ul> <li>[ ] Tenant isolation: Each tenant gets its own knowledge sources, instructions, and branding \u2014 no data leakage between tenants</li> <li>[ ] Single codebase: Agent topics, flows, and logic are shared. Only configuration varies.</li> <li>[ ] Runtime resolution: The correct tenant configuration is loaded automatically based on user identity</li> <li>[ ] Easy onboarding: Adding a new tenant requires configuration, not code changes</li> <li>[ ] Centralized updates: Bug fixes and features propagate to all tenants simultaneously</li> </ul>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#approach-a-environment-variables-per-power-platform-environment","title":"Approach A: Environment Variables per Power Platform Environment","text":"<p>Summary: Deploy the same solution to separate Power Platform environments \u2014 one per tenant. Each environment has its own environment variable values (SharePoint URL, instructions, branding). Technique: Power Platform managed solutions, environment-specific variable values, solution import per environment.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Solution Package&lt;/b&gt;&lt;br/&gt;(shared)\"]\n    B[\"&lt;b&gt;Environment: Client-A&lt;/b&gt;&lt;br/&gt;SharePointUrl: clienta.sharepoint.com/kb&lt;br/&gt;AgentName: ClientA Assistant&lt;br/&gt;CustomInstructions: ClientA support agent\"]\n    C[\"&lt;b&gt;Environment: Client-B&lt;/b&gt;&lt;br/&gt;SharePointUrl: clientb.sharepoint.com/kb&lt;br/&gt;AgentName: ClientB Helper&lt;br/&gt;CustomInstructions: Serve ClientB employees\"]\n    D[\"&lt;b&gt;Environment: Client-C&lt;/b&gt;&lt;br/&gt;SharePointUrl: clientc.sharepoint.com/docs&lt;br/&gt;AgentName: ClientC Agent&lt;br/&gt;CustomInstructions: ClientC policy advisor\"]\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D</code></pre> <p>Same agent, same topics, same flows. Only the environment variable values differ.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#implementation","title":"Implementation","text":"<p>Step 1: Define configurable elements as environment variables</p> <pre><code>&lt;!-- In the solution, define all tenant-specific config as env vars --&gt;\n&lt;environmentvariabledefinition schemaname=\"agent_TenantName\"&gt;\n  &lt;defaultvalue&gt;Default Tenant&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_SharePointSiteUrl\"&gt;\n  &lt;defaultvalue&gt;https://default.sharepoint.com/kb&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_AgentDisplayName\"&gt;\n  &lt;defaultvalue&gt;Support Assistant&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_CustomInstructions\"&gt;\n  &lt;defaultvalue&gt;You are a helpful support assistant.&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_BrandColor\"&gt;\n  &lt;defaultvalue&gt;accent&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_SupportEmail\"&gt;\n  &lt;defaultvalue&gt;support@contoso.com&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n</code></pre> <p>Step 2: Reference env vars throughout the agent</p> <p>In agent instructions:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: =@environmentVariables(\"agent_AgentDisplayName\")\ninstructions: |+\n  # Agent Identity\n  You are **{Env.agent_AgentDisplayName}**, the AI assistant for {Env.agent_TenantName}.\n\n  {Env.agent_CustomInstructions}\n\n  ## Knowledge Source\n  You search the knowledge base at the configured SharePoint site.\n\n  ## Escalation\n  For human support, direct users to: {Env.agent_SupportEmail}\n</code></pre> <p>In knowledge source configuration:</p> <pre><code>kind: KnowledgeSourceConfiguration\nsource:\n  kind: SharePointSearchSource\n  site: \"@environmentVariables('agent_SharePointSiteUrl')\"\n</code></pre> <p>In topics (branded messages):</p> <pre><code>    - kind: SendActivity\n      id: greetUser\n      activity:\n        text:\n          - \"Welcome to **{Env.agent_AgentDisplayName}**! How can I help you today?\"\n</code></pre> <p>Step 3: Deploy to multiple environments</p> <pre><code># Export from dev\npac solution export --name MultiTenantAgent --path ./MultiTenantAgent.zip --managed\n\n# Import to Client A environment\npac auth create --environment \"https://clienta.crm.dynamics.com\"\npac solution import --path ./MultiTenantAgent.zip\n\n# Import to Client B environment\npac auth create --environment \"https://clientb.crm.dynamics.com\"\npac solution import --path ./MultiTenantAgent.zip\n\n# Set env vars per environment (via Power Apps admin or API)\n</code></pre> <p>Step 4: Per-environment variable configuration</p> <p>After import, set environment variable values in each environment:</p> <ol> <li>Go to Power Apps \u2192 Solutions \u2192 Default Solution \u2192 Environment Variables</li> <li>Set <code>agent_SharePointSiteUrl</code>, <code>agent_TenantName</code>, etc. for the specific tenant</li> <li>Publish the agent</li> </ol>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Standard Power Platform ALM. Well-documented solution import process. Maintainability \ud83d\udfe2 One solution, one codebase. Updates deploy via re-import to each environment. Tenant Isolation \ud83d\udfe2 Complete isolation \u2014 separate environments, separate databases. Scalability \ud83d\udfe1 Each tenant = separate environment. Environment creation may require admin and licensing. Onboarding Speed \ud83d\udfe1 New tenant: create environment + import solution + set variables. ~1-2 hours per tenant. Runtime Resolution \ud83d\udfe2 No resolution needed \u2014 each environment IS the tenant."},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#limitations","title":"Limitations","text":"<ul> <li>Environment proliferation: 20 tenants = 20 environments. Environment management overhead scales linearly.</li> <li>Power Platform licensing: Each environment may require licensing. Check your tenant's environment capacity.</li> <li>Update deployment: Updating 20 environments requires 20 solution imports (automatable via ALM pipelines but still operational overhead).</li> <li>No cross-tenant features: An admin can't view metrics across all tenants from a single dashboard without external aggregation.</li> <li>User routing: Users must be directed to the correct environment's agent URL. Doesn't auto-detect which tenant a user belongs to.</li> </ul>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#approach-b-runtime-configuration-table-in-dataverse","title":"Approach B: Runtime Configuration Table in Dataverse","text":"<p>Summary: Store all tenant configuration in a single Dataverse table. At conversation start, detect the user's tenant and load the matching configuration row. Technique: Dataverse configuration table, Power Automate or Graph API for tenant detection, global variables populated at runtime.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User starts conversation\"]\n    B[\"&lt;b&gt;Detect tenant&lt;/b&gt;&lt;br/&gt;Email domain \u2192 clienta.com \u2192 TenantId=ClientA&lt;br/&gt;OR: Entra group \u2192 ClientA-Users&lt;br/&gt;OR: Explicit selection \u2192 User picks tenant\"]\n    C[\"&lt;b&gt;Load config from Dataverse&lt;/b&gt;&lt;br/&gt;TenantConfig table \u2192&lt;br/&gt;Row where TenantId = ClientA\"]\n    D[\"&lt;b&gt;Populate global variables&lt;/b&gt;&lt;br/&gt;Global.TenantName = Client A&lt;br/&gt;Global.SharePointUrl = clienta.sharepoint.com/kb&lt;br/&gt;Global.CustomInstructions = ...&lt;br/&gt;Global.SupportEmail = support@clienta.com\"]\n    E[\"Agent uses Global.* variables&lt;br/&gt;for all tenant-specific behavior\"]\n    A --&gt; B --&gt; C --&gt; D --&gt; E</code></pre> <p>One environment, one agent, one Dataverse table with N rows (one per tenant).</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#implementation_1","title":"Implementation","text":"<p>Step 1: Create the TenantConfig Dataverse table</p> Column Type Description <code>TenantId</code> Single line text (Primary) Unique tenant identifier <code>TenantName</code> Single line text Display name <code>EmailDomain</code> Single line text Email domain for auto-detection (e.g., \"clienta.com\") <code>SharePointUrl</code> URL Tenant-specific knowledge source URL <code>CustomInstructions</code> Multi-line text Tenant-specific agent instructions <code>SupportEmail</code> Email Escalation email <code>BrandGreeting</code> Single line text Welcome message <code>MaxTurns</code> Integer Per-tenant conversation limit <code>Language</code> Choice Default language <code>IsActive</code> Boolean Enable/disable tenant <p>Step 2: Auto-detect tenant from user's email domain</p> <pre><code>Power Automate Flow: GetTenantConfig\n  Trigger: Run a flow from Copilot\n  Input: userEmail (Text)\n\n  Action: Extract domain\n    Expression: split(userEmail, '@')[1]  \u2192 \"clienta.com\"\n\n  Action: List Rows (Dataverse)\n    Table: TenantConfig\n    Filter: cr_emaildomain eq '{domain}' AND cr_isactive eq true\n    Top Count: 1\n\n  Condition: Row found?\n    Yes \u2192 Output all config fields\n    No \u2192 Output default configuration\n</code></pre> <p>Step 3: Load tenant config at conversation start</p> <p>Via agent instructions (M365 Copilot compatible):</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Multi-Tenant Agent\ninstructions: |+\n  # Multi-Tenant Agent\n\n  ## CRITICAL: Load Tenant Configuration\n  At the START of every conversation, call \"GetTenantConfig\" with the user's email.\n  Use the returned configuration for ALL subsequent behavior:\n\n  - Use `tenantName` in greetings: \"Welcome to [tenantName]!\"\n  - Follow `customInstructions` for tone and behavior\n  - Search knowledge at `sharePointUrl`\n  - Escalate to `supportEmail`\n\n  If no tenant configuration is found, use general-purpose defaults.\n</code></pre> <p>Or via ConversationStart topic:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnConversationStart\n  id: main\n  actions:\n    - kind: InvokeFlow\n      id: loadTenantConfig\n      flowId: \"@environmentVariables('GetTenantConfigFlowId')\"\n      inputs:\n        userEmail: =System.User.Email\n      outputVariable: Topic.TenantConfig\n\n    - kind: SetVariable\n      id: setTenantName\n      variable: Global.TenantName\n      value: =If(IsBlank(Topic.TenantConfig.tenantName), \"Support\", Topic.TenantConfig.tenantName)\n\n    - kind: SetVariable\n      id: setSharePointUrl\n      variable: Global.SharePointUrl\n      value: =Topic.TenantConfig.sharePointUrl\n\n    - kind: SetVariable\n      id: setInstructions\n      variable: Global.CustomInstructions\n      value: =Topic.TenantConfig.customInstructions\n\n    - kind: SetVariable\n      id: setSupportEmail\n      variable: Global.SupportEmail\n      value: =If(IsBlank(Topic.TenantConfig.supportEmail), \"support@contoso.com\", Topic.TenantConfig.supportEmail)\n\n    - kind: SendActivity\n      id: tenantGreeting\n      activity:\n        text:\n          - =If(IsBlank(Topic.TenantConfig.brandGreeting), \"Hello! How can I help?\", Topic.TenantConfig.brandGreeting)\n</code></pre> <p>Step 4: Use tenant config in knowledge searches</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: tenantAwareSearch\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n      sharePointSearchDataSource:\n        site: =Global.SharePointUrl\n      customInstructions: =Global.CustomInstructions\n</code></pre> <p>Note: Dynamic SharePoint URL in <code>SearchAndSummarizeContent</code> depends on platform support for variable-based site configuration. If not supported, use a topic-level HTTP call to SharePoint search API as a workaround.</p> <p>Step 5: Admin UI for tenant management</p> <p>Create a simple Power App (Model-driven or Canvas) on top of the TenantConfig table:</p> <pre><code>Tenant Management App (Power Apps)\n    \u2502\n    \u251c\u2500\u2500 List all tenants (grid view)\n    \u251c\u2500\u2500 Edit tenant config (form view)\n    \u251c\u2500\u2500 Add new tenant (new row)\n    \u251c\u2500\u2500 Activate/deactivate tenant (toggle IsActive)\n    \u2514\u2500\u2500 Test tenant config (preview greeting, instructions)\n</code></pre> <p>Non-technical administrators can onboard new tenants by filling in a form \u2014 no code changes needed.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Dataverse table + detection flow + variable mapping. Moderate setup. Maintainability \ud83d\udfe2 Single agent, single environment. Config changes via Dataverse rows. Tenant Isolation \ud83d\udfe1 Logical isolation (config rows), not physical isolation (shared environment). Scalability \ud83d\udfe2 Adding a tenant = adding a Dataverse row. Minutes, not hours. Onboarding Speed \ud83d\udfe2 Non-technical: fill a form. ~15 minutes per tenant. Runtime Resolution \ud83d\udfe2 Auto-detected from email domain. Zero user friction."},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#limitations_1","title":"Limitations","text":"<ul> <li>Shared environment risk: All tenants share one Power Platform environment. A configuration error could affect all tenants.</li> <li>Knowledge source limitation: Dynamic SharePoint URL in generative answers may not be fully supported. Validate with your platform version.</li> <li>Instruction token cost: Loading long custom instructions from Dataverse into the system prompt increases token usage per conversation.</li> <li>Config caching: Loading config from Dataverse every conversation adds latency (~1-2s). Cache with Gem 001's persistence pattern for repeat users.</li> <li>No physical data isolation: Unlike Approach A, tenant data isn't in separate databases. For compliance-sensitive scenarios, this may be insufficient.</li> </ul>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#approach-c-agent-cloning-with-vs-code-extension","title":"Approach C: Agent Cloning with VS Code Extension","text":"<p>Summary: Use the Copilot Studio VS Code Extension to clone and customize the agent per tenant. Each tenant gets a customized copy managed via git. Technique: VS Code Extension clone, git branching per tenant, YAML customization, selective sync.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Base Agent&lt;/b&gt;&lt;br/&gt;(git main branch)\"]\n    subgraph branchA [\"Branch: tenant/client-a\"]\n        B1[\"agent.yaml (customized name, instructions)\"]\n        B2[\"knowledge/ (client-a docs)\"]\n        B3[\"topics/ (shared, inherited from main)\"]\n    end\n    subgraph branchB [\"Branch: tenant/client-b\"]\n        C1[\"agent.yaml (customized)\"]\n        C2[\"knowledge/ (client-b docs)\"]\n        C3[\"topics/ (shared)\"]\n    end\n    subgraph branchC [\"Branch: tenant/client-c\"]\n        D1[\"...\"]\n    end\n    A --&gt; branchA\n    A --&gt; branchB\n    A --&gt; branchC\n    E[\"&lt;b&gt;Updates:&lt;/b&gt;&lt;br/&gt;main branch fix \u2192&lt;br/&gt;cherry-pick to all tenant branches\"]</code></pre> <p>Each tenant is a git branch of the same base agent. Shared topics stay on <code>main</code>; tenant-specific customizations (instructions, knowledge, branding) are branch-specific.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#implementation_2","title":"Implementation","text":"<p>Step 1: Clone the base agent</p> <pre><code>1. Open VS Code with Copilot Studio Extension\n2. Clone the base agent to a local workspace\n3. Initialize git: git init\n4. Commit the base: git add . &amp;&amp; git commit -m \"Base agent\"\n</code></pre> <p>Step 2: Create tenant branches</p> <pre><code># Create Client A branch\ngit checkout -b tenant/client-a\n\n# Edit agent.yaml \u2014 customize name, instructions\n# Edit knowledge sources \u2014 point to Client A's SharePoint\n# Commit customizations\ngit add . ; git commit -m \"Client A customization\"\n\n# Apply to Copilot Studio\n# VS Code Extension \u2192 Apply Changes (to Client A's environment)\n</code></pre> <p>Step 3: Propagate shared updates</p> <pre><code># Fix a bug in a shared topic (on main branch)\ngit checkout main\n# Edit topics/error-handler.topic.yaml\ngit commit -am \"Fix error handler edge case\"\n\n# Propagate to all tenants\ngit checkout tenant/client-a\ngit merge main\n# Resolve any conflicts (rare if customizations are limited to config)\n# VS Code Extension \u2192 Apply Changes\n\ngit checkout tenant/client-b\ngit merge main\n# Apply changes...\n</code></pre> <p>Step 4: Automation with scripts</p> <pre><code># Script: deploy-all-tenants.ps1\n$tenants = @(\"tenant/client-a\", \"tenant/client-b\", \"tenant/client-c\")\n\nforeach ($tenant in $tenants) {\n    git checkout $tenant\n    git merge main --no-edit\n    # pac solution pack + import (or VS Code Extension sync)\n    Write-Host \"Deployed to $tenant\"\n}\n</code></pre>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires git fluency and VS Code Extension workflow. Maintainability \ud83d\udfe1 Merge conflicts possible. Disciplined branching required. Tenant Isolation \ud83d\udfe2 Complete \u2014 separate agent instances per tenant. Scalability \ud83d\udd34 Git branching becomes unwieldy past 10-15 tenants. Onboarding Speed \ud83d\udfe1 Create branch + customize + deploy. ~30-60 minutes per tenant. Runtime Resolution \ud83d\udfe2 No resolution needed \u2014 each tenant has its own agent URL."},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#limitations_2","title":"Limitations","text":"<ul> <li>Branch management overhead: At 20+ tenants, managing and merging branches becomes a full-time job. Git conflicts multiply.</li> <li>No dynamic configuration: Changing a tenant's greeting requires a code change (YAML edit), commit, merge, and redeploy. Not admin-friendly.</li> <li>Requires developer skills: Git branching, VS Code Extension, and solution deployment are developer-level tasks. No self-service for non-technical administrators.</li> <li>No centralized analytics: Each tenant's agent is a separate instance. Cross-tenant metrics require aggregation in a shared Application Insights instance.</li> </ul>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Env per Environment Approach B: Runtime Config Table Approach C: Git Branching Implementation Effort \ud83d\udfe1 Medium (per environment) \ud83d\udfe1 Medium (one-time) \ud83d\udfe1 Medium (git setup) Tenant Isolation \ud83d\udfe2 Physical (separate envs) \ud83d\udfe1 Logical (shared env) \ud83d\udfe2 Physical (separate agents) Scalability \ud83d\udfe1 Linear env overhead \ud83d\udfe2 Config row per tenant \ud83d\udd34 Branch complexity grows Onboarding Speed \ud83d\udfe1 1-2 hours (env setup) \ud83d\udfe2 15 min (fill a form) \ud83d\udfe1 30-60 min (branch + deploy) Non-Technical Admin \ud83d\udd34 Requires PA admin \ud83d\udfe2 Power App form \ud83d\udd34 Requires developer Update Propagation \ud83d\udfe1 Re-import to each env \ud83d\udfe2 Instant (shared agent) \ud83d\udfe1 Merge to each branch Dynamic Config Changes \ud83d\udd34 Redeploy required \ud83d\udfe2 Edit Dataverse row \ud83d\udd34 Code change + redeploy Best When... Compliance requires physical isolation Rapid onboarding, admin self-service Developer-centric, &lt;10 tenants"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#recommended-approach","title":"Recommended Approach","text":"<p>For most multi-tenant scenarios: Approach B (Runtime Config Table) \u2014 fastest onboarding, admin-friendly, and the single-codebase benefit is enormous. One bug fix benefits all tenants instantly.</p> <p>Choose Approach A when: Regulatory compliance demands physical data isolation between tenants (healthcare, finance, government). The environment-level separation is the strongest isolation guarantee.</p> <p>Choose Approach C when: You have &lt;10 tenants, a developer-centric team, and need maximum per-tenant customization (not just config \u2014 different topic logic per tenant). The git branching model gives full flexibility at the cost of operational overhead.</p> <p>Hybrid pattern: Use Approach B as the baseline, with Approach A for compliance-sensitive tenants that require physical isolation. Most tenants share the single-environment agent; high-compliance tenants get dedicated environments.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Dynamic SharePoint URL in <code>SearchAndSummarizeContent</code> may not be supported. The <code>site</code> property in knowledge source configuration may require a static environment variable, not a runtime variable. Test whether <code>=Global.SharePointUrl</code> works in Approach B. If not, use a Power Automate flow to query SharePoint search API directly.</p> <p>Warning</p> <p>ConversationStart doesn't fire in M365 Copilot (see Gotchas Compendium). Tenant detection in ConversationStart only works in Teams and Web Chat. For M365 Copilot, use agent instructions to mandate calling the GetTenantConfig action before any response.</p> <p>Warning</p> <p>Shared environment means shared capacity. In Approach B, all tenants share one environment's Dataverse capacity, Power Automate quotas, and AI capacity. A high-volume tenant could impact others. Monitor per-tenant usage (Gem 012) and set quotas if needed.</p> <p>Note</p> <p>Environment variable values can be set via API. For Approach A at scale, don't manually configure each environment. Use the Power Platform Admin API to programmatically set environment variable values during deployment.</p>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context \u2014 Cache tenant config per user to avoid loading every conversation</li> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Tenant-specific instructions are a form of \"persona\" at the organizational level</li> <li>Gem 007: Role-Based Feature Gating \u2014 Tenant admin vs tenant user role gating within a shared agent</li> <li>Gem 005: Multi-Language Agent Response \u2014 Tenant may dictate default language</li> </ul>"},{"location":"gems/GEM-017-multi-tenant-agent-configuration/#references","title":"References","text":"<ul> <li>Microsoft Learn: Environment variables in Power Platform</li> <li>Microsoft Learn: Power Platform ALM with solutions</li> <li>Microsoft Learn: Copilot Studio VS Code Extension</li> <li>Microsoft Learn: Power Platform environments</li> </ul> <p>Gem 017 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/","title":"Gem 018: SharePoint Document Retrieval and Display","text":"<p>Beyond knowledge search \u2014 find, list, and link to specific SharePoint documents on demand.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 search API integration + result formatting) Channels All (Adaptive Card rendering varies) Prerequisite Gems None (Gem 008 complementary for knowledge optimization)"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#the-problem","title":"The Problem","text":"<p>Gem 008 (Knowledge Source Optimization) addresses how to get better answers from documents. But sometimes users don't want an answer \u2014 they want the document itself:</p> <ul> <li>\"Send me the latest expense report template.\"</li> <li>\"Find all compliance documents updated in January 2026.\"</li> <li>\"Where's the architecture diagram for Project Atlas?\"</li> <li>\"Show me documents tagged 'onboarding'.\"</li> </ul> <p>Copilot Studio's generative answers (<code>SearchAndSummarizeContent</code>) searches content and generates a synthesized response. But it doesn't return a list of matching documents with download links. The user gets an answer but can't access the source document directly.</p> <p>The gap: document discovery and retrieval \u2014 finding specific files, presenting them as a browsable list, and giving users direct links to open or download them. This is a search-and-display problem, not a question-answering problem.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that can find and present SharePoint documents:</p> <ul> <li>[ ] Search by query: Natural language search (\"find expense templates\") returns matching documents</li> <li>[ ] Filter by metadata: Filter by date, author, file type, or custom metadata</li> <li>[ ] Direct links: Results include clickable links to view or download the document</li> <li>[ ] Structured results: Documents presented in a scannable list, not a prose paragraph</li> <li>[ ] Pagination: Large result sets are pageable (\"show me the next 5\")</li> </ul>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#approach-a-power-automate-sharepoint-search","title":"Approach A: Power Automate + SharePoint Search","text":"<p>Summary: Use a Power Automate flow to query SharePoint's search API, format results, and return a structured document list to the agent. Technique: Power Automate cloud flow, SharePoint \"Send an HTTP request\" action (search API), result formatting, Adaptive Card display.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;User:&lt;/b&gt;&lt;br/&gt;Find onboarding documents\"]\n    B[\"Agent topic \u2192 InvokeFlow: SearchDocuments&lt;br/&gt;Input: query, fileType, folder\"]\n    C[\"&lt;b&gt;Power Automate&lt;/b&gt;&lt;br/&gt;SharePoint HTTP: /_api/search/query\"]\n    D[\"Parse results \u2192&lt;br/&gt;format as document list\"]\n    E[\"Agent receives:&lt;br/&gt;title, url, modified, author, fileType\"]\n    F[\"Agent displays results as&lt;br/&gt;Adaptive Card or formatted text\"]\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#implementation","title":"Implementation","text":"<p>Step 1: Create the SharePoint Search flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: searchQuery (Text), fileType (Text, optional), maxResults (Number, default 5)\n\nAction: Send an HTTP request to SharePoint\n  Site: @environmentVariables('SharePointSiteUrl')\n  Method: GET\n  URI: /_api/search/query?querytext='{searchQuery}'&amp;rowlimit={maxResults}&amp;selectproperties='Title,Path,LastModifiedTime,Author,FileExtension,Size'\n  Headers:\n    Accept: application/json;odata=verbose\n\nAction: Parse JSON\n  Content: body('Send_an_HTTP_request_to_SharePoint')\n  Schema: (auto-generate from sample response)\n\nAction: Select (transform results)\n  From: body('Parse_JSON')?['d']?['query']?['PrimaryQueryResult']?['RelevantResults']?['Table']?['Rows']?['results']\n  Map:\n    title: item()?['Cells']?['results'][index_of_Title]?['Value']\n    url: item()?['Cells']?['results'][index_of_Path]?['Value']\n    modified: item()?['Cells']?['results'][index_of_LastModifiedTime]?['Value']\n    author: item()?['Cells']?['results'][index_of_Author]?['Value']\n    fileType: item()?['Cells']?['results'][index_of_FileExtension]?['Value']\n\nCondition: Result count &gt; 0?\n  Yes \u2192 Output: documents (Array), resultCount (Number)\n  No \u2192 Output: documents (empty), resultCount = 0\n</code></pre> <p>Step 2: Display results in the agent</p> <p>Option 1: Formatted text (all channels)</p> <pre><code>    - kind: InvokeFlow\n      id: searchDocs\n      flowId: \"@environmentVariables('SearchDocumentsFlowId')\"\n      inputs:\n        searchQuery: =Topic.SearchTerm\n        maxResults: 5\n      outputVariable: Topic.SearchResults\n\n    - kind: ConditionGroup\n      id: checkResults\n      conditions:\n        - id: hasResults\n          condition: =Topic.SearchResults.resultCount &gt; 0\n          actions:\n            - kind: SendActivity\n              id: showResults\n              activity:\n                text:\n                  - \"\ud83d\udcc4 **Found {Topic.SearchResults.resultCount} documents:**\\n\\n{Topic.SearchResults.formattedList}\\n\\nWould you like me to search for something else?\"\n      elseActions:\n        - kind: SendActivity\n          id: noResults\n          activity:\n            text:\n              - \"I couldn't find documents matching \\\"{Topic.SearchTerm}\\\". Try:\\n- Different keywords\\n- Broader search terms\\n- Checking the document library directly: [SharePoint]({Env.agent_SharePointSiteUrl})\"\n</code></pre> <p>Option 2: Adaptive Card with clickable links (card-capable channels)</p> <pre><code>    - kind: SendActivity\n      id: sendResultsCard\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"\ud83d\udcc4 Document Search Results\"\n                  weight: bolder\n                  size: medium\n                - type: TextBlock\n                  text: \"Found {Topic.SearchResults.resultCount} documents for \\\"{Topic.SearchTerm}\\\"\"\n                  isSubtle: true\n                  wrap: true\n                # Dynamic result items rendered by the flow as pre-formatted JSON\n                - type: Container\n                  items:\n                    - type: FactSet\n                      facts:\n                        - title: \"1.\"\n                          value: \"[Document Title](url) \u2014 Modified: date\"\n                        # ... additional results ...\n              actions:\n                - type: Action.OpenUrl\n                  title: \"\ud83d\udd0d Search in SharePoint\"\n                  url: \"{Env.agent_SharePointSiteUrl}/_layouts/15/search.aspx?q={Topic.SearchTerm}\"\n</code></pre> <p>Step 3: Add filters for refined search</p> <pre><code>    - kind: Question\n      id: askSearchTerm\n      variable: init:Topic.SearchTerm\n      prompt: \"What document are you looking for?\"\n      entity: StringPrebuiltEntity\n\n    - kind: Question\n      id: askFileType\n      variable: init:Topic.FileTypeFilter\n      prompt: \"Any specific file type? (or say 'any')\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"any\"\n          synonyms: [\"all\", \"no filter\", \"doesn't matter\"]\n        - value: \"docx\"\n          synonyms: [\"word\", \"document\"]\n        - value: \"xlsx\"\n          synonyms: [\"excel\", \"spreadsheet\"]\n        - value: \"pptx\"\n          synonyms: [\"powerpoint\", \"presentation\"]\n        - value: \"pdf\"\n          synonyms: [\"pdf\"]\n</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 SharePoint search API parsing is moderately complex. Flow design requires API knowledge. Maintainability \ud83d\udfe2 Flow is reusable across topics. Changes to result formatting in one place. Channel Compatibility \ud83d\udfe2 Text format works everywhere. Adaptive Card for richer display. Search Quality \ud83d\udfe2 SharePoint search is mature \u2014 full-text, metadata, managed properties. Direct Links \ud83d\udfe2 Results include full URLs to documents. Pagination \ud83d\udfe1 Possible but requires flow modification (pass startRow parameter)."},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#limitations","title":"Limitations","text":"<ul> <li>SharePoint search API complexity: The search REST API returns deeply nested JSON. Parsing it in Power Automate requires careful configuration.</li> <li>Permissions: The flow must have access to the SharePoint site. Users see results based on the flow's permissions, not their own \u2014 unless you use delegated authentication.</li> <li>No preview: Results link to documents but don't show a preview. The user must click to see the content.</li> <li>Flow latency: SharePoint search + result parsing adds 2-4 seconds.</li> </ul>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#approach-b-microsoft-graph-search-api-via-http-request","title":"Approach B: Microsoft Graph Search API via HTTP Request","text":"<p>Summary: Call the Graph Search API directly from the agent using <code>HttpRequest</code> nodes. No Power Automate in the loop. Technique: <code>HttpRequest</code> to Graph API <code>/search/query</code> endpoint, result parsing, direct document links.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;User:&lt;/b&gt;&lt;br/&gt;Find expense templates\"]\n    B[\"&lt;b&gt;HttpRequest:&lt;/b&gt;&lt;br/&gt;POST /v1.0/search/query&lt;br/&gt;entityTypes: driveItem\"]\n    C[\"Parse results \u2192 format as list\"]\n    D[\"Display with direct links\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#implementation_1","title":"Implementation","text":"<p>Step 1: Call Graph Search API</p> <pre><code>    - kind: HttpRequest\n      id: http_graphSearch\n      method: POST\n      url: \"https://graph.microsoft.com/v1.0/search/query\"\n      headers:\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"requests\": [{\n            \"entityTypes\": [\"driveItem\"],\n            \"query\": {\n              \"queryString\": \"{Topic.SearchTerm} filetype:{Topic.FileTypeFilter}\"\n            },\n            \"from\": 0,\n            \"size\": 5,\n            \"fields\": [\"name\", \"webUrl\", \"lastModifiedDateTime\", \"lastModifiedBy\", \"size\"]\n          }]\n        }\n      responseType: json\n      responseVariable: Topic.GraphResults\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.GraphStatus\n      timeout: 10000\n</code></pre> <p>Step 2: Parse and display results</p> <pre><code>    - kind: ConditionGroup\n      id: checkGraphResults\n      conditions:\n        - id: hasHits\n          condition: =Topic.GraphStatus &gt;= 200 &amp;&amp; Topic.GraphStatus &lt; 300\n          actions:\n            - kind: SendActivity\n              id: showGraphResults\n              activity:\n                text:\n                  - \"\ud83d\udcc4 **Documents found:**\\n\\n{Topic.FormattedResults}\\n\\nClick any link to open the document.\"\n      elseActions:\n        - kind: SendActivity\n          id: graphError\n          activity:\n            text:\n              - \"I'm having trouble searching documents right now. You can search directly: [SharePoint]({Env.agent_SharePointSiteUrl})\"\n</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Graph API call is simpler than SharePoint REST, but authentication setup required. Maintainability \ud83d\udfe2 Single HTTP call. No Power Automate dependency. Channel Compatibility \ud83d\udfe2 HTTP nodes work everywhere. Search Quality \ud83d\udfe2 Graph Search is the most powerful Microsoft search API \u2014 cross-site, cross-service. Direct Links \ud83d\udfe2 <code>webUrl</code> field provides direct document links. Pagination \ud83d\udfe2 <code>from</code> and <code>size</code> parameters support native pagination."},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#limitations_1","title":"Limitations","text":"<ul> <li>Authentication: Graph API requires a bearer token. The agent must authenticate to Graph \u2014 either via the user's delegated token or a service principal.</li> <li>Permission scope: <code>Files.Read.All</code> or <code>Sites.Read.All</code> required. Admin consent may be needed.</li> <li>JSON parsing complexity: Graph Search response structure is deeply nested. Extracting document fields requires careful parsing in Power Fx.</li> <li>Cross-site results: Graph Search can return results from any SharePoint site the user (or service) has access to \u2014 this may be too broad. Use <code>site</code> or <code>path</code> filters to scope.</li> </ul>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#approach-c-generative-orchestration-with-find-document-instructions","title":"Approach C: Generative Orchestration with \"Find Document\" Instructions","text":"<p>Summary: Instruct the agent to use its knowledge source for document discovery \u2014 not just Q&amp;A. The LLM identifies relevant documents from search results and presents them as a list. Technique: Agent instructions that mandate document listing behavior, <code>SearchAndSummarizeContent</code> with specific instructions, LLM formats results as document references.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;User:&lt;/b&gt;&lt;br/&gt;Find the latest expense report template\"]\n    B[\"&lt;b&gt;Agent instructions:&lt;/b&gt;&lt;br/&gt;When asked to find/locate/show documents,&lt;br/&gt;search knowledge base and list matches\"]\n    C[\"SearchAndSummarizeContent executes\"]\n    D[\"&lt;b&gt;LLM response:&lt;/b&gt;&lt;br/&gt;1. Expense Report Template v3 \u2014 Jan 2026&lt;br/&gt;2. Expense Policy Guide \u2014 Dec 2025&lt;br/&gt;Access them in document library\"]\n    A --&gt; B --&gt; C --&gt; D</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#implementation_2","title":"Implementation","text":"<p>Step 1: Add document discovery instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Document-Aware Agent\ninstructions: |+\n  ## Document Discovery Mode\n\n  When the user asks to \"find\", \"locate\", \"show me\", \"where is\", or \"get\" a document:\n\n  1. Search the knowledge base using their query\n  2. Present results as a NUMBERED LIST of documents, not a prose answer\n  3. For each document, include:\n     - Document title (bold)\n     - Brief description (one sentence)\n     - Last modified date (if available)\n  4. End with: \"You can browse all documents at [document library link].\"\n\n  DO NOT synthesize an answer from the documents.\n  DO list the documents themselves so the user can choose which to open.\n</code></pre> <p>Step 2: Custom search instructions for document mode</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: findDocuments\n      variable: Topic.DocumentList\n      userInput: =System.Activity.Text\n      customInstructions: |\n        The user is looking for specific DOCUMENTS, not answers.\n\n        List each matching document as a numbered item:\n        1. **[Document Title]** \u2014 [brief description] (Modified: [date])\n\n        Do NOT answer questions from the document content.\n        DO present the documents as a browsable list.\n\n        If you find relevant documents, present them.\n        If no documents match, say: \"I couldn't find documents matching that query.\"\n</code></pre>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions only. Zero infrastructure. Maintainability \ud83d\udfe2 One instruction block. Easy to tune. Channel Compatibility \ud83d\udfe2 Text-based results work everywhere. Search Quality \ud83d\udfe1 Depends on knowledge source indexing (Gem 008). Direct Links \ud83d\udd34 Knowledge source doesn't expose document URLs in generative answers. LLM may reference titles but can't provide clickable links. Pagination \ud83d\udd34 SearchAndSummarizeContent doesn't support pagination."},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#limitations_2","title":"Limitations","text":"<ul> <li>No direct download links: This is the critical limitation. Generative answers don't include file URLs. The user gets document titles but must navigate to SharePoint manually to find and download them.</li> <li>No metadata filtering: Can't filter by date, file type, or author. The search is purely semantic.</li> <li>LLM interpretation: The LLM may still try to answer from the document rather than listing it, despite instructions. Compliance is ~80-90%.</li> <li>No pagination: All results come in one response. No \"show me more.\"</li> </ul>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: PA + SharePoint Search Approach B: Graph Search API Approach C: Generative Discovery Implementation Effort \ud83d\udfe1 Medium (3-4 hours) \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe2 Low (15 min) Direct Document Links \ud83d\udfe2 Full URL per result \ud83d\udfe2 webUrl per result \ud83d\udd34 No links (titles only) Search Quality \ud83d\udfe2 SharePoint search maturity \ud83d\udfe2 Graph Search (best cross-service) \ud83d\udfe1 Knowledge source quality Metadata Filtering \ud83d\udfe2 File type, date, author \ud83d\udfe2 Full KQL filter support \ud83d\udd34 None Pagination \ud83d\udfe1 Possible (manual) \ud83d\udfe2 Native (from/size) \ud83d\udd34 Not supported Infrastructure \ud83d\udfe1 Power Automate flow \ud83d\udfe1 Auth setup + HTTP nodes \ud83d\udfe2 None Best When... Teams-centric, PA skills Pro-dev, cross-site search Quick, titles sufficient (no download needed)"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#recommended-approach","title":"Recommended Approach","text":"<p>For document retrieval with links: Approach A (Power Automate) \u2014 the most practical path to actual clickable document links. SharePoint search API is well-understood, the flow pattern is reusable, and results can be formatted as Adaptive Cards with download buttons.</p> <p>Choose Approach B when: You need cross-site search (documents across multiple SharePoint sites) or you're a pro-dev team that wants to eliminate Power Automate latency. Graph Search is the most powerful option.</p> <p>Use Approach C when: Users just need to know which documents exist (\"Do we have an expense template?\") and can navigate to SharePoint themselves. Zero infrastructure, works immediately, but no download links.</p> <p>Practical pattern: Combine C + A \u2014 use Approach C (generative discovery) for casual \"do we have...\" queries, and Approach A (Power Automate search) for explicit \"find and link me to...\" requests. The agent detects intent from keywords like \"download\", \"link to\", \"send me\".</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p><code>SearchAndSummarizeContent</code> does not return document URLs. Generative answers synthesize content from documents but don't expose the source file's URL to the topic. For direct links, you must use Approach A or B.</p> <p>Warning</p> <p>SharePoint search API requires <code>Sites.Read.All</code> or equivalent permissions. The Power Automate \"Send an HTTP request to SharePoint\" action uses the connection's permissions. Ensure the connection account has read access to the target site.</p> <p>Note</p> <p>Format search results as Adaptive Cards for the best UX. A card with document titles, file type icons, and \"Open\" buttons is much more scannable than a text list. Use Gem 006's card patterns for result display.</p> <p>Note</p> <p>Graph Search supports KQL syntax. You can pass complex queries: <code>expense template filetype:docx modified&gt;2026-01-01</code>. This enables powerful filtering without building separate filter UI.</p>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 008: Knowledge Source Optimization \u2014 Better knowledge indexing improves document discovery quality</li> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Display search results in structured Adaptive Cards</li> <li>Gem 009: Graceful Degradation \u2014 Handle SharePoint unavailability with fallback messages</li> <li>Gem 017: Multi-Tenant Agent \u2014 Different tenants may have different SharePoint document libraries</li> </ul>"},{"location":"gems/GEM-018-sharepoint-document-retrieval-and-display/#references","title":"References","text":"<ul> <li>Microsoft Learn: SharePoint search REST API</li> <li>Microsoft Graph: Search API</li> <li>Microsoft Graph: driveItem resource</li> <li>KQL syntax reference</li> </ul> <p>Gem 018 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/","title":"Gem 020: Agent Instructions as Living Documents","text":"<p>Your agent's instructions are its DNA \u2014 version them, modularize them, and evolve them without redeploying.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#classification","title":"Classification","text":"Attribute Value Category Personalization Complexity \u2b50\u2b50\u2b50\u2b50 (Complex \u2014 instruction architecture + configuration management) Channels All Prerequisite Gems Gem 002 (persona instructions), Gem 017 (tenant-specific instructions)"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#the-problem","title":"The Problem","text":"<p>Every Gem in this collection uses <code>GptComponentMetadata.instructions</code> \u2014 it's the most important configuration in your agent. But it's treated as a monolithic block of text embedded in YAML. This causes problems at scale:</p> <ul> <li>Monolithic blob: A mature agent has 2,000+ words of instructions covering identity, personas, roles, knowledge handling, language, disambiguation, safety rules, and escalation. One giant <code>instructions: |+</code> block that nobody wants to edit.</li> <li>No version history: You changed the instructions yesterday and resolution rates dropped 15%. What did you change? If the instructions are embedded in YAML, you need git diff expertise to find out.</li> <li>No A/B testing: You think a friendlier tone will improve CSAT scores. How do you test this with 50% of users while keeping the other 50% on the current instructions?</li> <li>Token waste: Gem 002's Approach A puts ALL persona instructions in every conversation \u2014 even though only one persona is active. A 2,000-word instruction set with 5 personas burns tokens on 4 unused sections per turn.</li> <li>Cross-concern coupling: Safety rules (Gem 022), persona definitions (Gem 002), role gating (Gem 007), and language handling (Gem 005) are all crammed into one instructions block. Changing the safety policy risks accidentally breaking persona routing.</li> </ul> <p>The fundamental challenge: instructions need the same lifecycle management as code \u2014 versioning, modularity, testing, and rollback \u2014 but they're treated as static configuration.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An instruction management system that supports professional-grade agent operations:</p> <ul> <li>[ ] Modular composition: Instructions split into independent fragments (identity, personas, safety, routing) that can be edited independently</li> <li>[ ] Version control: Every change is logged, diffable, and reversible</li> <li>[ ] A/B testing: Multiple instruction variants can run simultaneously for different user segments</li> <li>[ ] Token efficiency: Only the relevant instruction fragments load per conversation (not all personas for every user)</li> <li>[ ] Non-technical editing: Content owners can update instructions without touching YAML</li> </ul>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#approach-a-static-yaml-with-git-version-control","title":"Approach A: Static YAML with Git Version Control","text":"<p>Summary: Keep instructions in YAML but apply software engineering practices \u2014 git branching, meaningful commits, pull request reviews. Technique: VS Code Extension workflow, git for versioning, branch-based A/B testing, commit history for audit trail.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Instructions in YAML&lt;/b&gt;&lt;br/&gt;(agent.yaml or gpt.default/data)\"] --&gt; B[\"&lt;b&gt;Git Repository&lt;/b&gt;\"]\n    B --&gt; C[\"main branch:&lt;br/&gt;current production instructions\"]\n    B --&gt; D[\"experiment/friendlier-tone:&lt;br/&gt;A/B test variant\"]\n    B --&gt; E[\"history:&lt;br/&gt;full commit log of every change\"]\n    F[\"&lt;b&gt;Change Workflow&lt;/b&gt;\"] --&gt; G[\"1. Create branch from main\"]\n    G --&gt; H[\"2. Edit instructions in VS Code\"]\n    H --&gt; I[\"3. Commit with descriptive message\"]\n    I --&gt; J[\"4. PR review (if team)\"]\n    J --&gt; K[\"5. Merge to main\"]\n    K --&gt; L[\"6. Apply changes via VS Code Extension\"]</code></pre>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#implementation","title":"Implementation","text":"<p>Step 1: Structure instructions with clear sections</p> <p>Even within a single YAML block, organize instructions into labeled sections:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Production Agent\ninstructions: |+\n  # ====================================\n  # SECTION 1: AGENT IDENTITY\n  # Version: 1.3 | Updated: 2026-02-15\n  # ====================================\n  You are [Agent Name], the AI assistant for Contoso.\n\n  # ====================================\n  # SECTION 2: PERSONA DEFINITIONS\n  # Version: 2.1 | Updated: 2026-02-17\n  # ====================================\n  ## When persona is \"Engineer\"\n  - Be technical, use code examples...\n\n  ## When persona is \"Manager\"\n  - Be concise, focus on outcomes...\n\n  # ====================================\n  # SECTION 3: SAFETY AND DATA HANDLING\n  # Version: 1.0 | Updated: 2026-02-17\n  # ====================================\n  ## Prohibited Data Types\n  - Never accept SSN, credit cards...\n\n  # ====================================\n  # SECTION 4: ROUTING AND DISAMBIGUATION\n  # Version: 1.2 | Updated: 2026-02-16\n  # ====================================\n  ## When a query is ambiguous...\n</code></pre> <p>Step 2: Meaningful commit messages</p> <pre><code>git log --oneline\n\na3f7b2c feat(instructions): Add NewHire persona with step-by-step guidance\nb1d9e4f fix(safety): Strengthen SSN refusal language after bypass report\nc5a2f8d perf(persona): Reduce Manager persona from 150 to 80 words\nd9b3c1e experiment: A/B test - friendlier greeting tone\ne2f4a7b rollback: Revert d9b3c1e - friendlier tone decreased CSAT by 8%\n</code></pre> <p>Step 3: A/B testing via branches</p> <pre><code># Production agent uses main branch\ngit checkout main\n# Apply to Production environment\n\n# Test agent uses experiment branch\ngit checkout experiment/friendlier-tone\n# Apply to Test environment\n\n# Compare CSAT scores between environments after 1 week\n# If experiment wins: merge to main\n# If experiment loses: delete branch\n</code></pre> <p>Step 4: Pre-commit instruction validation</p> <p>Create a simple validation script:</p> <pre><code># validate-instructions.ps1\n$content = Get-Content -Path \"gpt.default/data\" -Raw\n$wordCount = ($content -split '\\s+').Count\n\nif ($wordCount -gt 3000) {\n    Write-Warning \"Instructions exceed 3000 words ($wordCount). Consider modularizing.\"\n}\n\n# Check for required sections\n$requiredSections = @(\"AGENT IDENTITY\", \"SAFETY AND DATA HANDLING\")\nforeach ($section in $requiredSections) {\n    if ($content -notmatch $section) {\n        Write-Error \"Missing required section: $section\"\n    }\n}\n\nWrite-Host \"Instructions validated: $wordCount words, all required sections present.\"\n</code></pre>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Git + VS Code Extension. Standard developer workflow. Maintainability \ud83d\udfe2 Full version history, diff, blame, rollback. Channel Compatibility \ud83d\udfe2 YAML-based. Deploy to any channel. Token Efficiency \ud83d\udd34 All instructions loaded every conversation. No selective loading. A/B Testing \ud83d\udfe1 Via separate environments/branches. Not per-user within one environment. Non-Technical Editing \ud83d\udd34 Requires git + YAML knowledge. Developers only."},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#limitations","title":"Limitations","text":"<ul> <li>Developer-only workflow: Content owners and subject matter experts can't edit instructions without developer help.</li> <li>No per-user variants: A/B testing requires separate environments, not user-level segmentation within one agent.</li> <li>Full instructions loaded always: Even with clear sections, the LLM processes the entire instruction block for every user.</li> <li>Environment overhead: A/B testing requires a separate test environment per variant.</li> </ul>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#approach-b-dataverse-instruction-store-with-runtime-loading","title":"Approach B: Dataverse Instruction Store with Runtime Loading","text":"<p>Summary: Store instruction fragments in a Dataverse table. At conversation start, load the relevant fragments based on user context (persona, tenant, experiment group) and assemble the final instructions dynamically. Technique: Dataverse instruction table, Power Automate assembly flow, runtime instruction injection via agent instructions or topics.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    T[\"&lt;b&gt;Dataverse: InstructionFragments Table&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;F001 \u00b7 Identity \u00b7 v1.3 \u00b7 All \u00b7 You are Contoso Assistant...&lt;br/&gt;F002 \u00b7 Persona \u00b7 v2.1 \u00b7 Engineer \u00b7 Be technical, use code...&lt;br/&gt;F003 \u00b7 Persona \u00b7 v2.1 \u00b7 Manager \u00b7 Be concise, focus on...&lt;br/&gt;F004 \u00b7 Safety \u00b7 v1.0 \u00b7 All \u00b7 Never accept SSN...&lt;br/&gt;F005 \u00b7 Routing \u00b7 v1.2 \u00b7 All \u00b7 When query is ambiguous...&lt;br/&gt;F006 \u00b7 Identity \u00b7 v1.3-B \u00b7 AB_Test \u00b7 Hey! I'm your Contoso pal...\"]\n    T --&gt; A[\"&lt;b&gt;At conversation start&lt;/b&gt;&lt;br/&gt;User persona = Engineer, AB group = Control\"]\n    A --&gt; L[\"&lt;b&gt;Load:&lt;/b&gt; F001 (Identity) + F002 (Engineer Persona)&lt;br/&gt;+ F004 (Safety) + F005 (Routing)\"]\n    A --&gt; S[\"&lt;b&gt;Skip:&lt;/b&gt; F003 (Manager), F006 (AB_Test variant)\"]\n    L --&gt; R[\"Assembled instructions: ~800 words (not 2000!)\"]</code></pre> <p>Only the relevant fragments are loaded \u2014 the user's specific persona, the universal safety rules, and the current routing logic. Other personas and A/B variants are skipped.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#implementation_1","title":"Implementation","text":"<p>Step 1: Create the InstructionFragments Dataverse table</p> Column Type Description <code>FragmentId</code> Auto-number Unique identifier <code>Section</code> Choice (Identity/Persona/Safety/Routing/Knowledge/Language/Custom) Instruction category <code>Version</code> Single line text Version tag (e.g., \"1.3\", \"1.3-B\") <code>Audience</code> Single line text Who sees this: \"All\", \"Engineer\", \"Manager\", \"AB_GroupB\", \"TenantA\" <code>Priority</code> Integer Assembly order (lower = first) <code>Content</code> Multi-line text The actual instruction text <code>IsActive</code> Boolean Enable/disable without deleting <code>EffectiveDate</code> DateTime When this version becomes active <code>ExpiryDate</code> DateTime When this version expires (for time-limited rules) <p>Step 2: Create the Instruction Assembly flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: persona (Text), tenantId (Text), abGroup (Text)\n\nAction: List Rows (Dataverse)\n  Table: InstructionFragments\n  Filter: cr_isactive eq true \n          AND (cr_audience eq 'All' OR cr_audience eq '{persona}' OR cr_audience eq '{tenantId}' OR cr_audience eq '{abGroup}')\n          AND cr_effectivedate le '{utcNow()}'\n          AND (cr_expirydate eq null OR cr_expirydate ge '{utcNow()}')\n  Order by: cr_priority asc\n\nAction: Select Content\n  From: body/value\n  Map: item()?['cr_content']\n\nAction: Join\n  From: output of Select\n  Separator: \"\\n\\n\"\n\nOutput: assembledInstructions (string)\n</code></pre> <p>Step 3: Load assembled instructions at conversation start</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Modular Agent\ninstructions: |+\n  # Core Agent Configuration\n\n  ## CRITICAL: Load Dynamic Instructions\n  At the START of every conversation:\n  1. Call \"GetUserContext\" to retrieve persona, tenant, and AB group\n  2. Call \"AssembleInstructions\" with those parameters\n  3. Follow the returned instructions for the rest of the conversation\n\n  ## Fallback Instructions (if assembly fails)\n  You are a helpful assistant for Contoso.\n  Be professional, concise, and helpful.\n  Never accept sensitive personal information.\n  If unsure, ask for clarification.\n</code></pre> <p>Step 4: Admin UI for instruction management</p> <p>Build a Power App on the InstructionFragments table:</p> <pre><code>Instruction Manager (Canvas App)\n    \u2502\n    \u251c\u2500\u2500 Fragment List: Filter by Section, Audience, Active status\n    \u251c\u2500\u2500 Fragment Editor: Rich text editor for instruction content\n    \u251c\u2500\u2500 Version History: Show all versions of a fragment\n    \u251c\u2500\u2500 A/B Test Manager: Create variant fragments with audience groups\n    \u251c\u2500\u2500 Preview: Assemble and display instructions for a sample user\n    \u2514\u2500\u2500 Rollback: Deactivate current version, reactivate previous\n</code></pre> <p>Subject matter experts edit fragments via the app. Changes take effect immediately \u2014 no deployment needed.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Dataverse table + assembly flow + admin app. Significant upfront investment. Maintainability \ud83d\udfe2 Fragments edited via UI. Version history in Dataverse. Non-technical editing possible. Channel Compatibility \ud83d\udfe2 Instructions are loaded dynamically \u2014 works in all channels. Token Efficiency \ud83d\udfe2 Only relevant fragments loaded. A 5-persona agent loads 1 persona per conversation. A/B Testing \ud83d\udfe2 Native \u2014 create variant fragments with different <code>Audience</code> values (AB_GroupA, AB_GroupB). Non-Technical Editing \ud83d\udfe2 Power App with rich text editor. No YAML, no git, no deployment."},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#limitations_1","title":"Limitations","text":"<ul> <li>Upfront investment: Dataverse table, assembly flow, and admin app take 4-6 hours to build initially.</li> <li>Assembly latency: Loading and assembling fragments adds 1-3 seconds at conversation start.</li> <li>Instruction coherence risk: Independently-edited fragments may contradict each other. The \"Identity\" fragment says \"Be concise\" but the \"NewHire Persona\" fragment says \"Explain everything in detail.\" Need editorial guidelines.</li> <li>Dynamic instructions and LLM compliance: Very long assembled instructions (if all fragments are verbose) may exceed the LLM's effective instruction-following threshold.</li> <li>Testing complexity: A change to one fragment combined with another user's persona may create unexpected behavior. Integration testing across fragment combinations is important.</li> </ul>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#approach-c-modular-markdown-fragment-composition","title":"Approach C: Modular Markdown Fragment Composition","text":"<p>Summary: Store instruction fragments as separate Markdown files. Assemble at build time (VS Code Extension sync) or runtime (Prompt Tool composition). Technique: Markdown files per section, build script for assembly, VS Code Extension for deployment, optional runtime composition.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    R[\"/agent-workspace/\"] --&gt; I[\"instructions/\"]\n    R --&gt; B[\"build-instructions.ps1&lt;br/&gt;&lt;i&gt;Assembly script&lt;/i&gt;\"]\n    R --&gt; Y[\"agent.yaml&lt;br/&gt;&lt;i&gt;References assembled output&lt;/i&gt;\"]\n    I --&gt; F1[\"01-identity.md&lt;br/&gt;&lt;i&gt;You are Contoso Assistant...&lt;/i&gt;\"]\n    I --&gt; F2[\"02-persona-engineer.md&lt;br/&gt;&lt;i&gt;When persona is Engineer...&lt;/i&gt;\"]\n    I --&gt; F3[\"02-persona-manager.md&lt;br/&gt;&lt;i&gt;When persona is Manager...&lt;/i&gt;\"]\n    I --&gt; F4[\"02-persona-newhire.md&lt;br/&gt;&lt;i&gt;When persona is NewHire...&lt;/i&gt;\"]\n    I --&gt; F5[\"03-safety.md&lt;br/&gt;&lt;i&gt;Never accept SSN...&lt;/i&gt;\"]\n    I --&gt; F6[\"04-routing.md&lt;br/&gt;&lt;i&gt;When query is ambiguous...&lt;/i&gt;\"]\n    I --&gt; F7[\"05-language.md&lt;br/&gt;&lt;i&gt;Respond in user's language...&lt;/i&gt;\"]\n    I --&gt; F8[\"06-knowledge.md&lt;br/&gt;&lt;i&gt;Cite sources, use tables...&lt;/i&gt;\"]</code></pre> <p>Each concern is a separate file. A build script assembles the relevant fragments into the final instructions block.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#implementation_2","title":"Implementation","text":"<p>Step 1: Create instruction fragments as Markdown files</p> <pre><code>&lt;!-- instructions/01-identity.md --&gt;\n# Agent Identity\nYou are **Contoso Assistant**, an AI-powered support agent for Contoso employees.\nYou are helpful, professional, and accurate.\n</code></pre> <pre><code>&lt;!-- instructions/02-persona-engineer.md --&gt;\n## When the user's persona is \"Engineer\"\n- Be direct and technical\n- Use code examples and CLI commands\n- Prefer precision over friendliness\n</code></pre> <pre><code>&lt;!-- instructions/03-safety.md --&gt;\n## Sensitive Data Handling\n- NEVER accept SSN, credit cards, or passwords\n- Redirect to secure portals for sensitive operations\n- Log security events (type only, not data)\n</code></pre> <p>Step 2: Build script for full assembly</p> <pre><code># build-instructions.ps1\n# Assembles all fragments into a single instructions block\n\nparam(\n    [string[]]$Personas = @(\"All\"),  # Which persona fragments to include\n    [string]$OutputFile = \"assembled-instructions.md\"\n)\n\n$fragments = @()\n\n# Always include universal fragments (no persona filter)\n$universalFiles = @(\"01-identity.md\", \"03-safety.md\", \"04-routing.md\", \"05-language.md\", \"06-knowledge.md\")\nforeach ($file in $universalFiles) {\n    $fragments += Get-Content \"instructions/$file\" -Raw\n}\n\n# Include persona-specific fragments\nforeach ($persona in $Personas) {\n    $personaFile = \"instructions/02-persona-$($persona.ToLower()).md\"\n    if (Test-Path $personaFile) {\n        $fragments += Get-Content $personaFile -Raw\n    }\n}\n\n$assembled = $fragments -join \"`n`n---`n`n\"\n$wordCount = ($assembled -split '\\s+').Count\n\nSet-Content -Path $OutputFile -Value $assembled\nWrite-Host \"Assembled $wordCount words from $($fragments.Count) fragments \u2192 $OutputFile\"\n</code></pre> <p>Step 3: Build-time assembly (full instructions, all personas)</p> <pre><code># For static deployment: include all personas\n./build-instructions.ps1 -Personas @(\"Engineer\", \"Manager\", \"NewHire\") -OutputFile \"full-instructions.md\"\n\n# Copy assembled content into agent.yaml\n# Deploy via VS Code Extension\n</code></pre> <p>Step 4: Runtime selective assembly (optimal token efficiency)</p> <p>For runtime composition, use a simpler Prompt Tool or Power Automate flow that concatenates only the needed fragments from a storage location (SharePoint, Blob Storage, or Dataverse):</p> <pre><code>kind: PromptTool\nid: prompt_instructionAssembler\ndisplayName: \"Instruction Assembler\"\ndescription: \"Assembles relevant instruction fragments for the current user\"\ninstructions: |\n  You are an instruction assembler. Given the universal instructions and a persona-specific \n  section, combine them into a coherent instruction set.\n\n  Universal: {universalInstructions}\n  Persona-specific: {personaInstructions}\n\n  Output the combined instructions as a single coherent document.\n  Do not add anything \u2014 just combine and output.\n</code></pre> <p>Simpler alternative: Use a Power Automate flow that reads the appropriate Markdown files from a SharePoint library and concatenates them, similar to Approach B but file-based instead of Dataverse.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Markdown files + PowerShell script. Developer-friendly. Maintainability \ud83d\udfe2 Each concern is a separate file. Git-diffable per section. Channel Compatibility \ud83d\udfe2 Assembled output works in all channels. Token Efficiency \ud83d\udfe1 Build-time: all personas included. Runtime: selective but needs infrastructure. A/B Testing \ud83d\udfe1 Via file variants (02-persona-engineer-v2.md) + build script parameters. Non-Technical Editing \ud83d\udfe1 Markdown is friendlier than YAML, but still requires file editing and deployment."},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#limitations_2","title":"Limitations","text":"<ul> <li>Build-time vs runtime trade-off: Build-time assembly is simple but loads all fragments. Runtime assembly requires infrastructure (flow or Prompt Tool).</li> <li>Still requires deployment: Editing a Markdown file requires running the build script and redeploying via VS Code Extension. Not instant like Approach B.</li> <li>Fragment coherence: Same risk as Approach B \u2014 independent editing may create contradictions. Needs editorial review.</li> <li>File management: 8-10 instruction files per agent, per variant. For 5 tenants \u00d7 3 A/B experiments = potentially many files.</li> </ul>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: YAML + Git Approach B: Dataverse Store Approach C: Markdown Fragments Implementation Effort \ud83d\udfe2 Low (existing workflow) \ud83d\udfe1 Medium (4-6 hours) \ud83d\udfe2 Low (1-2 hours) Non-Technical Editing \ud83d\udd34 Developers only \ud83d\udfe2 Power App for content owners \ud83d\udfe1 Markdown-friendly Version Control \ud83d\udfe2 Git (full history) \ud83d\udfe2 Dataverse (version column) \ud83d\udfe2 Git (per-file history) Token Efficiency \ud83d\udd34 All loaded always \ud83d\udfe2 Selective per-user \ud83d\udfe1 Build-time all, runtime selective A/B Testing \ud83d\udfe1 Via environments \ud83d\udfe2 Native (audience groups) \ud83d\udfe1 Via file variants Instant Updates \ud83d\udd34 Requires deployment \ud83d\udfe2 Dataverse edit \u2192 live \ud83d\udd34 Requires build + deploy Best When... Developer team, small instruction set Enterprise, content owner self-service Developer team, modular architecture"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#recommended-approach","title":"Recommended Approach","text":"<p>For small-medium agents (&lt; 1,000 words of instructions): Approach A (YAML + Git) \u2014 keep it simple. The overhead of Approaches B and C isn't justified for a small instruction set. Just write good commit messages.</p> <p>For enterprise agents with content owners: Approach B (Dataverse Store) \u2014 the investment pays off when non-technical SMEs need to update instructions (HR updates policy language, legal updates compliance rules, marketing updates brand voice). The Power App interface unlocks self-service instruction management.</p> <p>For developer-centric teams valuing modularity: Approach C (Markdown Fragments) \u2014 the best separation of concerns. Each team owns their section (security team owns safety.md, HR team owns persona-newhire.md). Git provides per-team change tracking.</p> <p>The evolution path:</p> <pre><code>Prototype:   Approach A \u2014 monolithic YAML, git commits\nGrowth:      Approach C \u2014 split into fragments, build script\nEnterprise:  Approach B \u2014 Dataverse + Power App, content owner self-service\n</code></pre>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Agent instructions have a practical effective length limit. While there's no hard character limit, LLM instruction-following degrades past ~3,000-4,000 words. If your assembled instructions exceed this, the model may ignore later sections. Measure quality with Gem 013 as instructions grow.</p> <p>Warning</p> <p>Dynamic instructions loaded via agent instructions create a bootstrapping problem. If you tell the agent \"call AssembleInstructions first,\" the agent needs some instructions to know to do that. Always have a static fallback instruction block in YAML with the assembly directive.</p> <p>Note</p> <p>Modular instructions save tokens when loaded selectively. A 2,000-word instruction set with 5 personas loads 2,000 tokens on every turn. With selective loading (Approach B), an Engineer conversation loads only ~600 words (identity + engineer persona + safety + routing). At 100 turns/day, that's 140,000 fewer tokens per day.</p> <p>Note</p> <p>A/B testing instructions requires a metric to measure. Without Gem 016 (analytics) tracking resolution rate and CSAT per instruction variant, A/B testing is blind. Always pair instruction experiments with measurable outcomes.</p>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Defines the persona content that lives in instruction fragments</li> <li>Gem 007: Role-Based Feature Gating \u2014 Role-specific instructions can be separate fragments</li> <li>Gem 012: Cost Estimation \u2014 Instruction length directly affects per-turn token cost</li> <li>Gem 017: Multi-Tenant Agent \u2014 Tenant-specific instructions are a modular fragment use case</li> <li>Gem 022: Secure Data Handling \u2014 Safety instructions should be an independent, immutable fragment</li> </ul>"},{"location":"gems/GEM-020-agent-instructions-as-living-documents/#references","title":"References","text":"<ul> <li>Microsoft Learn: Agent instructions in Copilot Studio</li> <li>Microsoft Learn: Copilot Studio VS Code Extension</li> <li>Prompt Engineering best practices</li> <li>Microsoft Learn: Dataverse tables</li> </ul> <p>Gem 020 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/","title":"Gem 021: Conversation Branching and Disambiguation","text":"<p>When the user says \"Tell me about leave,\" which of your 4 leave topics should fire?</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#classification","title":"Classification","text":"Attribute Value Category UX Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 topic design + conditional routing) Channels All Prerequisite Gems None (Gem 011 complementary for contextual disambiguation)"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#the-problem","title":"The Problem","text":"<p>The user says \"leave.\" Your agent has four leave-related topics: PTO, sick leave, parental leave, and bereavement leave. What happens?</p> <ul> <li>Generative orchestration guesses: The LLM picks whichever topic seems most likely \u2014 usually PTO (the most common). If the user meant parental leave, they get the wrong answer and must rephrase.</li> <li>Multiple topic match: If trigger phrases overlap (\"leave\" appears in all four topics), the orchestrator may pick inconsistently \u2014 PTO today, sick leave tomorrow for the same query.</li> <li>Information dump: Some agents respond with everything about all types of leave \u2014 a 500-word wall of text that nobody reads.</li> <li>Silent misroute: The agent confidently answers about the wrong topic. The user doesn't even realize they got the wrong information \u2014 the most dangerous outcome.</li> </ul> <p>This isn't a rare edge case. Ambiguous queries account for 15-30% of all agent interactions in production, based on typical unmatched/mismatched analytics. It's the #1 category in \"edge case\" testing (GEM-013, TC-020).</p> <p>The problem worsens as agents grow: an agent with 5 topics has few overlaps; an agent with 30 topics has dozens. Without a systematic disambiguation strategy, every new topic increases the chance of misrouting.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that handles ambiguity gracefully and accurately:</p> <ul> <li>[ ] Detects ambiguity: Recognizes when a query matches multiple topics with similar confidence</li> <li>[ ] Clarifies efficiently: Asks one focused clarification question \u2014 not an interrogation</li> <li>[ ] Routes correctly: After clarification, routes to the exact right topic 100% of the time</li> <li>[ ] Skips disambiguation when unnecessary: Specific queries (\"How many PTO days do I get?\") go directly to the topic without an extra turn</li> <li>[ ] Learns from patterns: Analytics reveal which queries are commonly ambiguous, driving trigger phrase improvements</li> </ul>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#approach-a-dedicated-disambiguation-topic-with-choice-card","title":"Approach A: Dedicated Disambiguation Topic with Choice Card","text":"<p>Summary: Create a disambiguation topic that fires when the query is broad. It presents options as a choice question or Adaptive Card. The user selects, and the agent routes precisely. Technique: <code>OnRecognizedIntent</code> topic with broad trigger phrases, <code>Question</code> or <code>AdaptiveCardPrompt</code> for option selection, <code>GotoTopic</code> for routing.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: Tell me about leave\"] --&gt; B[\"Disambiguation Topic fires&lt;br/&gt;(broad trigger phrases)\"]\n    B --&gt; C[\"Agent: I can help with several types of leave:&lt;br/&gt;\ud83c\udfd6\ufe0f PTO / Vacation&lt;br/&gt;\ud83e\udd12 Sick Leave&lt;br/&gt;\ud83d\udc76 Parental Leave&lt;br/&gt;\ud83d\udd4a\ufe0f Bereavement Leave&lt;br/&gt;&lt;br/&gt;Which one are you interested in?\"]\n    C --&gt; D[\"User selects: Parental Leave\"]\n    D --&gt; E[\"Redirect to Parental Leave topic\"]</code></pre> <p>One extra turn in exchange for 100% routing accuracy.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#implementation","title":"Implementation","text":"<p>Step 1: Design the trigger phrase strategy</p> <p>The key insight: broad queries go to the disambiguation topic, specific queries go directly to leaf topics.</p> Trigger Phrase Routes To Why \"leave\" Disambiguation Too broad \u2014 could be any leave type \"leave policy\" Disambiguation Still ambiguous \"time off\" Disambiguation Could be PTO or sick \"PTO\" PTO Topic (direct) Specific enough \"how many vacation days\" PTO Topic (direct) Clearly about PTO \"sick day policy\" Sick Leave (direct) Clearly about sick leave \"maternity leave\" Parental Leave (direct) Clearly about parental \"paternity leave\" Parental Leave (direct) Clearly about parental \"bereavement\" Bereavement (direct) Clearly about bereavement <p>Step 2: Create the disambiguation topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Leave Policy Disambiguation\n    includeInOnSelectIntent: true\n    triggerQueries:\n      - \"leave\"\n      - \"leave policy\"\n      - \"time off\"\n      - \"absence\"\n      - \"days off\"\n      - \"what leave do I get\"\n      - \"tell me about leave\"\n  actions:\n    - kind: Question\n      id: askLeaveType\n      variable: init:Topic.LeaveType\n      prompt: \"I can help with several types of leave. Which one are you interested in?\"\n      entity: ChoicePrebuiltEntity\n      choiceOptions:\n        - value: \"PTO\"\n          synonyms: [\"vacation\", \"paid time off\", \"annual leave\", \"holiday\"]\n        - value: \"Sick Leave\"\n          synonyms: [\"sick\", \"sick day\", \"illness\", \"medical\"]\n        - value: \"Parental Leave\"\n          synonyms: [\"maternity\", \"paternity\", \"baby\", \"parent\", \"adoption\"]\n        - value: \"Bereavement Leave\"\n          synonyms: [\"bereavement\", \"funeral\", \"death\", \"mourning\"]\n\n    # Route to the specific topic\n    - kind: ConditionGroup\n      id: routeToLeave\n      conditions:\n        - id: isPTO\n          condition: =Topic.LeaveType = \"PTO\"\n          actions:\n            - kind: GotoTopic\n              id: gotoPTO\n              topicId: PTOPolicy\n        - id: isSick\n          condition: =Topic.LeaveType = \"Sick Leave\"\n          actions:\n            - kind: GotoTopic\n              id: gotoSick\n              topicId: SickLeavePolicy\n        - id: isParental\n          condition: =Topic.LeaveType = \"Parental Leave\"\n          actions:\n            - kind: GotoTopic\n              id: gotoParental\n              topicId: ParentalLeavePolicy\n        - id: isBereavement\n          condition: =Topic.LeaveType = \"Bereavement Leave\"\n          actions:\n            - kind: GotoTopic\n              id: gotoBereavement\n              topicId: BereavementLeavePolicy\n</code></pre> <p>Step 3: Create an Adaptive Card version for richer UX</p> <pre><code>    - kind: SendActivity\n      id: sendDisambiguationCard\n      activity:\n        attachments:\n          - contentType: application/vnd.microsoft.card.adaptive\n            content:\n              type: AdaptiveCard\n              \"$schema\": http://adaptivecards.io/schemas/adaptive-card.json\n              version: \"1.5\"\n              body:\n                - type: TextBlock\n                  text: \"Which type of leave are you asking about?\"\n                  weight: bolder\n                  size: medium\n                - type: ActionSet\n                  actions:\n                    - type: Action.Submit\n                      title: \"\ud83c\udfd6\ufe0f PTO / Vacation\"\n                      data: { \"leaveType\": \"PTO\" }\n                    - type: Action.Submit\n                      title: \"\ud83e\udd12 Sick Leave\"\n                      data: { \"leaveType\": \"Sick\" }\n                    - type: Action.Submit\n                      title: \"\ud83d\udc76 Parental Leave\"\n                      data: { \"leaveType\": \"Parental\" }\n                    - type: Action.Submit\n                      title: \"\ud83d\udd4a\ufe0f Bereavement Leave\"\n                      data: { \"leaveType\": \"Bereavement\" }\n</code></pre> <p>Step 4: Build a reusable disambiguation pattern</p> <p>For agents with many disambiguation points, standardize:</p> <pre><code># Template: Disambiguation Topic\n# Copy and customize per domain\n\n# 1. Trigger: broad phrases for the domain\n# 2. Question/Card: present domain-specific options\n# 3. Route: ConditionGroup \u2192 GotoTopic per option\n\n# Domains that commonly need disambiguation:\n# - Leave types (PTO, sick, parental, bereavement)\n# - Support categories (billing, technical, account)\n# - Report types (financial, performance, compliance)\n# - IT requests (access, hardware, software, network)\n</code></pre>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Question node + ConditionGroup. Standard topic authoring. Maintainability \ud83d\udfe2 Adding a new option = adding a choice + a condition branch. Channel Compatibility \ud83d\udfe2 Choice questions work everywhere. Adaptive Card for richer display. Routing Accuracy \ud83d\udfe2 100% accurate \u2014 user explicitly selected the target. User Experience \ud83d\udfe1 Adds one turn. Users who knew what they wanted may find it redundant. Specific Query Bypass \ud83d\udfe2 Specific queries bypass disambiguation and go directly to leaf topics."},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#limitations","title":"Limitations","text":"<ul> <li>Extra turn for every broad query: The disambiguation question adds a conversation turn. For users who ask the same thing daily (\"leave\" always means PTO for them), this feels repetitive. Combine with Gem 001 to remember their last choice.</li> <li>Static options: The choice list is hardcoded. Adding a new leave type requires editing the topic, the choices, and adding a new route.</li> <li>Doesn't scale to 10+ options: A choice list with 10 items is overwhelming. For large option sets, consider hierarchical disambiguation (category first, then subcategory).</li> <li>No learning: The disambiguation topic doesn't get smarter. The same broad query always shows the same options, regardless of user history.</li> </ul>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#approach-b-llm-inference-with-clarification-fallback","title":"Approach B: LLM Inference with Clarification Fallback","text":"<p>Summary: Let the generative orchestrator attempt to route based on context and LLM inference. Only ask for clarification when the query is truly ambiguous \u2014 not every time. Technique: Agent instructions that define when to clarify vs when to infer, generative orchestration with well-described topics, contextual re-routing.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: Tell me about leave\"] --&gt; B[\"&lt;b&gt;LLM evaluates:&lt;/b&gt;&lt;br/&gt;Conversation context? (Gem 011)&lt;br/&gt;If discussed parental before, assume parental leave&lt;br/&gt;&lt;br/&gt;User context? (Gem 001)&lt;br/&gt;If user is 8 months pregnant, infer parental leave&lt;br/&gt;&lt;br/&gt;Truly ambiguous with no context?&lt;br/&gt;Ask for clarification\"]\n    B --&gt; C[\"If inferrable:&lt;br/&gt;Route directly (no extra turn)\"]\n    B --&gt; D[\"If ambiguous:&lt;br/&gt;Ask clarification (one extra turn)\"]</code></pre> <p>The LLM tries to resolve ambiguity using available context before asking the user. Disambiguation is a fallback, not the default.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#implementation_1","title":"Implementation","text":"<p>Step 1: Craft orchestrator instructions for disambiguation</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Smart Routing Agent\ninstructions: |+\n  # Intent Disambiguation Protocol\n\n  ## When a user's query could match multiple topics:\n\n  ### Step 1: Check conversation context\n  If the conversation already established a topic (e.g., we were discussing PTO),\n  assume the new query relates to the same topic unless the user explicitly shifts.\n\n  ### Step 2: Check user context\n  Use user profile data (role, department, recent interactions) to infer likely intent:\n  - HR department user asking \"leave\" \u2192 likely asking about leave policies they manage\n  - New hire asking \"leave\" \u2192 likely asking about their own PTO entitlements\n  - User who just returned from parental leave \u2192 likely asking about return-to-work\n\n  ### Step 3: Check query specificity\n  If the query contains ANY specific keyword, route directly:\n  - \"PTO\", \"vacation\", \"annual\" \u2192 PTO Policy\n  - \"sick\", \"illness\", \"medical\" \u2192 Sick Leave\n  - \"maternity\", \"paternity\", \"baby\", \"adoption\" \u2192 Parental Leave\n  - \"bereavement\", \"funeral\", \"death\" \u2192 Bereavement Leave\n\n  ### Step 4: If still ambiguous \u2014 ASK\n  If steps 1-3 don't resolve the intent, ask ONE focused question:\n  \"I can help with PTO, sick leave, parental leave, or bereavement leave.\n   Which one are you interested in?\"\n\n  ## IMPORTANT\n  - NEVER guess when multiple options are equally likely\n  - NEVER dump information about all topics \u2014 it overwhelms the user\n  - ONE clarification question is acceptable; TWO in a row is not\n  - After the user clarifies, remember their choice for context (Step 1 next time)\n</code></pre> <p>Step 2: Write well-differentiated topic descriptions</p> <p>Generative orchestration routes based on agent/topic descriptions (see Gotchas Compendium). Make them disambiguating:</p> <pre><code># PTO topic description\ndescription: \"Handles questions about Paid Time Off (PTO), vacation days, \n  annual leave entitlements, carryover rules, and PTO booking procedures.\n  Do NOT route here for sick leave, parental leave, or bereavement.\"\n\n# Sick Leave topic description  \ndescription: \"Handles questions about sick leave policy, sick day entitlements,\n  medical leave procedures, and doctor's note requirements.\n  Do NOT route here for PTO, parental leave, or bereavement.\"\n</code></pre> <p>The \"Do NOT route here for...\" negative instructions help the LLM differentiate between similar topics.</p> <p>Step 3: Context-aware disambiguation (link to Gem 011)</p> <pre><code>instructions: |+\n  ## Contextual Routing\n\n  If Global.ConversationSummary mentions a specific leave type,\n  assume follow-up questions about \"leave\" refer to that type.\n\n  Example:\n  - Summary contains \"PTO\" \u2192 \"What about carryover?\" \u2192 Route to PTO topic\n  - Summary contains \"parental leave\" \u2192 \"How long is it?\" \u2192 Route to Parental Leave\n</code></pre>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions + topic descriptions. No new topics or flows. Maintainability \ud83d\udfe2 Update instructions and descriptions. No structural changes. Channel Compatibility \ud83d\udfe2 Works in all channels (LLM-based). Routing Accuracy \ud83d\udfe1 Good for clear contexts. Still guesses incorrectly ~10-15% of the time for truly ambiguous queries. User Experience \ud83d\udfe2 Zero extra turns when context resolves ambiguity. One turn when it can't. Best possible UX. Specific Query Bypass \ud83d\udfe2 Naturally handled \u2014 specific queries trigger specific topics."},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#limitations_1","title":"Limitations","text":"<ul> <li>LLM inference is probabilistic: \"leave\" with no context \u2014 the LLM still has to pick something or ask. It may pick PTO (most common) when the user meant something else.</li> <li>Description quality dependency: If topic descriptions don't clearly differentiate, the LLM will struggle. Requires careful description authoring.</li> <li>Context dependency: Without Gem 011 (session memory), the LLM has no prior context to use for inference. The approach degrades to \"guess or ask.\"</li> <li>Testing difficulty: Unlike Approach A (deterministic routing), LLM-based routing requires probabilistic testing (Gem 013). The same query may route differently across runs.</li> <li>No explicit user confirmation: When the LLM infers correctly, it's seamless. When it infers incorrectly, the user gets wrong information without ever being asked \u2014 the worst outcome.</li> </ul>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#approach-c-trigger-phrase-engineering-with-overlap-elimination","title":"Approach C: Trigger Phrase Engineering with Overlap Elimination","text":"<p>Summary: Redesign trigger phrases across all topics to eliminate overlap. Broad phrases go to disambiguation; specific phrases go directly to leaf topics. Systematic trigger management prevents ambiguity at the source. Technique: Trigger phrase audit, overlap matrix, disambiguation topic for broad terms, leaf topics with unique-only triggers.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#how-it-works_2","title":"How It Works","text":"<pre><code>Before (overlap problem):\n  PTO Topic:       \"leave\", \"PTO\", \"vacation\", \"time off\", \"days off\"\n  Sick Leave:      \"leave\", \"sick\", \"illness\", \"sick day\"\n  Parental Leave:  \"leave\", \"parental\", \"maternity\", \"paternity\"\n  \u2192 \"leave\" matches 3 topics! Ambiguous.\n\nAfter (overlap eliminated):\n  Disambiguation:  \"leave\", \"time off\", \"days off\", \"absence\" (broad terms)\n  PTO Topic:       \"PTO\", \"vacation\", \"annual leave\", \"how many vacation days\"\n  Sick Leave:      \"sick leave\", \"sick day\", \"illness\", \"medical leave\"\n  Parental Leave:  \"parental leave\", \"maternity\", \"paternity\", \"adoption leave\"\n  \u2192 \"leave\" \u2192 Disambiguation. \"PTO\" \u2192 PTO directly. Zero overlap.\n</code></pre>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#implementation_2","title":"Implementation","text":"<p>Step 1: Audit existing trigger phrases</p> <p>Create an overlap matrix:</p> <pre><code>| Trigger Phrase    | PTO | Sick | Parental | Bereavement | Action |\n|-------------------|-----|------|----------|-------------|--------|\n| \"leave\"           | \u2713   | \u2713    | \u2713        | \u2713           | \u2192 Move to Disambiguation |\n| \"time off\"        | \u2713   | \u2713    |          |             | \u2192 Move to Disambiguation |\n| \"PTO\"             | \u2713   |      |          |             | \u2705 Keep in PTO |\n| \"vacation\"        | \u2713   |      |          |             | \u2705 Keep in PTO |\n| \"sick\"            |     | \u2713    |          |             | \u2705 Keep in Sick |\n| \"maternity\"       |     |      | \u2713        |             | \u2705 Keep in Parental |\n| \"bereavement\"     |     |      |          | \u2713           | \u2705 Keep in Bereavement |\n</code></pre> <p>Rule: If a trigger phrase matches 2+ topics, move it to the disambiguation topic.</p> <p>Step 2: Formalize the trigger hierarchy</p> <pre><code>Level 1 (Disambiguation): Broad terms shared across subtopics\n  \"leave\", \"time off\", \"days off\", \"absence\"\n\nLevel 2 (Leaf Topics): Unique terms for each specific topic\n  PTO:         \"PTO\", \"vacation\", \"annual leave\", \"paid time off\"\n  Sick:        \"sick leave\", \"sick day\", \"illness\", \"medical leave\"\n  Parental:    \"parental leave\", \"maternity\", \"paternity\", \"adoption leave\"\n  Bereavement: \"bereavement leave\", \"funeral leave\", \"compassionate leave\"\n</code></pre> <p>Step 3: Document trigger assignments for governance</p> <p>Create a trigger phrase registry (spreadsheet or Dataverse table):</p> Phrase Assigned Topic Level Last Reviewed \"leave\" Disambiguation 1 2026-02-17 \"PTO\" PTO Policy 2 2026-02-17 \"vacation\" PTO Policy 2 2026-02-17 \"sick leave\" Sick Leave Policy 2 2026-02-17 <p>Step 4: Add new phrases systematically</p> <p>When adding trigger phrases:</p> <ol> <li>Check the registry for overlap</li> <li>If the phrase is unique \u2192 add to leaf topic</li> <li>If the phrase overlaps \u2192 add to disambiguation topic</li> <li>Update the registry</li> </ol> <p>Step 5: Monitor and iterate using analytics (Gem 016)</p> <pre><code>// Find misrouted queries (from unmatched or low-satisfaction conversations)\ncustomEvents\n| where name == \"UserFeedback\"\n| where toint(customDimensions.Rating) &lt;= 2\n| extend TopicName = tostring(customDimensions.TopicName)\n| extend UserQuery = tostring(customDimensions.OriginalQuery)\n| summarize LowRatingCount = count() by TopicName, UserQuery\n| order by LowRatingCount desc\n</code></pre> <p>If \"leave\" routed to PTO gets low ratings, the user probably wanted a different leave type \u2192 confirm it should go to disambiguation.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires trigger audit across all topics. Design work, not coding. Maintainability \ud83d\udfe1 Registry must be maintained. Every new phrase needs overlap checking. Channel Compatibility \ud83d\udfe2 Trigger phrases work the same in all channels. Routing Accuracy \ud83d\udfe2 Deterministic. No overlap = no ambiguity for covered phrases. User Experience \ud83d\udfe2 Specific queries: zero extra turns. Broad queries: one disambiguation turn. Best of both worlds. Specific Query Bypass \ud83d\udfe2 By design \u2014 specific phrases go directly to leaf topics."},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#limitations_2","title":"Limitations","text":"<ul> <li>Upfront audit effort: For an agent with 30 topics and 200+ trigger phrases, the initial audit is significant.</li> <li>Doesn't cover unanticipated queries: Users will always find new ways to ask things. A phrase not in any trigger list goes to generative orchestration (unpredictable).</li> <li>Registry overhead: Maintaining the trigger registry adds governance overhead. If not maintained, overlap creeps back.</li> <li>Phrases aren't enough: Users don't always use your exact trigger phrases. \"I need to take time off because my dad passed away\" \u2014 this needs LLM understanding, not trigger matching.</li> </ul>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Disambiguation Topic Approach B: LLM Inference Approach C: Trigger Engineering Implementation Effort \ud83d\udfe2 Low (1-2 hours) \ud83d\udfe2 Low (1 hour) \ud83d\udfe1 Medium (2-4 hours audit) Extra Turns \ud83d\udfe1 Always 1 for broad queries \ud83d\udfe2 Zero when context resolves \ud83d\udfe1 Only for broad queries Routing Accuracy \ud83d\udfe2 100% (user selected) \ud83d\udfe1 85-90% (LLM inference) \ud83d\udfe2 100% (no overlap) Scalability (topics) \ud83d\udfe1 Choice list grows with topics \ud83d\udfe2 LLM handles any count \ud83d\udfe1 Registry grows with topics Handles Novel Queries \ud83d\udd34 Only listed options \ud83d\udfe2 LLM adapts to any phrasing \ud83d\udd34 Only registered phrases Determinism \ud83d\udfe2 Fully deterministic \ud83d\udd34 Probabilistic \ud83d\udfe2 Fully deterministic Best When... Well-defined option sets, accuracy critical Rich user context, natural UX Governance-oriented, large topic sets"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#recommended-approach","title":"Recommended Approach","text":"<p>Combine all three \u2014 they're complementary layers:</p> <pre><code>Layer 1: Approach C (Prevention)\n  Audit and eliminate trigger phrase overlap.\n  Specific phrases route directly. Broad phrases go to disambiguation.\n\nLayer 2: Approach A (Explicit Disambiguation)\n  For broad queries that reach the disambiguation topic,\n  present clear options for the user to choose.\n\nLayer 3: Approach B (Smart Inference)\n  Within the disambiguation topic or the orchestrator,\n  use conversation context (Gem 011) and user context (Gem 001)\n  to pre-select the most likely option \u2014 but still confirm.\n</code></pre> <p>The combined pattern in practice:</p> <pre><code>User: \"leave\"\n  \u2192 Trigger engineering (C): Matches \"Disambiguation\" topic (broad term)\n  \u2192 LLM inference (B): Checks context \u2014 user discussed PTO yesterday\n  \u2192 Disambiguation topic (A): \"Based on our previous conversation, \n    I think you're asking about PTO. Is that right?\n    If not: [Sick Leave] [Parental] [Bereavement]\"\n</code></pre> <p>This gives you: trigger-based prevention, context-aware inference, and explicit user confirmation. Three layers, maximum accuracy.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Generative orchestration can override your trigger phrases. Even if you carefully separate trigger phrases, the LLM may route queries based on topic descriptions rather than exact phrase matching. Ensure descriptions are also disambiguating (add \"Do NOT route here for X\" instructions per Approach B, Step 2).</p> <p>Warning</p> <p>Choice question synonyms are exact-match, not semantic. In a <code>ChoicePrebuiltEntity</code>, synonyms like <code>[\"vacation\"]</code> only match the exact word \"vacation.\" They won't match \"I want to go on vacation next month.\" For natural language flexibility, combine Approach A (choices) with Approach B (LLM instructions).</p> <p>Note</p> <p>The \"Unmatched queries\" analytics (Gem 016) is your disambiguation radar. Queries that consistently go unmatched often indicate missing disambiguation topics or insufficient trigger phrases. Check weekly and add new broad terms to disambiguation topics.</p> <p>Note</p> <p>Remember disambiguation choices across sessions (Gem 001). If a user always selects \"PTO\" when disambiguation fires, persist this preference. Next session, pre-select PTO: \"I think you're asking about PTO again. Is that right?\" This reduces friction for repeat users.</p>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 001: Persisting User Context \u2014 Remember disambiguation preferences across sessions</li> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Present disambiguation options as a structured card</li> <li>Gem 011: Conversation Memory Within a Session \u2014 Conversation context resolves many ambiguities automatically</li> <li>Gem 013: Testing Strategies \u2014 Ambiguous queries are a key test category (TC-020)</li> <li>Gem 016: Conversation Analytics \u2014 Unmatched queries reveal where disambiguation is needed</li> </ul>"},{"location":"gems/GEM-021-conversation-branching-and-disambiguation/#references","title":"References","text":"<ul> <li>Microsoft Learn: Trigger phrases in Copilot Studio</li> <li>Microsoft Learn: Generative orchestration</li> <li>Microsoft Learn: Topic management best practices</li> </ul> <p>Gem 021 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/","title":"Gem 022: Secure Data Handling in Conversations","text":"<p>Users will type passwords, SSNs, and credit card numbers into your agent. Here's how to protect that data.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#classification","title":"Classification","text":"Attribute Value Category Security Complexity \u2b50\u2b50\u2b50\u2b50 (Complex \u2014 multi-layer defense across platform, telemetry, and storage) Channels All (risks and mitigations vary by channel) Prerequisite Gems Gem 004 (telemetry pipeline awareness), Gem 007 (role-based access)"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#the-problem","title":"The Problem","text":"<p>Users treat AI agents like trusted confidants. They volunteer sensitive information freely \u2014 sometimes before the agent even asks:</p> <ul> <li>\"My SSN is 123-45-6789, can you update my profile?\"</li> <li>\"The password is P@ssw0rd123, it's not working.\"</li> <li>\"My credit card number is 4111-1111-1111-1111, process the refund.\"</li> <li>\"I'm dealing with a harassment complaint about [specific person].\"</li> </ul> <p>Once typed, this data propagates to multiple locations:</p> Data Location Visibility Retention Risk Conversation window User + anyone viewing screen Session Screen shoulder-surfing LLM context window Processed by LLM Session Included in model input/output Copilot Studio logs Platform telemetry 30+ days Platform-accessible Application Insights Custom telemetry (Gem 004) Up to 730 days Queryable by admins Power Automate run history Flow execution logs 28 days Visible to flow owners Dataverse Persistent storage (Gem 001) Indefinite Queryable by admins <p>A single credit card number typed into a conversation can end up in 6 different places \u2014 each with different access controls, retention periods, and compliance implications.</p> <p>For regulated industries, this isn't theoretical:</p> <ul> <li>GDPR (EU): Data minimization \u2014 don't collect what you don't need.</li> <li>PCI-DSS: Credit card data must never be stored in plain text.</li> <li>HIPAA (US): Protected health information requires encryption and access controls.</li> <li>SOX: Financial data handling requires audit trails.</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that minimizes sensitive data exposure across all layers:</p> <ul> <li>[ ] Prevention: The agent actively discourages users from sharing sensitive data</li> <li>[ ] Detection: Sensitive patterns (SSN, credit cards, passwords) are identified when entered</li> <li>[ ] Containment: Detected sensitive data is not logged, not persisted, and not propagated</li> <li>[ ] Response safety: The agent doesn't display sensitive data in responses unnecessarily</li> <li>[ ] Compliance: Handling meets regulatory requirements for the target industry</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#approach-a-instruction-based-prevention","title":"Approach A: Instruction-Based Prevention","text":"<p>Summary: Use agent instructions to explicitly refuse sensitive data and redirect users to secure alternatives. Technique: Agent instructions with data handling rules, refusal patterns, secure alternative suggestions.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: My SSN is 123-45-6789\"] --&gt; B[\"LLM reads instructions:&lt;br/&gt;NEVER accept SSN, credit card, or passwords\"]\n    B --&gt; C[\"Agent: \u26a0\ufe0f For your security, please don't share&lt;br/&gt;sensitive information like SSNs in this chat.&lt;br/&gt;&lt;br/&gt;To update your profile securely, please use:&lt;br/&gt;\ud83d\udd12 HR Self-Service Portal&lt;br/&gt;\ud83d\udce7 hr-secure@contoso.com (encrypted email)&lt;br/&gt;&lt;br/&gt;I've noted that you need a profile update.\"]</code></pre> <p>The agent acknowledges the user's intent (profile update) while refusing the sensitive data and offering a secure alternative.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#implementation","title":"Implementation","text":"<p>Step 1: Comprehensive data handling instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Security-Aware Agent\ninstructions: |+\n  # Sensitive Data Handling Protocol\n\n  ## CRITICAL: Data You Must NEVER Accept\n\n  If a user shares ANY of the following, immediately:\n  1. Warn them NOT to share sensitive data in chat\n  2. Do NOT repeat, reference, or acknowledge the specific data they shared\n  3. Redirect to a secure alternative\n\n  ### Prohibited Data Types\n  - **Social Security Numbers** (SSN): Any 9-digit number in XXX-XX-XXXX format\n  - **Credit/Debit Card Numbers**: Any 13-19 digit number\n  - **Passwords**: Any text the user identifies as a password or credential\n  - **Bank Account Numbers**: Routing and account numbers\n  - **Personal Health Information**: Medical conditions, diagnoses, prescriptions\n  - **Government IDs**: Passport numbers, driver's license numbers\n\n  ### Response Template for Prohibited Data\n  \"\u26a0\ufe0f **For your security**, please don't share [data type] in this chat. \n  This conversation is not a secure channel for sensitive information.\n\n  Instead, please use: [appropriate secure alternative]\n\n  I can still help with your request \u2014 just without the sensitive data.\"\n\n  ## Data You CAN Handle (with care)\n  - **Name**: OK to use for personalization\n  - **Email**: OK for identification and communication\n  - **Employee ID**: OK for record lookup (non-sensitive identifier)\n  - **Phone Number**: OK if user volunteers for callback\n\n  ## Response Safety\n  - When displaying user records, MASK sensitive fields:\n    - SSN: \"***-**-6789\" (show last 4 only)\n    - Credit Card: \"**** **** **** 1111\" (show last 4 only)\n    - Salary: Display only if user has Admin role (Gem 007)\n\n  ## Secure Alternatives by Request Type\n  | User Needs | Redirect To |\n  |---|---|\n  | Update personal info | HR Self-Service Portal |\n  | Reset password | IT Self-Service Portal |\n  | Financial transaction | Finance Portal |\n  | Medical/benefits claim | Benefits Portal (encrypted) |\n  | Report harassment | Ethics Hotline (anonymous) |\n</code></pre> <p>Step 2: Create a dedicated \"sensitive data detected\" topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Sensitive Data Warning\n    triggerQueries:\n      - \"my social security number is\"\n      - \"my SSN is\"\n      - \"my credit card number\"\n      - \"my password is\"\n      - \"my bank account\"\n  actions:\n    - kind: SendActivity\n      id: securityWarning\n      activity:\n        text:\n          - \"\u26a0\ufe0f **Security Notice**\\n\\nPlease don't share sensitive personal information (SSN, credit cards, passwords) in this chat.\\n\\nThis conversation is **not encrypted** and may be logged for quality purposes.\\n\\n\ud83d\udd12 For secure actions, please use:\\n- [HR Portal](https://hr.contoso.com) for personal info updates\\n- [IT Portal](https://it.contoso.com) for password resets\\n- [Finance Portal](https://finance.contoso.com) for financial requests\\n\\nI can help with your request in other ways. What would you like to do?\"\n\n    # Log the incident (WITHOUT the sensitive data)\n    - kind: LogCustomTelemetryEvent\n      id: logSensitiveAttempt\n      eventName: SecurityEvent\n      properties: \"={EventType: \\\"SensitiveDataAttempt\\\", DataCategory: \\\"Unknown\\\", ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Instructions only + one topic. 30 minutes to implement. Maintainability \ud83d\udfe2 Update instructions and secure alternative links as needed. Channel Compatibility \ud83d\udfe2 Works in all channels. Prevention Effectiveness \ud83d\udfe1 LLM compliance is ~85-90%. It will usually refuse, but edge cases exist (disguised data, partial numbers). Detection Accuracy \ud83d\udfe1 Relies on LLM pattern recognition. No deterministic validation. Containment \ud83d\udd34 The sensitive data is already in the conversation history and LLM context. This approach prevents use, not capture."},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#limitations","title":"Limitations","text":"<ul> <li>Data is already in the message: By the time the LLM reads the instruction, the user's message (with the SSN) is already in the conversation context. The instruction prevents the agent from repeating it, but doesn't prevent it from being logged.</li> <li>LLM compliance is probabilistic: In rare cases, the agent may acknowledge or repeat the sensitive data before catching itself. Particularly with complex prompts that disguise the sensitive data.</li> <li>No regex-based detection: The LLM recognizes patterns but doesn't run regex. \"One two three-four five-six seven eight nine\" may slip through as SSN.</li> <li>Conversation logs still contain the data: Copilot Studio's platform logs capture the user's raw message regardless of the agent's instructions.</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#approach-b-input-sanitization-via-prompt-tool","title":"Approach B: Input Sanitization via Prompt Tool","text":"<p>Summary: Pre-process every user message through a Prompt Tool that detects and redacts sensitive patterns before the main agent processes it. Technique: Prompt Tool as a pre-filter, sensitive pattern detection, redacted message passed to the agent, original message blocked from further processing.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: My SSN is 123-45-6789,&lt;br/&gt;please update my profile\"] --&gt; B[\"&lt;b&gt;Prompt Tool (Sanitizer)&lt;/b&gt;&lt;br/&gt;Input: My SSN is 123-45-6789...&lt;br/&gt;Output: My SSN is REDACTED-SSN...&lt;br/&gt;Flag: sensitiveDetected = true&lt;br/&gt;Type: SSN\"]\n    B --&gt; C[\"Agent processes sanitized message ONLY&lt;br/&gt;Never sees the actual SSN\"]\n    C --&gt; D[\"Agent: \u26a0\ufe0f I detected sensitive data.&lt;br/&gt;For security, I've removed it.&lt;br/&gt;Please use HR Portal for profile updates.\"]</code></pre> <p>The Prompt Tool acts as a security gateway \u2014 the main agent never processes the raw sensitive data.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#implementation_1","title":"Implementation","text":"<p>Step 1: Create the Input Sanitizer Prompt Tool</p> <pre><code>kind: PromptTool\nid: prompt_inputSanitizer\ndisplayName: \"Input Sanitizer\"\ndescription: \"Detects and redacts sensitive data patterns from user input\"\ninstructions: |\n  Analyze the following user message for sensitive data patterns.\n\n  Message: {userMessage}\n\n  Detect these patterns:\n  - **SSN**: 9 digits in XXX-XX-XXXX or XXXXXXXXX format \u2192 Replace with [REDACTED-SSN]\n  - **Credit Card**: 13-19 digit number (may have spaces/dashes) \u2192 Replace with [REDACTED-CC]\n  - **Password**: Any text after \"password is\", \"pwd:\", \"pass:\" \u2192 Replace with [REDACTED-PWD]\n  - **Bank Account**: Routing (9 digits) + account numbers \u2192 Replace with [REDACTED-BANK]\n  - **Phone Number with context**: \"call me at\" + number \u2192 Keep (not sensitive in most contexts)\n\n  Return a JSON object:\n  {\n    \"sanitizedMessage\": \"the message with sensitive data replaced by [REDACTED-*] tokens\",\n    \"sensitiveDetected\": true/false,\n    \"detectedTypes\": [\"SSN\", \"CreditCard\", etc.],\n    \"originalContainedSensitive\": true/false\n  }\n\n  IMPORTANT: \n  - If NO sensitive data is found, return the original message unchanged\n  - NEVER include the actual sensitive data in your output\n  - Be conservative \u2014 when in doubt, redact\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: userMessage\n    type: string\n    required: true\noutputs:\n  - name: result\n    type: string\n</code></pre> <p>Step 2: Integrate as a pre-processing step</p> <p>In agent instructions:</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Secure Agent\ninstructions: |+\n  ## CRITICAL: Input Sanitization\n\n  Before processing ANY user message, call the \"InputSanitizer\" tool.\n\n  If sensitiveDetected is true:\n  1. DO NOT process the original message further\n  2. Warn the user about sharing sensitive data\n  3. Redirect to secure alternatives\n  4. Log the event (type of data detected, NOT the data itself)\n\n  If sensitiveDetected is false:\n  Process the message normally.\n</code></pre> <p>Or as an explicit topic pre-processor:</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnUnknownIntent\n  id: main\n  priority: 100\n  actions:\n    # Sanitize first\n    - kind: InvokePrompt\n      id: sanitizeInput\n      promptId: prompt_inputSanitizer\n      inputs:\n        userMessage: =System.Activity.Text\n      outputVariable: Topic.SanitizationResult\n\n    # Check if sensitive data was detected\n    - kind: ConditionGroup\n      id: checkSensitive\n      conditions:\n        - id: foundSensitive\n          condition: =Topic.SanitizationResult.sensitiveDetected = true\n          actions:\n            - kind: SendActivity\n              id: warnUser\n              activity:\n                text:\n                  - \"\u26a0\ufe0f **Security Notice**: I detected what appears to be sensitive information ({Topic.SanitizationResult.detectedTypes}) in your message.\\n\\nFor your protection, I've blocked that data from being processed.\\n\\n\ud83d\udd12 **Secure alternatives:**\\n- [HR Portal](https://hr.contoso.com) for personal info\\n- [IT Portal](https://it.contoso.com) for password issues\\n\\nHow else can I help you?\"\n\n            - kind: LogCustomTelemetryEvent\n              id: logSensitiveDetection\n              eventName: SecurityEvent\n              properties: \"={EventType: \\\"SensitiveDataDetected\\\", DataTypes: Topic.SanitizationResult.detectedTypes, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n      elseActions:\n        # No sensitive data \u2014 pass sanitized message to normal processing\n        - kind: SearchAndSummarizeContent\n          id: normalProcessing\n          variable: Topic.Answer\n          userInput: =Topic.SanitizationResult.sanitizedMessage\n</code></pre>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Prompt Tool + integration logic. Moderate setup. Maintainability \ud83d\udfe2 Sanitizer prompt is easy to update with new patterns. Channel Compatibility \ud83d\udfe2 Works in all channels (pre-processing is backend). Prevention Effectiveness \ud83d\udfe2 Agent never sees raw sensitive data \u2014 only sanitized version. Detection Accuracy \ud83d\udfe1 LLM-based detection catches most patterns but may miss encoded or disguised data. Containment \ud83d\udfe1 The main agent is protected, but the raw message still exists in platform logs and the Prompt Tool's own processing."},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#limitations_1","title":"Limitations","text":"<ul> <li>Double LLM cost: Every message goes through the sanitizer LLM call before the main agent processes it. +1-2 seconds latency and ~50% more tokens per turn.</li> <li>Raw message still in platform logs: The user's original message (with the SSN) is captured by Copilot Studio's platform-level logging before the Prompt Tool can sanitize it. This approach protects the agent but not the platform logs.</li> <li>False positives: A 9-digit number in a business context (\"Order #123456789\") may be flagged as SSN. The sanitizer needs tuning for domain-specific patterns.</li> <li>Prompt Tool isn't regex: LLM-based detection is approximate. A deliberately encoded SSN (\"one-two-three dash four-five dash six-seven-eight-nine\") may not be caught.</li> <li>Still in conversation history: The user's original message is in the conversation view. The sanitizer prevents the agent from using it, but the text remains visible in the chat window.</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#approach-c-telemetry-and-storage-redaction","title":"Approach C: Telemetry and Storage Redaction","text":"<p>Summary: Accept that sensitive data may enter the conversation, but ensure it doesn't persist in logs, telemetry, or storage. Defense-in-depth at the data layer. Technique: Application Insights data masking, Power Automate log configuration, Dataverse field-level security, retention policies.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User types sensitive data&lt;br/&gt;(enters conversation \u2014 unavoidable)\"] --&gt; B[\"&lt;b&gt;Layer 1: Agent instructions&lt;/b&gt; (Approach A)&lt;br/&gt;Agent refuses to repeat/use the data\"]\n    B --&gt; C[\"&lt;b&gt;Layer 2: Sanitizer pre-processing&lt;/b&gt; (Approach B)&lt;br/&gt;Main agent doesn't process raw data\"]\n    C --&gt; D[\"&lt;b&gt;Layer 3: Telemetry redaction&lt;/b&gt; (THIS approach)\"]\n    D --&gt; E[\"Application Insights:&lt;br/&gt;Telemetry initializer strips PII\"]\n    D --&gt; F[\"Power Automate:&lt;br/&gt;Secure inputs/outputs enabled on flows\"]\n    D --&gt; G[\"Dataverse:&lt;br/&gt;Field-level security on sensitive columns\"]\n    D --&gt; H[\"Retention:&lt;br/&gt;Short retention for conversation logs\"]</code></pre> <p>This is the post-capture defense. It doesn't prevent sensitive data from entering the system, but ensures it doesn't persist where it can be accessed later.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#implementation_2","title":"Implementation","text":"<p>Step 1: Application Insights \u2014 Never log raw user messages</p> <p>In your telemetry events, never include <code>System.Activity.Text</code> directly:</p> <pre><code>    # BAD \u2014 logs the raw user message (may contain PII)\n    - kind: LogCustomTelemetryEvent\n      id: log_bad\n      eventName: AgentTrace\n      properties: \"={UserMessage: System.Activity.Text, ConversationId: System.Conversation.Id}\"\n\n    # GOOD \u2014 logs ONLY non-sensitive metadata\n    - kind: LogCustomTelemetryEvent\n      id: log_good\n      eventName: AgentTrace\n      properties: \"={TopicName: \\\"PasswordReset\\\", MessageLength: Len(System.Activity.Text), ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n</code></pre> <p>Rule: Log the topic name, message length, and metadata \u2014 never the message text itself.</p> <p>Step 2: Application Insights \u2014 Reduce retention</p> <p>Configure Application Insights retention:</p> <ol> <li>Azure Portal \u2192 Application Insights \u2192 Usage and estimated costs \u2192 Data Retention</li> <li>Set retention to 30 days (minimum) instead of the default 90</li> <li>For highly sensitive agents, consider 7-day retention</li> </ol> <p>Step 3: Power Automate \u2014 Enable secure inputs/outputs</p> <p>For flows that handle user messages:</p> <ol> <li>Open the flow in Power Automate</li> <li>For each action, click <code>...</code> \u2192 Settings</li> <li>Enable Secure Inputs and Secure Outputs</li> <li>This hides the input/output values from flow run history</li> </ol> <pre><code>// In the flow definition JSON\n\"actions\": {\n  \"Process_User_Message\": {\n    \"type\": \"Compose\",\n    \"inputs\": \"@triggerBody()?['userMessage']\",\n    \"runtimeConfiguration\": {\n      \"secureData\": {\n        \"properties\": [\"inputs\", \"outputs\"]\n      }\n    }\n  }\n}\n</code></pre> <p>Step 4: Dataverse \u2014 Exclude sensitive data from persisted context</p> <p>When using Gem 001's persistence pattern, explicitly exclude sensitive fields:</p> <pre><code>    # NEVER persist raw user messages\n    - kind: InvokeFlow\n      id: saveContext\n      flowId: \"@environmentVariables('WriteContextFlowId')\"\n      inputs:\n        userId: =System.User.Id\n        preferredLanguage: =Global.PreferredLanguage    # \u2705 OK to persist\n        region: =Global.UserRegion                       # \u2705 OK to persist\n        lastTopicName: =Global.LastTopicName             # \u2705 OK to persist\n        # DO NOT persist: System.Activity.Text, Topic.UserMessage, or any raw input\n</code></pre> <p>Step 5: Create a data handling policy document</p> <pre><code>## Agent Data Handling Policy\n\n### Data Classification\n| Data Type | Classification | Can Log? | Can Persist? | Can Display? |\n|---|---|---|---|---|\n| User name | Low | \u2705 Yes | \u2705 Yes | \u2705 Yes |\n| Email | Low | \u2705 Yes | \u2705 Yes | \u2705 Yes |\n| Employee ID | Low | \u2705 Yes | \u2705 Yes | \u2705 Yes |\n| User message text | Medium | \u274c Never raw | \u274c Never | N/A (input) |\n| SSN | Critical | \u274c Never | \u274c Never | Masked (last 4) |\n| Credit card | Critical | \u274c Never | \u274c Never | Masked (last 4) |\n| Password | Critical | \u274c Never | \u274c Never | \u274c Never |\n| Salary | High | \u2705 Admins only | \u2705 With access control | \u2705 Role-gated (Gem 007) |\n| Medical info | Critical | \u274c Never | \u274c Never | \u274c Never |\n</code></pre>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Multiple configuration points across platforms. No code, but many settings. Maintainability \ud83d\udfe2 Once configured, settings persist. Policy document guides future development. Channel Compatibility \ud83d\udfe2 Backend configurations \u2014 all channels benefit equally. Prevention Effectiveness N/A This approach doesn't prevent \u2014 it contains. Detection Accuracy N/A No detection component. Containment \ud83d\udfe2 Strongest layer. Even if data enters, it doesn't persist in queryable form."},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#limitations_2","title":"Limitations","text":"<ul> <li>Doesn't prevent initial capture: Copilot Studio's platform-level telemetry captures the raw message before any of your configurations apply. You control your custom telemetry and storage \u2014 not the platform's internal logs.</li> <li>Platform log access: Microsoft may retain conversation data for service operation purposes. Check the Microsoft Privacy Statement and your specific licensing agreement.</li> <li>Operational impact: Secure inputs/outputs in Power Automate make debugging harder \u2014 you can't see flow inputs in run history when investigating issues. Security vs debuggability trade-off.</li> <li>Requires cross-team coordination: App Insights configuration, Power Automate settings, and Dataverse security involve different admin roles. Needs coordination.</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Instructions Approach B: Sanitizer Approach C: Redaction Layer Prevention (refuse) Detection (before agent) Containment (after capture) Implementation Effort \ud83d\udfe2 Low (30 min) \ud83d\udfe1 Medium (2-3 hours) \ud83d\udfe1 Medium (2-3 hours) Runtime Cost \ud83d\udfe2 Zero extra \ud83d\udfe1 +1 LLM call per turn \ud83d\udfe2 Zero extra Protects Agent Context \ud83d\udfe1 Agent still sees raw message \ud83d\udfe2 Agent sees sanitized only \ud83d\udd34 Agent sees raw message Protects Logs \ud83d\udd34 No (platform logs raw) \ud83d\udd34 No (platform logs raw) \ud83d\udfe2 Custom logs redacted Protects Storage \ud83d\udfe1 Depends on dev discipline \ud83d\udfe1 Depends on dev discipline \ud83d\udfe2 Policy-enforced Determinism \ud83d\udfe1 LLM ~85-90% \ud83d\udfe1 LLM ~90-95% \ud83d\udfe2 Configuration-based Best When... Minimum viable security Agent context must be clean Compliance / audit requirements"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#recommended-approach","title":"Recommended Approach","text":"<p>Layer all three \u2014 they address different layers of the problem:</p> <pre><code>Layer 1 (Prevention):   Approach A \u2014 Agent instructions refuse sensitive data\nLayer 2 (Detection):    Approach B \u2014 Sanitizer catches what slips through\nLayer 3 (Containment):  Approach C \u2014 Logs and storage redacted as safety net\n\nDefense-in-depth: each layer catches what the previous missed.\n</code></pre> <p>For basic agents: Start with Approach A alone \u2014 instructions that refuse sensitive data and redirect to secure channels. This covers 85-90% of cases at zero cost.</p> <p>For regulated agents: Add Approach C \u2014 telemetry redaction, secure I/O on flows, and a data handling policy. This satisfies compliance auditors.</p> <p>For maximum protection: Add Approach B \u2014 the sanitizer ensures the main agent never processes raw sensitive data. Worth the LLM cost for healthcare, finance, or government agents.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Copilot Studio platform logs capture raw user messages. Your custom telemetry and storage can be redacted, but the platform's internal conversation logs capture everything the user types. Check your org's data retention settings and Microsoft's data processing agreements for compliance implications.</p> <p>Warning</p> <p>LLM-based detection is not PCI-DSS compliant on its own. PCI-DSS requires deterministic protection of credit card data. LLM pattern detection (~90-95% accuracy) is not sufficient for PCI compliance. For payment processing agents, use server-side regex validation as an additional layer, or redirect all payment operations to a certified payment page.</p> <p>Warning</p> <p>The user's original message is visible in the conversation window. Even if you sanitize the message for the agent, the user's original text (containing the SSN) remains visible in the chat window. There's no way to \"delete\" or \"mask\" a sent message in Copilot Studio channels. The only defense is instructing the user not to share it in the first place.</p> <p>Note</p> <p>\"Secure Inputs/Outputs\" in Power Automate hides data from run history. This is powerful for compliance but makes debugging harder. Consider enabling it only in production environments, not in dev/test.</p> <p>Note</p> <p>Application Insights data masking can be configured in the SDK. If you have access to the Application Insights configuration, you can add a telemetry initializer that strips PII patterns from all events before they're sent. This is the most thorough protection for custom telemetry.</p>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 004: Debug Mode \u2014 Custom telemetry events must exclude sensitive data. GEM-022 defines what to log and what to redact.</li> <li>Gem 007: Role-Based Feature Gating \u2014 Control who can see sensitive data in agent responses (e.g., salary data only for HR admins).</li> <li>Gem 001: Persisting User Context \u2014 Define what user data is safe to persist vs what must be excluded.</li> <li>Gem 010: Human Handoff \u2014 Escalation summaries must not include sensitive data the user shared.</li> <li>Gem 016: Conversation Analytics \u2014 Analytics queries should never return raw user messages.</li> </ul>"},{"location":"gems/GEM-022-secure-data-handling-in-conversations/#references","title":"References","text":"<ul> <li>Microsoft Privacy Statement</li> <li>Microsoft Learn: Data loss prevention in Power Platform</li> <li>PCI-DSS compliance for AI systems</li> <li>GDPR Article 25: Data protection by design</li> <li>Microsoft Learn: Secure inputs/outputs in Power Automate</li> <li>Application Insights: Data masking and privacy</li> </ul> <p>Gem 022 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/","title":"Gem 023: MCP Connector Integration Patterns","text":"<p>MCP, custom connector, or HTTP node? Choose the right integration tool for the job.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50 (Moderate \u2014 connector selection + configuration) Channels All (MCP requires Generative Orchestration) Prerequisite Gems None (Gem 015 complementary for Dataverse-specific patterns)"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#the-problem","title":"The Problem","text":"<p>Your agent needs to call an external service \u2014 a CRM, a ticketing system, a weather API, an internal database. Copilot Studio offers four different ways to connect to external services, and the documentation doesn't tell you which one to use:</p> <ol> <li>Model Context Protocol (MCP): The newest option. Connect to an MCP server that publishes tools and resources. The agent auto-discovers available operations.</li> <li>Power Platform Custom Connector: The traditional Power Platform approach. Define an OpenAPI spec, configure authentication, register operations.</li> <li>Power Automate Flow: Build a visual flow that calls the API and returns results. Register the flow as a tool.</li> <li>HTTP Request Node: Call any REST API directly from a topic with the <code>HttpRequest</code> node.</li> </ol> <p>Each serves different use cases, and choosing the wrong one wastes time or limits capabilities:</p> <ul> <li>MCP is magical when an MCP server exists \u2014 auto-discovery, auto-sync, zero per-agent configuration. But if no MCP server exists, you must build one first.</li> <li>Custom Connectors are reusable across agents and environments, but require OpenAPI spec authoring and connector certification for sharing.</li> <li>Power Automate Flows are visual and familiar, but each call consumes a flow run against your quota, and the flow adds 1-3 seconds latency.</li> <li>HTTP Nodes are the most flexible but require manual URL construction, authentication management, and no connector governance.</li> </ul> <p>Most builders choose based on familiarity (what they already know), not fitness (what best serves the scenario).</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A clear decision framework for selecting the right integration approach:</p> <ul> <li>[ ] Right tool for the job: Each integration scenario uses the most appropriate connector type</li> <li>[ ] Minimal overhead: No unnecessary infrastructure (don't build a flow when an HTTP node suffices)</li> <li>[ ] Future-proof: Integration approach supports upstream API changes gracefully</li> <li>[ ] Governable: IT can manage, monitor, and control what external services agents access</li> <li>[ ] Reusable: Integrations built once can be used across multiple agents</li> </ul>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#approach-a-model-context-protocol-mcp-connector","title":"Approach A: Model Context Protocol (MCP) Connector","text":"<p>Summary: Connect to an MCP server that publishes tools and resources. The agent auto-discovers operations and their parameters. When the upstream API changes, the MCP server updates once and all agents automatically use the new version. Technique: Copilot Studio MCP onboarding wizard, MCP server (prebuilt or custom), Streamable HTTP transport, OAuth 2.0 / API key / no auth.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#how-it-works","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;Tools auto-discovered:&lt;br/&gt;\u2022 search_tickets&lt;br/&gt;\u2022 create_ticket&lt;br/&gt;\u2022 get_customer&lt;br/&gt;\u2022 update_status\"] -- \"MCP\" --&gt; B[\"&lt;b&gt;MCP Server&lt;/b&gt;&lt;br/&gt;(tools + resources)&lt;br/&gt;&lt;br/&gt;Publishes:&lt;br/&gt;\u2022 Tool name + description&lt;br/&gt;\u2022 Input schema (JSON Schema)&lt;br/&gt;\u2022 Output schema&lt;br/&gt;\u2022 Auth requirements\"]\n    B -- \"JSON\" --&gt; A\n    B -- \"API\" --&gt; C[\"&lt;b&gt;Backend Service&lt;/b&gt;\"]\n    C --&gt; B</code></pre> <p>The MCP server is the single source of truth for tool definitions. When a new operation is added or an existing one changes, the server updates once \u2014 all connected agents reflect the change automatically, without republishing.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#implementation","title":"Implementation","text":"<p>Step 1: Connect to a prebuilt Microsoft MCP server</p> <p>Microsoft provides prebuilt MCP connectors for common services:</p> Prebuilt MCP Server Tools Available Dataverse Query tables, describe schema, CRUD operations Outlook Send email, search emails, manage calendar GitHub Repository operations, issues, pull requests Salesforce Account, contact, opportunity management JIRA Issue management, project queries <p>To add a prebuilt connector:</p> <ol> <li>Go to Tools \u2192 Add a tool</li> <li>Select Model Context Protocol</li> <li>Browse the catalog of available MCP connectors</li> <li>Select the desired connector \u2192 Authorize \u2192 Add to agent</li> </ol> <p>Step 2: Connect to a custom MCP server</p> <p>If no prebuilt connector exists, use the MCP onboarding wizard:</p> <ol> <li>Go to Tools \u2192 Add a tool \u2192 New tool \u2192 Model Context Protocol</li> <li>Fill in:</li> <li>Server Name: \"Inventory Service\"</li> <li>Server Description: \"Manages product inventory \u2014 check stock, reserve items, update quantities\"</li> <li>Server URL: <code>https://inventory-mcp.contoso.com/mcp</code></li> <li>Configure authentication:</li> <li>None: For internal services on private networks</li> <li>API Key: Header or query parameter authentication</li> <li>OAuth 2.0: Dynamic discovery, dynamic, or manual configuration</li> <li>Click Create \u2192 Add to agent</li> </ol> <p>Step 3: Configure which tools the agent can use</p> <p>After adding the MCP server:</p> <ol> <li>Go to Tools \u2192 Select the MCP server</li> <li>View the auto-discovered Tools and Resources</li> <li>Toggle off tools the agent shouldn't use (e.g., disable <code>delete_item</code> for safety)</li> <li>The Allow all toggle controls auto-enabling of newly published tools</li> </ol> <pre><code>Tools from Inventory MCP Server:\n  \u2705 check_stock        \u2014 Check available quantity for a product\n  \u2705 reserve_item       \u2014 Reserve items for an order\n  \u2705 get_product_info   \u2014 Get product details and pricing\n  \u274c delete_product     \u2014 DISABLED (admin only, not agent-accessible)\n  \u274c bulk_update        \u2014 DISABLED (too risky for conversational use)\n</code></pre> <p>Step 4: Agent instructions for MCP tool usage</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Inventory Agent\ninstructions: |+\n  # Inventory Agent\n\n  You have access to the Inventory MCP Server. Use these tools to help users:\n\n  ## Available Tools\n  - **check_stock**: Use when users ask about product availability\n  - **reserve_item**: Use when users want to place a hold on items\n  - **get_product_info**: Use for pricing, descriptions, specifications\n\n  ## Rules\n  - ALWAYS confirm before reserving items\n  - If stock is zero, suggest alternatives or notify the user\n  - Format results as tables when showing multiple products\n  - Never reveal wholesale pricing (only retail)\n</code></pre> <p>Step 5: Build a custom MCP server (when none exists)</p> <p>If you need to expose a custom API as MCP, build an MCP server:</p> <pre><code>Your REST API                    MCP Server Wrapper              Copilot Studio\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n/api/tickets (GET, POST)   \u2190\u2500\u2500  Expose as MCP tools:            Agent auto-discovers:\n/api/tickets/:id (PATCH)         \u2022 search_tickets                \u2022 search_tickets\n/api/customers (GET)             \u2022 create_ticket                 \u2022 create_ticket\n                                 \u2022 update_ticket                 \u2022 update_ticket\n                                 \u2022 get_customer                  \u2022 get_customer\n</code></pre> <p>Microsoft provides an MCP server implementation example on GitHub. Use the Streamable HTTP transport (SSE is deprecated after August 2025).</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Prebuilt: 3 clicks. Custom server: moderate effort to build, then 3 clicks to connect. Maintainability \ud83d\udfe2 Tool updates on server auto-sync to all agents. Zero per-agent maintenance. Channel Compatibility \ud83d\udfe2 All channels (requires Generative Orchestration). Reusability \ud83d\udfe2 One MCP server serves unlimited agents. Publish connector for cross-tenant sharing. Governance \ud83d\udfe2 Selective tool toggling per agent. Auth managed centrally on the server. Auto-Discovery \ud83d\udfe2 Tools and resources auto-discovered. Name, description, inputs inherited from server."},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#limitations","title":"Limitations","text":"<ul> <li>Generative Orchestration required: MCP tools are only available when generative orchestration is enabled. Manual topics cannot call MCP tools directly.</li> <li>MCP server must exist: If no prebuilt connector exists and no MCP server is available, you must build one. This is the server-side investment that custom connectors and HTTP nodes don't require.</li> <li>Can't enrich tool descriptions per agent: The tool description comes from the MCP server. You can't add agent-specific context to a tool's description to improve routing accuracy.</li> <li>No custom input/output transformation: The MCP server defines the exact input/output schema. If you need to transform data before or after the call, you need a wrapper flow or a modified MCP server.</li> <li>Transport limitation: Only Streamable HTTP is supported. SSE deprecated after August 2025.</li> </ul>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#approach-b-power-platform-custom-connector","title":"Approach B: Power Platform Custom Connector","text":"<p>Summary: Define a custom connector from an OpenAPI specification. Register operations as agent tools. Reusable across agents and environments within the Power Platform. Technique: OpenAPI/Swagger spec, Power Platform custom connector wizard, operation registration in Copilot Studio.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;\"] -- \"Custom Connector\" --&gt; B[\"&lt;b&gt;Custom Connector&lt;/b&gt;&lt;br/&gt;(OpenAPI spec)&lt;br/&gt;&lt;br/&gt;Operations:&lt;br/&gt;\u2022 GET /tickets \u2192 Search Tickets&lt;br/&gt;\u2022 POST /tickets \u2192 Create Ticket&lt;br/&gt;\u2022 PATCH /tickets/id \u2192 Update Ticket&lt;br/&gt;\u2022 GET /customers/id \u2192 Get Customer\"]\n    B --&gt; A\n    B -- \"API\" --&gt; C[\"&lt;b&gt;Backend Service&lt;/b&gt;\"]\n    C --&gt; B</code></pre> <p>Each operation has manually-defined descriptions, parameters, and response schemas. The connector is a registered Power Platform resource with managed authentication.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#implementation_1","title":"Implementation","text":"<p>Step 1: Create an OpenAPI specification</p> <pre><code>openapi: 3.0.0\ninfo:\n  title: Contoso Ticket API\n  version: 1.0.0\n  description: Support ticket management API\nservers:\n  - url: https://api.contoso.com/v1\npaths:\n  /tickets:\n    get:\n      operationId: searchTickets\n      summary: Search support tickets\n      description: Search and filter support tickets. Use when users ask about their tickets, open cases, or ticket status.\n      parameters:\n        - name: userId\n          in: query\n          required: true\n          schema:\n            type: string\n          description: The ID of the user whose tickets to search\n        - name: status\n          in: query\n          required: false\n          schema:\n            type: string\n            enum: [open, in_progress, resolved, cancelled]\n          description: Filter by ticket status\n      responses:\n        '200':\n          description: List of matching tickets\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  type: object\n                  properties:\n                    ticketId: { type: string }\n                    title: { type: string }\n                    status: { type: string }\n                    priority: { type: string }\n                    createdAt: { type: string, format: date-time }\n    post:\n      operationId: createTicket\n      summary: Create a new support ticket\n      description: Create a new support ticket for a user. Use when users want to report an issue or submit a request.\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              type: object\n              required: [title, description, priority]\n              properties:\n                title: { type: string, description: Brief issue description }\n                description: { type: string, description: Detailed issue description }\n                priority: { type: string, enum: [low, medium, high, critical] }\n      responses:\n        '201':\n          description: Ticket created successfully\n</code></pre> <p>Step 2: Create the custom connector in Power Platform</p> <ol> <li>Go to Power Apps \u2192 Custom Connectors \u2192 New custom connector \u2192 Import from OpenAPI</li> <li>Upload or paste your OpenAPI spec</li> <li>Configure authentication (API key, OAuth 2.0, etc.)</li> <li>Test each operation</li> <li>Create the connector</li> </ol> <p>Step 3: Add connector operations to your agent</p> <ol> <li>In Copilot Studio \u2192 Tools \u2192 Add a tool</li> <li>Search for your custom connector name</li> <li>Select the operations you want \u2192 Add to agent</li> </ol> <p>Each operation appears as a separate tool with the description from your OpenAPI spec.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires OpenAPI spec + connector creation. Moderate effort. Maintainability \ud83d\udfe1 API changes require updating the OpenAPI spec and connector. Manual per-change. Channel Compatibility \ud83d\udfe2 Works in all channels. Reusability \ud83d\udfe2 Connector reusable across agents, flows, and Power Apps in the environment. Governance \ud83d\udfe2 Power Platform DLP policies apply. Admin-managed connector approval. Auto-Discovery \ud83d\udd34 No auto-discovery. Operations must be manually defined and described."},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#limitations_1","title":"Limitations","text":"<ul> <li>OpenAPI spec authoring: Writing a good OpenAPI spec with clear descriptions, proper schemas, and examples is non-trivial. Poor descriptions lead to poor LLM routing.</li> <li>Manual updates: When the API changes (new endpoint, modified parameters), you must update the OpenAPI spec, update the connector, and potentially update the agent.</li> <li>Per-environment: Custom connectors are environment-specific unless certified and published to the connector catalog.</li> <li>Description quality is critical: The LLM uses operation descriptions to decide when to call each operation. Vague descriptions (\"Process data\") lead to misrouting. Invest in clear, specific descriptions.</li> </ul>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#approach-c-http-request-node-direct-api-call","title":"Approach C: HTTP Request Node (Direct API Call)","text":"<p>Summary: Call any REST API directly from a topic using the <code>HttpRequest</code> node. Maximum flexibility, zero infrastructure overhead. Technique: <code>HttpRequest</code> node in topic YAML, environment variables for URLs and keys, manual response parsing.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#how-it-works_2","title":"How It Works","text":"<pre><code>Topic YAML \u2192 HttpRequest node \u2192 REST API \u2192 JSON response \u2192 Parse \u2192 Use in topic\n</code></pre> <p>No connector, no MCP server, no Power Automate. The agent calls the API directly with a configured HTTP request.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#implementation_2","title":"Implementation","text":"<p>See Gem 009 (Graceful Degradation) and Gem 015 (Dataverse CRUD, Approach B) for detailed <code>HttpRequest</code> node examples. The pattern is:</p> <pre><code>    - kind: HttpRequest\n      id: http_searchTickets\n      method: GET\n      url: =Concatenate(Env.agent_ApiBaseUrl, \"/tickets?userId=\", EncodeUrl(System.User.Id), \"&amp;status=open\")\n      headers:\n        - key: \"Authorization\"\n          value: =Concatenate(\"Bearer \", Env.agent_ApiKey)\n        - key: \"Accept\"\n          value: \"application/json\"\n      responseType: json\n      responseVariable: Topic.TicketResults\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.HttpStatus\n      timeout: 10000\n\n    - kind: ConditionGroup\n      id: checkResults\n      conditions:\n        - id: success\n          condition: =Topic.HttpStatus &gt;= 200 &amp;&amp; Topic.HttpStatus &lt; 300\n          actions:\n            - kind: SendActivity\n              id: showResults\n              activity:\n                text:\n                  - \"Found {Len(Topic.TicketResults)} tickets...\"\n      elseActions:\n        - kind: SendActivity\n          id: showError\n          activity:\n            text:\n              - \"I couldn't retrieve your tickets right now. Please try again in a few minutes.\"\n</code></pre>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 No infrastructure, but URL construction and response parsing are manual. Maintainability \ud83d\udd34 API changes require editing YAML in every topic that calls the API. Channel Compatibility \ud83d\udfe2 Works in all channels. Reusability \ud83d\udd34 Not reusable. Each agent must configure its own HTTP calls. Governance \ud83d\udd34 No DLP policy coverage. No admin visibility into what APIs agents call. Auto-Discovery \ud83d\udd34 No auto-discovery. Everything is manually configured."},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#limitations_2","title":"Limitations","text":"<ul> <li>No governance: IT admins have no visibility into what HTTP endpoints agents call. No DLP policy coverage.</li> <li>URL string construction: Building OData or REST URLs with query parameters in Power Fx is error-prone and hard to debug.</li> <li>Response parsing: You must parse JSON responses manually. Nested objects require careful Power Fx expressions.</li> <li>Not reusable: The HTTP call configuration is embedded in topic YAML. Can't be shared across agents.</li> <li>Authentication management: API keys in environment variables. No connector-level credential management.</li> </ul>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: MCP Approach B: Custom Connector Approach C: HTTP Node Setup Effort \ud83d\udfe2 Prebuilt: 3 clicks. Custom: build server \ud83d\udfe1 OpenAPI spec + connector creation \ud83d\udfe1 URL + header configuration per call Upstream API Changes \ud83d\udfe2 Auto-sync (MCP server updates once) \ud83d\udd34 Manual spec + connector update \ud83d\udd34 Manual YAML edit per topic Reusability \ud83d\udfe2 One server, unlimited agents \ud83d\udfe2 One connector, multiple agents \ud83d\udd34 Per-topic, per-agent Governance \ud83d\udfe2 Tool toggling + auth on server \ud83d\udfe2 DLP policies + admin approval \ud83d\udd34 No governance Auto-Discovery \ud83d\udfe2 Tools auto-discovered from server \ud83d\udd34 Manual operation definitions \ud83d\udd34 Fully manual Manual Topics \ud83d\udd34 Cannot call from manual topics \ud83d\udfe2 Available in flows + topics \ud83d\udfe2 Available in any topic Generative Orchestration \ud83d\udfe2 Required (and native) \ud83d\udfe2 Supported \ud83d\udfe1 Requires manual topic routing Flow Quota \ud83d\udfe2 None \ud83d\udfe1 If called via flow \ud83d\udfe2 None Best When... MCP server exists or can be built; multiple agents consume same API Reusable across Power Platform; governance required Quick prototype; one-off API call; manual topic control"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#decision-framework","title":"Decision Framework","text":"<p>Use this flowchart to select the right approach:</p> <pre><code>Does a prebuilt MCP connector exist? (Dataverse, Outlook, GitHub, Salesforce, JIRA)\n  \u2502\n  \u251c\u2500\u2500 YES \u2192 Use Approach A (MCP prebuilt). Done.\n  \u2502\n  \u2514\u2500\u2500 NO \u2192 Do you control the API?\n            \u2502\n            \u251c\u2500\u2500 YES \u2192 Will multiple agents use this API?\n            \u2502          \u2502\n            \u2502          \u251c\u2500\u2500 YES \u2192 Build an MCP server (Approach A custom)\n            \u2502          \u2502          Best long-term investment: auto-sync, auto-discovery\n            \u2502          \u2502\n            \u2502          \u2514\u2500\u2500 NO  \u2192 Is governance/DLP required?\n            \u2502                     \u2502\n            \u2502                     \u251c\u2500\u2500 YES \u2192 Custom Connector (Approach B)\n            \u2502                     \u2502\n            \u2502                     \u2514\u2500\u2500 NO  \u2192 HTTP Node (Approach C)\n            \u2502                               Fastest for single-agent, single-call\n            \u2502\n            \u2514\u2500\u2500 NO (third-party API) \u2192 Does a community MCP server exist?\n                                        \u2502\n                                        \u251c\u2500\u2500 YES \u2192 Use it (Approach A)\n                                        \u2502\n                                        \u2514\u2500\u2500 NO  \u2192 Is an OpenAPI spec available?\n                                                   \u2502\n                                                   \u251c\u2500\u2500 YES \u2192 Custom Connector (Approach B)\n                                                   \u2502\n                                                   \u2514\u2500\u2500 NO  \u2192 HTTP Node (Approach C)\n</code></pre>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#recommended-approach","title":"Recommended Approach","text":"<p>Default to MCP when possible: If a prebuilt MCP connector exists for your service, it's always the fastest and most maintainable option. The auto-sync capability alone justifies MCP \u2014 when upstream APIs change, you update the MCP server once instead of updating every agent.</p> <p>Build an MCP server when: Multiple agents will consume the same API, or the API changes frequently. The upfront server investment pays for itself through zero per-agent maintenance.</p> <p>Use Custom Connectors when: You need Power Platform governance (DLP policies, admin approval), or you're integrating an API that's also used in Power Automate flows and Power Apps (connector is shared across the platform).</p> <p>Use HTTP Nodes when: Quick prototyping, one-off API calls in a single manual topic, or when you need full control over the HTTP request (custom headers, complex URL construction, response transformation).</p> <pre><code>Prebuilt MCP exists     \u2192  Approach A (MCP prebuilt, 3 clicks)\nMulti-agent, API changes \u2192  Approach A (MCP custom server, build once)\nGovernance required      \u2192  Approach B (Custom Connector, reusable)\nQuick prototype          \u2192  Approach C (HTTP Node, fastest start)\n</code></pre>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>MCP requires Generative Orchestration. MCP tools are only available when generative orchestration is enabled. If your agent uses only manually-authored topics (Gem 027's deterministic flows), you cannot call MCP tools. Use Power Automate flows or HTTP nodes instead.</p> <p>Warning</p> <p>SSE transport is deprecated after August 2025. If connecting to an MCP server, ensure it supports the Streamable HTTP transport. Servers using the older SSE (Server-Sent Events) transport are no longer supported by Copilot Studio.</p> <p>Warning</p> <p>MCP tool descriptions can't be enriched per agent. The tool name and description come from the MCP server. If the description is vague (\"Process data\"), the LLM will struggle to know when to call it. Fix the description on the server side, not the agent side. For agent-specific routing guidance, use agent instructions.</p> <p>Note</p> <p>Prebuilt MCP connectors are expanding rapidly. Microsoft adds new prebuilt MCP connectors regularly. Check the catalog before building a custom connector or MCP server \u2014 the service you need may already be available.</p> <p>Note</p> <p>MCP resources must be exposed as tool outputs. For an MCP resource (file-like data) to be used by a Copilot Studio agent, the MCP server owner must configure the resource as an output of one of the MCP tools. Resources alone aren't directly accessible \u2014 they must flow through a tool.</p> <p>Note</p> <p>New tools added to an MCP server are off by default when \"Allow all\" is disabled. If you've toggled off \"Allow all\" and selectively enabled tools, any new tools published by the server won't auto-enable. You must manually enable them. This is a safety feature for governance.</p>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 015: Dataverse CRUD Operations \u2014 Approach D uses the prebuilt Dataverse MCP Server</li> <li>Gem 009: Graceful Degradation \u2014 Error handling patterns apply to all integration approaches</li> <li>Gem 018: SharePoint Document Retrieval \u2014 Graph API calls can be via HTTP node or custom connector</li> <li>Gem 007: Role-Based Feature Gating \u2014 Control which users can trigger which tools</li> <li>Gem 014: Proactive Messages \u2014 Event triggers can invoke MCP tools autonomously</li> </ul>"},{"location":"gems/GEM-023-mcp-connector-integration-patterns/#references","title":"References","text":"<ul> <li>Microsoft Learn: Extend your agent with Model Context Protocol</li> <li>Microsoft Learn: Connect to an existing MCP server</li> <li>Microsoft Learn: Add MCP tools and resources to your agent</li> <li>Microsoft Learn: Create a new MCP server</li> <li>Microsoft Learn: Agent tools guidance \u2014 when to use MCP</li> <li>Microsoft Learn: Dataverse MCP Server</li> <li>MCP Server implementation example (GitHub)</li> <li>Model Context Protocol specification</li> </ul> <p>Gem 023 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current (MCP GA)</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/","title":"Gem 024: Multi-Agent Composition and Connected Agent Patterns","text":"<p>One agent can't do everything. But how do you split responsibilities across multiple agents without creating an unmanageable mess?</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50\u2b50 (multi-agent architecture design + connection configuration) Channels All (with M365 Copilot limitations for Fabric Data Agents) Prerequisite Gems Gem 002 (persona routing as the simplest multi-agent case), Gem 013 (testing multi-agent architectures)"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#the-problem","title":"The Problem","text":"<p>Your agent started simple: one agent, five topics, one knowledge source. Then it grew.</p> <p>Now it has 35 topics, 12 tools, 3 knowledge sources, and serves 4 departments. The orchestrator struggles to differentiate between similarly-described topics. Response quality degrades because the instruction set is 5,000 words long. Three different teams want to update their portion of the agent independently. And the data science team built a Fabric Data Agent for analytics questions that needs to plug in somehow.</p> <p>Copilot Studio now supports five distinct ways to compose multi-agent solutions:</p> Connection Type What It Is Child Agents Lightweight agents defined within your main agent's solution Connected Copilot Studio Agents Separate, independently published agents in the same environment Microsoft Foundry Agents (preview) AI agents built in Azure AI Foundry, connected by agent ID Fabric Data Agents (preview) Data-grounding agents from Microsoft Fabric (Gem 028) A2A Protocol Agents (preview) Any agent implementing the open Agent2Agent standard <p>The challenge isn't can you connect agents \u2014 it's which connection type to use, when to split vs keep together, and how to manage the resulting architecture. Get it wrong and you have:</p> <ul> <li>Over-splitting: 10 connected agents with 2 topics each. Every query adds an orchestration hop. Latency doubles.</li> <li>Under-splitting: One monolith agent with 50 tools. The orchestrator can't distinguish between them. Routing accuracy drops.</li> <li>Wrong boundary: You split by technology (one agent for Power Automate flows, one for HTTP calls) instead of by domain (one for HR, one for IT). Users can't tell the difference, but the orchestrator can \u2014 badly.</li> </ul> <p>Microsoft's own guidance: performance degrades when a single agent has more than 30-40 choices (tools + topics + agents combined). That's your split signal.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A well-composed multi-agent solution where:</p> <ul> <li>[ ] Clear domain boundaries: Each agent owns a distinct domain (HR, IT, Finance) or capability (analytics, document search)</li> <li>[ ] Right connection type: Child agents for simple cases, connected agents for team independence, external agents for cross-platform</li> <li>[ ] Manageable orchestration: The main agent has &lt; 30 choices and routes accurately</li> <li>[ ] Independent lifecycle: Teams can update their agents without redeploying the entire solution</li> <li>[ ] Acceptable latency: Each orchestration hop adds &lt; 2 seconds; total response time &lt; 5 seconds</li> </ul>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#approach-a-child-agents-monolith-pattern","title":"Approach A: Child Agents (Monolith Pattern)","text":"<p>Summary: Create lightweight specialist agents as <code>AgentDialog</code> components within your main agent's solution. Single deployment, single ALM pipeline, lowest latency. Technique: <code>AgentDialog</code> YAML components, generative orchestration for routing, shared knowledge and tools.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    O[\"&lt;b&gt;Main Agent (Orchestrator)&lt;/b&gt;&lt;br/&gt;Instructions + routing logic&lt;br/&gt;30 tools/topics/agents max\"]\n    O --&gt; A1[\"&lt;b&gt;Child: HR Agent&lt;/b&gt;&lt;br/&gt;Leave, benefits, payroll topics&lt;br/&gt;HR knowledge source\"]\n    O --&gt; A2[\"&lt;b&gt;Child: IT Agent&lt;/b&gt;&lt;br/&gt;Password reset, hardware request&lt;br/&gt;IT knowledge source\"]\n    O --&gt; A3[\"&lt;b&gt;Child: Finance Agent&lt;/b&gt;&lt;br/&gt;Expense reports, budgets&lt;br/&gt;Finance knowledge source\"]</code></pre> <p>All agents live in the same Copilot Studio solution. The main agent automatically routes to children based on their descriptions. No network hops \u2014 routing is in-process.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#implementation","title":"Implementation","text":"<p>Step 1: Design domain boundaries</p> <p>Split by user intent domain, not by technical capability:</p> Good Boundary (by domain) Bad Boundary (by technology) HR Agent \u2192 all HR topics Power Automate Agent \u2192 all flow-based topics IT Agent \u2192 all IT topics Knowledge Agent \u2192 all search topics Finance Agent \u2192 all finance topics Adaptive Card Agent \u2192 all card-based topics <p>Rule of thumb: If a user would describe their question as belonging to a department or function, that's a good agent boundary.</p> <p>Step 2: Create child agents with clear descriptions</p> <pre><code>kind: AgentDialog\nbeginDialog:\n  kind: OnToolSelected\n  id: main\n  description: &gt;\n    HR specialist handling questions about Paid Time Off (PTO), sick leave, \n    parental leave, benefits enrollment, payroll schedules, and HR policies.\n    Routes here when the user asks about any human resources topic.\n    Do NOT route here for IT support, finance, or general company questions.\n\nsettings:\n  instructions: |\n    # HR Specialist Agent\n\n    You are an HR policy expert. Answer questions about leave policies,\n    benefits, payroll, and HR procedures.\n\n    ## Knowledge Priority\n    1. Always check HR knowledge sources first\n    2. Cite specific policy documents and sections\n    3. If unsure, say \"I'd recommend contacting HR directly at hr@contoso.com\"\n\n    ## Tone\n    - Professional but approachable\n    - Empathetic for sensitive topics (leave, termination)\n    - Always include policy references\n\ninputType: {}\noutputType: {}\n</code></pre> <p>Step 3: Write differentiated descriptions</p> <p>The orchestrator routes based on description quality. Ambiguous descriptions cause misrouting:</p> <pre><code># BAD \u2014 overlapping descriptions\nHR Agent:      \"Handles employee questions\"\nIT Agent:      \"Handles employee questions about technology\"\nFinance Agent: \"Handles employee questions about money\"\n\n# GOOD \u2014 specific, with negative boundaries\nHR Agent:      \"Handles leave, benefits, payroll, onboarding. \n               Do NOT route here for IT tickets or expense reports.\"\nIT Agent:      \"Handles password resets, hardware requests, software access, \n               VPN issues. Do NOT route here for HR policies or finance.\"\nFinance Agent: \"Handles expense reports, budget queries, invoice status, \n               procurement. Do NOT route here for payroll (that's HR).\"\n</code></pre> <p>Step 4: Reference child agents in orchestrator instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Enterprise Assistant\ninstructions: |+\n  # Enterprise Assistant\n\n  You help employees with HR, IT, and Finance questions.\n\n  ## Routing\n  Route each query to the most appropriate specialist:\n  - /HRAgent for leave, benefits, payroll, HR policies\n  - /ITAgent for passwords, hardware, software, network issues\n  - /FinanceAgent for expenses, budgets, invoices, procurement\n\n  If the query spans multiple domains (\"I need to expense my new laptop\"),\n  route to the primary domain (Finance for expense, IT for laptop setup)\n  and mention the other: \"I've submitted the expense. For laptop setup, \n  you can ask me about that next.\"\n\n  ## When in doubt\n  Ask one clarification question rather than guessing the wrong agent.\n</code></pre> <p>Step 5: Configure behavior after child agent completion</p> <p>When a child agent finishes, the main agent can:</p> <ul> <li>Respond (default): The orchestrator synthesizes the child's output into a final response</li> <li>Don't respond: The child's response is sent directly to the user (less overhead, more direct)</li> </ul> <p>Set via the child agent's configuration on the Agents page.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 YAML components within one solution. Standard Copilot Studio authoring. Latency \ud83d\udfe2 No network hops. Fastest multi-agent pattern. Team Independence \ud83d\udd34 Single solution = single deployment. All teams share one ALM pipeline. Reusability \ud83d\udd34 Child agents can't be used by other main agents. Locked to this solution. Scalability \ud83d\udfe1 Works up to ~30 total tools/topics/agents. Beyond that, routing degrades. Per-Agent Configuration \ud83d\udd34 Children share the main agent's settings (model, general knowledge toggle)."},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#limitations","title":"Limitations","text":"<ul> <li>Single deployment bottleneck: Any change to any child agent requires redeploying the entire solution. Team A's urgent fix is blocked by Team B's untested change.</li> <li>No independent publishing: Child agents can't be deployed to channels independently. They only exist within the main agent.</li> <li>Shared settings: The main agent's model choice and general knowledge setting apply to all children. You can't use GPT-4o for the Finance agent and GPT-4o-mini for the FAQ agent.</li> <li>30-40 item ceiling: Microsoft's documented threshold. Past this, the orchestrator's selection quality degrades \u2014 it may call the wrong agent or miss the right one.</li> </ul>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#approach-b-connected-copilot-studio-agents-federated-pattern","title":"Approach B: Connected Copilot Studio Agents (Federated Pattern)","text":"<p>Summary: Build each domain agent as an independent Copilot Studio agent in the same environment. Connect them to a main orchestrator agent. Each agent has its own ALM lifecycle, settings, and can be published independently. Technique: Separate Copilot Studio agents, connected agent configuration, independent solutions, generative orchestration.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    O[\"&lt;b&gt;Main Orchestrator Agent&lt;/b&gt;&lt;br/&gt;Routing + general questions&lt;br/&gt;Published to Teams/Web/M365\"]\n    O --&gt;|\"connected\"| A1[\"&lt;b&gt;HR Agent&lt;/b&gt;&lt;br/&gt;(separate solution)&lt;br/&gt;Own knowledge, own settings&lt;br/&gt;Can also be published directly\"]\n    O --&gt;|\"connected\"| A2[\"&lt;b&gt;IT Agent&lt;/b&gt;&lt;br/&gt;(separate solution)&lt;br/&gt;Own knowledge, own settings&lt;br/&gt;Can also be published directly\"]\n    O --&gt;|\"connected\"| A3[\"&lt;b&gt;Analytics Agent&lt;/b&gt;&lt;br/&gt;(separate solution)&lt;br/&gt;Fabric Data Agent connection&lt;br/&gt;Team-managed\"]</code></pre> <p>Each connected agent is a full, independently deployable agent. The orchestrator discovers and routes to them, but they can also be published directly to channels for standalone use.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#implementation_1","title":"Implementation","text":"<p>Step 1: Create each domain agent as a separate Copilot Studio agent</p> <p>Each agent is its own solution with its own:</p> <ul> <li>Agent instructions (tailored to the domain)</li> <li>Knowledge sources (domain-specific documents)</li> <li>Tools and flows (domain-specific integrations)</li> <li>Settings (model choice, general knowledge toggle)</li> <li>Authentication configuration</li> </ul> <p>Step 2: Connect agents to the orchestrator</p> <ol> <li>In the orchestrator agent \u2192 Agents tab \u2192 + Add an agent</li> <li>Select Connect to a Copilot Studio agent</li> <li>Choose the agent from your environment</li> <li>Select the connection \u2192 Add and configure</li> </ol> <p>The connected agent appears on the orchestrator's Agents page with an Enabled toggle.</p> <p>Step 3: Write the orchestrator's routing instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Enterprise Hub\ninstructions: |+\n  # Enterprise Hub \u2014 Orchestrator\n\n  You are the front door for all employee questions. Route to the right\n  specialist agent based on the query domain.\n\n  ## Connected Agents\n  - **HR Agent**: Leave policies, benefits, payroll, onboarding, offboarding\n  - **IT Support Agent**: Passwords, hardware, software, VPN, network\n  - **Finance Agent**: Expenses, budgets, invoices, procurement, travel\n  - **Analytics Agent**: Data questions, metrics, reports, dashboards\n\n  ## Routing Rules\n  1. Analyze the user's query to determine the domain\n  2. Route to the matching specialist agent\n  3. If the query spans domains, route to the PRIMARY domain\n  4. For general questions (\"What time does the cafeteria open?\"), \n     answer directly from general knowledge\n\n  ## After Specialist Responds\n  If the specialist's response mentions a related domain \n  (\"Your expense was approved. You may also need IT to set up the laptop\"),\n  proactively ask: \"Would you like me to help with the IT setup too?\"\n</code></pre> <p>Step 4: Enable independent publishing (optional)</p> <p>Connected agents can be published to channels independently. This enables:</p> <ul> <li>Direct access: Users in the IT team access the IT Agent directly in their Teams channel</li> <li>Hub access: All users access the orchestrator, which routes to the IT Agent when needed</li> </ul> <p>Same agent, two access paths. No duplication.</p> <p>Step 5: Manage lifecycle independently</p> <p>Each team deploys their agent on their own schedule:</p> <pre><code>HR Team:      Updates HR Agent \u2192 Tests \u2192 Publishes \u2192 Orchestrator picks up changes\nIT Team:      Updates IT Agent \u2192 Tests \u2192 Publishes \u2192 Orchestrator picks up changes  \nOrchestrator: Only updates when routing logic or general instructions change\n</code></pre> <p>No cross-team deployment dependencies.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Multiple agents to create, connect, and configure. More setup. Latency \ud83d\udfe1 Each connected agent adds an orchestration hop (+1-3s). User may notice. Team Independence \ud83d\udfe2 Each agent is independently deployable. Teams manage their own lifecycle. Reusability \ud83d\udfe2 A connected agent can serve multiple main agents (with restrictions). Scalability \ud83d\udfe2 Each agent has its own 30-item budget. The orchestrator routes between N agents. Per-Agent Configuration \ud83d\udfe2 Each agent has its own model, knowledge, settings. Full isolation."},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#limitations_1","title":"Limitations","text":"<ul> <li>Orchestration hop latency: Each connected agent runs its own orchestration layer. A query routed from orchestrator \u2192 HR Agent incurs two orchestration cycles. For complex chains (orchestrator \u2192 HR Agent \u2192 benefits sub-agent), latency compounds.</li> <li>No circular connections: If Agent A connects to Agent B, Agent B cannot also connect to Agent A. Hub-and-spoke only \u2014 no mesh.</li> <li>Same environment required: Connected Copilot Studio agents must be in the same Power Platform environment as the orchestrator.</li> <li>Connection limit: While undocumented, practical testing shows routing quality degrades with more than 8-10 connected agents on a single orchestrator (same 30-40 item principle applies to agents).</li> <li><code>explanation_of_tool_call</code> message: In multi-agent setups where the parent has no topics/knowledge of its own, the platform may send an extra system-generated message after the child responds. This is a known platform behavior \u2014 design around it by giving the orchestrator at least basic general knowledge.</li> </ul>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#approach-c-external-agent-connections-a2a-foundry-fabric","title":"Approach C: External Agent Connections (A2A, Foundry, Fabric)","text":"<p>Summary: Connect agents built outside Copilot Studio \u2014 Foundry agents for AI-powered workflows, Fabric Data Agents for analytics, and any agent implementing the A2A protocol. Maximum reach, cross-platform composition. Technique: A2A protocol connections, Foundry agent connections, Fabric Data Agent connections (all preview).</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    O[\"&lt;b&gt;Copilot Studio Orchestrator&lt;/b&gt;\"]\n    O --&gt;|\"A2A protocol\"| E1[\"&lt;b&gt;Custom Python Agent&lt;/b&gt;&lt;br/&gt;(LangChain, AutoGen, etc.)&lt;br/&gt;Any A2A-compliant endpoint\"]\n    O --&gt;|\"Foundry connection\"| E2[\"&lt;b&gt;Azure AI Foundry Agent&lt;/b&gt;&lt;br/&gt;Custom AI workflows&lt;br/&gt;Azure-hosted\"]\n    O --&gt;|\"Fabric connection\"| E3[\"&lt;b&gt;Fabric Data Agent&lt;/b&gt;&lt;br/&gt;SQL/DAX/KQL analytics&lt;br/&gt;(see Gem 028)\"]\n    O --&gt;|\"M365 Agents SDK\"| E4[\"&lt;b&gt;SDK Agent&lt;/b&gt;&lt;br/&gt;Custom Bot Framework agent&lt;br/&gt;Teams-deployed\"]</code></pre> <p>This approach reaches beyond the Copilot Studio ecosystem. Each connection type serves a different scenario.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#implementation_2","title":"Implementation","text":"<p>Option 1: A2A Protocol Connection</p> <p>The Agent2Agent (A2A) protocol is an open standard. Any agent with a compliant endpoint can be connected:</p> <ol> <li>In Copilot Studio \u2192 Agents tab \u2192 + Add an agent</li> <li>Select Agent2Agent under \"Connect to an external agent\"</li> <li>Enter the agent's endpoint URL (not the agent card URL)</li> <li>Copilot Studio auto-populates name and description from the agent card at <code>/.well-known/agent.json</code></li> <li>If auto-population fails, manually enter a descriptive name and description (critical for routing)</li> <li>Select the authentication method (None, API Key, OAuth, etc.)</li> <li>Click Create \u2192 select connection \u2192 Add and configure</li> </ol> <pre><code>A2A Agent Card (/.well-known/agent.json):\n{\n  \"name\": \"Inventory Lookup Agent\",\n  \"description\": \"Checks real-time product inventory across warehouses. \n                   Ask about stock levels, availability, and reorder status.\",\n  \"endpoint\": \"https://inventory-agent.contoso.com/a2a\",\n  \"auth\": { \"type\": \"bearer\", \"tokenUrl\": \"...\" }\n}\n</code></pre> <p>When to use A2A:</p> <ul> <li>Your organization has agents built with LangChain, Semantic Kernel, AutoGen, or other AI frameworks</li> <li>You need to connect to a partner's agent (cross-organization composition)</li> <li>You're integrating with non-Microsoft AI platforms that support the A2A standard</li> </ul> <p>Option 2: Microsoft Foundry Agent Connection</p> <p>For agents built in Azure AI Foundry:</p> <ol> <li>In Copilot Studio \u2192 Agents tab \u2192 + Add an agent</li> <li>Select Microsoft Foundry under \"Connect to an external agent\"</li> <li>Authenticate with your Azure credentials</li> <li>Select the published Foundry agent from the list</li> <li>Add and configure</li> </ol> <p>When to use Foundry:</p> <ul> <li>Your data science team builds custom AI workflows in Azure AI Foundry</li> <li>You need agents with custom models (fine-tuned, domain-specific)</li> <li>The agent requires Azure-specific integrations (Cognitive Services, Document Intelligence)</li> </ul> <p>Option 3: Fabric Data Agent Connection</p> <p>Covered in detail in Gem 028. In brief:</p> <ol> <li>Create and publish a Data Agent in Microsoft Fabric</li> <li>In Copilot Studio \u2192 Agents tab \u2192 + Add an agent \u2192 Microsoft Fabric</li> <li>Select the published Fabric Data Agent</li> <li>Configure with a clear, routing-friendly description</li> </ol> <p>When to use Fabric:</p> <ul> <li>Users need to query structured data (warehouses, lakehouses, semantic models)</li> <li>Questions are ad-hoc (can't pre-build flows for every possible query)</li> <li>Data already lives in Microsoft Fabric</li> </ul> <p>Step: Write routing instructions for mixed agent types</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Enterprise Hub\ninstructions: |+\n  # Enterprise Hub with External Agents\n\n  ## Connected Agents\n\n  ### Internal (Copilot Studio)\n  - **HR Agent**: Leave, benefits, payroll \u2014 routes for any HR policy question\n  - **IT Agent**: Passwords, hardware, software \u2014 routes for technical support\n\n  ### External\n  - **Analytics Agent** (Fabric): Data questions about revenue, KPIs, metrics.\n    Route here when users ask for numbers, trends, comparisons, or reports.\n  - **Inventory Agent** (A2A): Real-time stock levels and warehouse availability.\n    Route here when users ask about product availability or inventory.\n\n  ## Routing Priority\n  1. If the question involves DATA or METRICS \u2192 Analytics Agent\n  2. If the question involves INVENTORY or STOCK \u2192 Inventory Agent\n  3. If the question involves HR policies \u2192 HR Agent\n  4. If the question involves IT support \u2192 IT Agent\n  5. General questions \u2192 Answer from knowledge sources\n\n  ## External Agent Caveats\n  - External agents may have higher latency (2-5 seconds). \n    Send a brief \"Looking into that...\" message before routing.\n  - If an external agent is unavailable, inform the user and suggest alternatives.\n</code></pre>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Connection setup is simple. Building the external agent is the hard part. Latency \ud83d\udd34 Network hop + external orchestration. 2-5 seconds per external call. Team Independence \ud83d\udfe2 Fully independent. Different platforms, teams, organizations. Reusability \ud83d\udfe2 External agents serve any consumer \u2014 not locked to Copilot Studio. Scalability \ud83d\udfe2 No shared item budget. Each external agent is self-contained. Cross-Platform \ud83d\udfe2 A2A connects to any compliant agent \u2014 LangChain, AutoGen, custom frameworks."},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#limitations_2","title":"Limitations","text":"<ul> <li>Preview status: Foundry, Fabric, M365 Agents SDK, and A2A connections are all in preview (February 2026). Expect breaking changes.</li> <li>Authentication complexity: Each external agent has its own auth model. Managing credentials across N external agents is a governance challenge.</li> <li>Latency stacking: Orchestrator (1-2s) + network hop (0.5-1s) + external orchestration (1-3s) = 3-6 seconds per external call. Users notice.</li> <li>No topic redirect for Fabric: Fabric Data Agents can't be called via <code>Redirect</code> nodes in topics. Only generative orchestration can route to them.</li> <li>No Fabric in M365 Copilot: Fabric Data Agent connections don't function when the main agent is deployed to M365 Copilot.</li> <li>No instruction references for Fabric: Fabric Data Agents can't be referenced with <code>/AgentName</code> in orchestrator instructions.</li> <li>Agent card dependency (A2A): If the A2A agent's <code>.well-known/agent.json</code> card is missing or malformed, auto-population fails and you must manually write the description. Bad descriptions = bad routing.</li> <li>Responsibility model: You are responsible for the security, data handling, and quality of connected external agents. Copilot Studio doesn't validate what external agents do.</li> </ul>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Child Agents Approach B: Connected CS Agents Approach C: External (A2A/Foundry/Fabric) Implementation Effort \ud83d\udfe2 Low (YAML in one solution) \ud83d\udfe1 Medium (separate agents + connections) \ud83d\udfe1 Medium (external agent + connection) Latency \ud83d\udfe2 Fastest (in-process) \ud83d\udfe1 +1-3s per hop \ud83d\udd34 +2-5s per external call Team Independence \ud83d\udd34 Single ALM pipeline \ud83d\udfe2 Independent deployment \ud83d\udfe2 Fully independent Reusability \ud83d\udd34 Locked to one main agent \ud83d\udfe2 Reusable across main agents \ud83d\udfe2 Reusable across platforms Per-Agent Settings \ud83d\udd34 Shared with parent \ud83d\udfe2 Independent model, knowledge, settings \ud83d\udfe2 Fully independent Cross-Platform \ud83d\udd34 Copilot Studio only \ud83d\udd34 Copilot Studio only \ud83d\udfe2 Any A2A-compliant agent Maturity \ud83d\udfe2 GA, stable \ud83d\udfe2 GA, stable \ud83d\udfe1 Preview (A2A, Foundry, Fabric) Best When... Small team, &lt; 30 items, simplicity Multiple teams, independent lifecycle Cross-platform, external AI, analytics"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#recommended-approach","title":"Recommended Approach","text":"<p>Start with Child Agents (A), evolve to Connected Agents (B) when you hit the ceiling, add External Agents (C) for cross-platform needs.</p> <pre><code>Phase 1: One agent with child agents\n  (&lt; 30 tools/topics/agents, single team)\n\nPhase 2: Split into connected agents  \n  (&gt; 30 items, OR multiple teams need independent deployment)\n\nPhase 3: Add external agents for specialized capabilities\n  (Fabric for analytics, Foundry for custom AI, A2A for partner agents)\n</code></pre> <p>The decision flowchart:</p> <pre><code>flowchart TB\n    A{\"Total tools + topics + agents &lt; 30?\"} --&gt;|YES| B{\"Single team manages everything?\"}\n    A --&gt;|NO| D[\"Split into Connected Agents (B)\"]\n    B --&gt;|YES| C[\"Child Agents (A) \u2705\"]\n    B --&gt;|NO| D\n    D --&gt; E{\"Need cross-platform agents?\"}\n    E --&gt;|NO| F[\"Connected CS Agents only (B) \u2705\"]\n    E --&gt;|YES| G{\"What type?\"}\n    G --&gt;|\"Analytics/data\"| H[\"Add Fabric Data Agent (C)\"]\n    G --&gt;|\"Custom AI models\"| I[\"Add Foundry Agent (C)\"]\n    G --&gt;|\"External/partner\"| J[\"Add A2A Agent (C)\"]</code></pre> <p>The hybrid pattern (recommended for production):</p> <p>Most enterprise solutions end up with a mix:</p> <ul> <li>Child agents for closely related domains within one team's ownership</li> <li>Connected Copilot Studio agents for domains owned by different teams</li> <li>One Fabric Data Agent for analytics questions (Gem 028)</li> <li>A2A connections if partner or cross-platform agents exist</li> </ul> <p>The orchestrator's job is to route \u2014 it should have minimal logic of its own. Keep the orchestrator thin: good descriptions on all connected agents, clear routing instructions, and general knowledge for FAQ-style queries that don't belong to any specialist.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Orchestration quality degrades past 30-40 choices. This is Microsoft's documented threshold. If your main agent's total count of tools + topics + child agents + connected agents exceeds ~30, the orchestrator may call the wrong agent or fail to differentiate between similar descriptions. Monitor routing accuracy (Gem 013) and split when quality drops.</p> <p>Warning</p> <p>Connected agents can't form circular connections. If Agent A connects to Agent B, Agent B cannot also connect to Agent A. Multi-agent topologies are hub-and-spoke only \u2014 no mesh or peer-to-peer. Design your architecture with a clear orchestrator at the top.</p> <p>Warning</p> <p>Fabric Data Agents don't work in M365 Copilot. If your main agent is deployed to M365 Copilot, connected Fabric Data Agents won't function. Plan alternative data access for M365 Copilot users (e.g., Power Automate flow with pre-built queries as fallback).</p> <p>Warning</p> <p>A2A, Foundry, and Fabric connections are in preview. Preview features may have breaking changes, limited support, and aren't recommended for production-critical workloads. Child agents and connected Copilot Studio agents are GA and stable.</p> <p>Note</p> <p>Write \"Do NOT route here for...\" in every agent description. Negative boundaries are as important as positive ones. Without them, the orchestrator may route \"payroll\" to both the HR Agent and the Finance Agent. Explicit exclusions eliminate ambiguity.</p> <p>Note</p> <p>The orchestrator should have its own knowledge source. If the orchestrator has zero topics and zero knowledge, it sends every query to a child/connected agent. This can produce an extra <code>explanation_of_tool_call</code> message. Give the orchestrator basic general knowledge (FAQ, company info) so it can handle simple queries directly.</p> <p>Note</p> <p>Test routing with ambiguous queries (Gem 013). The highest-value test cases for multi-agent are cross-domain queries: \"I need to expense my new laptop\" (Finance or IT?), \"My paycheck seems wrong\" (HR or Finance?). Include these in your test suite.</p>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 002: Persona-Adaptive Agent Instructions \u2014 Child agents per persona is the simplest multi-agent use case. This Gem generalizes beyond personas to full domain composition.</li> <li>Gem 013: Testing Strategies for Multi-Agent Architectures \u2014 Testing routing accuracy across connected agents is covered there. This Gem focuses on when and how to split.</li> <li>Gem 021: Conversation Branching and Disambiguation \u2014 Disambiguation within a single agent. This Gem addresses disambiguation between agents via description quality.</li> <li>Gem 028: Grounding Agents in Enterprise Analytics Data \u2014 Fabric Data Agent connection is one specific case of Approach C. That Gem covers the data grounding depth; this Gem covers the composition pattern.</li> <li>Gem 023: MCP Connector Integration Patterns \u2014 MCP connects to external tools; connected agents connect to external agents. Different integration layers.</li> </ul>"},{"location":"gems/GEM-024-multi-agent-composition-and-connected-agent-patterns/#references","title":"References","text":"<ul> <li>Microsoft Learn: Add other agents overview</li> <li>Microsoft Learn: Create child agents</li> <li>Microsoft Learn: Connect to other Copilot Studio agents</li> <li>Microsoft Learn: Connect A2A protocol agents</li> <li>Microsoft Learn: Connect Foundry agents</li> <li>Microsoft Learn: Connect Fabric Data Agents</li> <li>Microsoft Learn: Generative orchestration best practices</li> <li>Agent2Agent (A2A) Protocol specification</li> </ul> <p>Gem 024 | Author: S\u00e9bastien Brochet | Created: 2026-02-19 | Last Validated: 2026-02-19 | Platform Version: current (A2A, Foundry, Fabric connections in preview)</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/","title":"Gem 025: Custom Canvas and Embedded Agent UX Patterns","text":"<p>Your agent works great in Teams. Now put it on your website \u2014 with your brand, your layout, your rules.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#classification","title":"Classification","text":"Attribute Value Category UX Complexity \u2b50\u2b50 to \u2b50\u2b50\u2b50\u2b50 (depends on customization depth) Channels Web Chat (custom website deployment) Prerequisite Gems None"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#the-problem","title":"The Problem","text":"<p>Copilot Studio agents deploy to Teams and M365 Copilot with one click. But embedding the agent on a custom website \u2014 a customer portal, an intranet landing page, a product documentation site \u2014 requires decisions that aren't covered anywhere:</p> <ul> <li>Default embed looks generic: The out-of-the-box embed is a Microsoft-branded chat bubble. For a customer-facing product, this screams \"third-party widget\" instead of \"our support agent.\"</li> <li>Limited layout control: The default widget is a fixed-position chat popup. What if you want a full-page chat experience? A sidebar panel? An inline component within existing page content?</li> <li>No UX integration: Want to show user account info alongside the chat? Display search results in your page layout instead of inside the chat bubble? Impossible with the default embed.</li> <li>Authentication handling: On a logged-in portal, users shouldn't re-authenticate with the agent. The embed should inherit the portal's authentication context.</li> <li>Analytics integration: You want to track chat engagement alongside your existing web analytics (Google Analytics, Application Insights for the website). The default embed doesn't expose events.</li> </ul> <p>The spectrum of options ranges from \"paste this code snippet\" (5 minutes, zero customization) to \"build a complete custom chat UI\" (days of frontend development, total control). The right choice depends on your UX requirements, development capacity, and deployment timeline.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent embedded in your website that feels native:</p> <ul> <li>[ ] Brand consistency: Colors, fonts, and layout match your website's design system</li> <li>[ ] Flexible placement: Chat widget, sidebar, full-page, or inline \u2014 your choice</li> <li>[ ] Auth integration: Users don't re-authenticate if already logged into the portal</li> <li>[ ] UX extension: Ability to render agent responses in custom UI components (not just a chat bubble)</li> <li>[ ] Analytics hooks: Chat events (start, message, escalation) fire into your web analytics</li> </ul>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#approach-a-default-embed-code-copy-paste","title":"Approach A: Default Embed Code (Copy-Paste)","text":"<p>Summary: Use the embed code provided by Copilot Studio. Paste it into your website's HTML. Done. Technique: <code>&lt;iframe&gt;</code> or Web Chat script tag from Copilot Studio's publication settings.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"Copilot Studio \u2192 Channels \u2192&lt;br/&gt;Custom Website \u2192 Copy embed code\"] --&gt; B[\"Paste into your website's HTML\"]\n    B --&gt; C[\"Chat widget appears at bottom-right corner\"]</code></pre>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#implementation","title":"Implementation","text":"<p>Step 1: Get the embed code</p> <p>In Copilot Studio:</p> <ol> <li>Go to Settings \u2192 Channels \u2192 Custom website</li> <li>Copy the embed code snippet</li> </ol> <p>The code looks approximately like:</p> <pre><code>&lt;script src=\"https://cdn.botframework.com/botruntime/webchat/latest/webchat.js\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  window.WebChat.render({\n    botURL: \"https://YOUR_BOT_URL\",\n    directLineToken: \"YOUR_TOKEN\"\n  });\n&lt;/script&gt;\n</code></pre> <p>Or the iframe variant:</p> <pre><code>&lt;iframe\n  src=\"https://copilotstudio.microsoft.com/environments/YOUR_ENV/bots/YOUR_BOT/webchat?__version__=2\"\n  frameborder=\"0\"\n  style=\"width: 100%; height: 600px;\"&gt;\n&lt;/iframe&gt;\n</code></pre> <p>Step 2: Add to your website</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Contoso Support&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1&gt;Welcome to Contoso Support&lt;/h1&gt;\n  &lt;p&gt;Our AI assistant is ready to help.&lt;/p&gt;\n\n  &lt;!-- Paste embed code here --&gt;\n  &lt;iframe\n    src=\"https://copilotstudio.microsoft.com/environments/YOUR_ENV/bots/YOUR_BOT/webchat\"\n    frameborder=\"0\"\n    style=\"width: 400px; height: 600px; position: fixed; bottom: 20px; right: 20px; border: 1px solid #ccc; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\"&gt;\n  &lt;/iframe&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Step 3: Minimal styling</p> <p>The iframe can be styled with CSS for basic positioning:</p> <pre><code>/* Chat widget \u2014 bottom-right corner */\n.copilot-widget {\n  position: fixed;\n  bottom: 20px;\n  right: 20px;\n  width: 400px;\n  height: 600px;\n  border: 1px solid #e0e0e0;\n  border-radius: 12px;\n  box-shadow: 0 4px 16px rgba(0,0,0,0.12);\n  overflow: hidden;\n  z-index: 1000;\n}\n\n/* Full-page mode */\n.copilot-fullpage {\n  width: 100%;\n  height: calc(100vh - 64px); /* Below header */\n  border: none;\n  border-radius: 0;\n}\n</code></pre>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 5 minutes. Copy, paste, done. Maintainability \ud83d\udfe2 Zero maintenance. Updates come from Copilot Studio automatically. Brand Customization \ud83d\udd34 Microsoft branding. Can't change colors, fonts, or chat bubble design. Layout Flexibility \ud83d\udfe1 Fixed position, adjustable via CSS on iframe. No inline or sidebar integration. Auth Integration \ud83d\udd34 Separate authentication context. Users may need to re-authenticate. Analytics Hooks \ud83d\udd34 No events exposed. Can't track chat interactions in your web analytics."},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#limitations","title":"Limitations","text":"<ul> <li>Zero customization inside the iframe: You can position and size the iframe, but everything inside it (colors, fonts, avatar, greeting) is controlled by Copilot Studio's default styling.</li> <li>Cross-origin restrictions: The iframe's content is on Microsoft's domain. You can't inject CSS, read conversation data, or listen to events from your host page.</li> <li>Authentication isolation: The iframe has its own auth context. If your portal uses Entra ID, the user may need to authenticate separately inside the iframe.</li> <li>Mobile UX: The fixed-position iframe may conflict with mobile layouts. Responsive design requires manual CSS media queries on the host page.</li> <li>No deep linking: You can't pre-populate the first message or pass context from the host page into the chat (e.g., the product the user is viewing).</li> </ul>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#approach-b-bot-framework-web-chat-component","title":"Approach B: Bot Framework Web Chat Component","text":"<p>Summary: Use the open-source Bot Framework Web Chat React component. Full control over styling, behavior, and integration \u2014 while still using Copilot Studio as the backend. Technique: <code>botframework-webchat</code> npm package, Direct Line token, React component with style customization, event middleware.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Your Website&lt;/b&gt; (React/JS)\"] --&gt; B[\"&lt;b&gt;Bot Framework Web Chat Component&lt;/b&gt;\"]\n    B --&gt; B1[\"Connects to Copilot Studio via Direct Line\"]\n    B --&gt; B2[\"Custom CSS theme (your brand colors/fonts)\"]\n    B --&gt; B3[\"Event middleware (analytics hooks)\"]\n    B --&gt; B4[\"Activity middleware (custom rendering)\"]\n    B --&gt; C[\"&lt;b&gt;Copilot Studio Agent&lt;/b&gt;&lt;br/&gt;(backend \u2014 unchanged)\"]</code></pre> <p>The Web Chat component is the same rendering engine that Copilot Studio uses internally, but you control every aspect of its appearance and behavior.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#implementation_1","title":"Implementation","text":"<p>Step 1: Set up Direct Line connection</p> <p>Obtain a Direct Line secret from your Copilot Studio agent's channel configuration. Exchange it for a token:</p> <pre><code>// Token exchange (do this server-side for security!)\nasync function getDirectLineToken() {\n  const response = await fetch('https://YOUR_TOKEN_ENDPOINT/api/token', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' }\n  });\n  const { token } = await response.json();\n  return token;\n}\n</code></pre> <p>Step 2: Embed Web Chat with custom styling</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Contoso Support&lt;/title&gt;\n  &lt;script crossorigin=\"anonymous\" src=\"https://cdn.botframework.com/botruntime/webchat/latest/webchat-es5.js\"&gt;&lt;/script&gt;\n  &lt;style&gt;\n    #webchat-container {\n      position: fixed;\n      bottom: 20px;\n      right: 20px;\n      width: 420px;\n      height: 640px;\n      border-radius: 16px;\n      overflow: hidden;\n      box-shadow: 0 8px 32px rgba(0,0,0,0.18);\n    }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;div id=\"webchat-container\"&gt;&lt;/div&gt;\n\n  &lt;script&gt;\n    (async function () {\n      const token = await getDirectLineToken();\n\n      const styleOptions = {\n        // Brand colors\n        accent: '#0078D4',                    // Your brand primary color\n        backgroundColor: '#FFFFFF',\n\n        // Chat bubble styling\n        bubbleBackground: '#F3F2F1',          // Bot message background\n        bubbleFromUserBackground: '#0078D4',  // User message background\n        bubbleFromUserTextColor: '#FFFFFF',    // User message text\n        bubbleBorderRadius: 12,\n\n        // Fonts\n        primaryFont: \"'Segoe UI', -apple-system, sans-serif\",\n\n        // Avatar\n        botAvatarImage: '/assets/agent-avatar.png',\n        botAvatarInitials: 'CA',              // Contoso Assistant\n        userAvatarInitials: 'You',\n\n        // Send box\n        sendBoxBackground: '#FFFFFF',\n        sendBoxTextColor: '#323130',\n        sendBoxPlaceholderColor: '#A19F9D',\n        hideSendBox: false,\n\n        // Sizing\n        bubbleMaxWidth: 360,\n        rootWidth: '100%',\n        rootHeight: '100%',\n\n        // Suggested actions (quick replies)\n        suggestedActionLayout: 'stacked',\n        suggestedActionBackground: '#FFFFFF',\n        suggestedActionBorderColor: '#0078D4',\n        suggestedActionTextColor: '#0078D4'\n      };\n\n      window.WebChat.renderWebChat(\n        {\n          directLine: window.WebChat.createDirectLine({ token }),\n          styleOptions,\n          locale: 'en-US',\n\n          // Custom greeting\n          overrideLocalizedStrings: {\n            TEXT_INPUT_PLACEHOLDER: 'Ask Contoso Assistant anything...'\n          }\n        },\n        document.getElementById('webchat-container')\n      );\n    })();\n  &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Step 3: Add event middleware for analytics</p> <pre><code>const store = window.WebChat.createStore({}, ({ dispatch }) =&gt; next =&gt; action =&gt; {\n  // Track conversation start\n  if (action.type === 'DIRECT_LINE/CONNECT_FULFILLED') {\n    gtag('event', 'agent_conversation_start', {\n      event_category: 'Copilot Agent',\n      event_label: 'Web Chat'\n    });\n  }\n\n  // Track user messages\n  if (action.type === 'DIRECT_LINE/POST_ACTIVITY') {\n    gtag('event', 'agent_user_message', {\n      event_category: 'Copilot Agent',\n      event_label: action.payload.activity.text?.substring(0, 50)\n    });\n  }\n\n  // Track bot responses\n  if (action.type === 'DIRECT_LINE/INCOMING_ACTIVITY') {\n    const activity = action.payload.activity;\n    if (activity.from.role === 'bot' &amp;&amp; activity.type === 'message') {\n      gtag('event', 'agent_bot_response', {\n        event_category: 'Copilot Agent'\n      });\n    }\n  }\n\n  return next(action);\n});\n\n// Pass store to renderWebChat\nwindow.WebChat.renderWebChat(\n  {\n    directLine: window.WebChat.createDirectLine({ token }),\n    store,\n    styleOptions\n  },\n  document.getElementById('webchat-container')\n);\n</code></pre> <p>Step 4: Pre-populate context from the host page</p> <pre><code>// Send context to the agent when chat starts\nstore.dispatch({\n  type: 'WEB_CHAT/SEND_EVENT',\n  payload: {\n    name: 'pageContext',\n    value: {\n      currentPage: window.location.pathname,\n      productId: document.querySelector('[data-product-id]')?.dataset.productId,\n      userTier: 'Premium'  // From your portal's auth context\n    }\n  }\n});\n</code></pre> <p>Step 5: Toggle chat widget visibility</p> <pre><code>&lt;button id=\"chat-toggle\" onclick=\"toggleChat()\"&gt;\n  \ud83d\udcac Chat with Support\n&lt;/button&gt;\n\n&lt;script&gt;\n  function toggleChat() {\n    const container = document.getElementById('webchat-container');\n    container.style.display = container.style.display === 'none' ? 'block' : 'none';\n  }\n&lt;/script&gt;\n</code></pre>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires JavaScript/React knowledge. 2-4 hours for basic setup. Maintainability \ud83d\udfe2 Web Chat component updates via CDN. Your customizations are in your code. Brand Customization \ud83d\udfe2 Full control: colors, fonts, avatars, bubble shapes, animations. Layout Flexibility \ud83d\udfe2 Widget, sidebar, fullpage, inline \u2014 any CSS layout works. Auth Integration \ud83d\udfe1 Token exchange can include user identity. Requires server-side token endpoint. Analytics Hooks \ud83d\udfe2 Store middleware captures all events. Feed to any analytics platform."},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#limitations_1","title":"Limitations","text":"<ul> <li>Frontend development required: You need JavaScript/React skills. Not a low-code solution.</li> <li>Token management: Direct Line tokens expire. You need a server-side token exchange endpoint to avoid exposing secrets in client-side code.</li> <li>Web Chat version management: The CDN version updates automatically. Test after major Web Chat releases to ensure your customizations still work.</li> <li>Adaptive Card rendering: Web Chat supports Adaptive Card schema 1.6 (higher than Teams 1.5), but some advanced features may render differently than in Teams.</li> <li>No SSO by default: Passing the portal user's auth context to the agent requires additional configuration (token exchange with user claims).</li> </ul>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#approach-c-fully-custom-ui-with-direct-line-api","title":"Approach C: Fully Custom UI with Direct Line API","text":"<p>Summary: Build a completely custom chat interface \u2014 your own React/Angular/Blazor component that communicates with the agent via the Bot Framework Direct Line REST API. Technique: Direct Line REST API for conversation management, custom UI components for message rendering, custom logic for typing indicators, cards, and attachments.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"&lt;b&gt;Your Custom UI&lt;/b&gt;&lt;br/&gt;(React/Angular/Blazor)\"] --&gt; B[\"POST /conversations&lt;br/&gt;\u2192 Start conversation\"]\n    A --&gt; C[\"POST /conversations/{id}/activities&lt;br/&gt;\u2192 Send message\"]\n    A --&gt; D[\"GET /conversations/{id}/activities&lt;br/&gt;\u2192 Receive messages (polling or WebSocket)\"]\n    A --&gt; E[\"&lt;b&gt;Direct Line API&lt;/b&gt; \u2192 &lt;b&gt;Copilot Studio Agent&lt;/b&gt;\"]</code></pre> <p>You build everything: the message list, the input box, the send button, the typing indicator, the Adaptive Card renderer, the file upload handler. The Direct Line API is just a message transport layer.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#implementation_2","title":"Implementation","text":"<p>Step 1: Start a conversation</p> <pre><code>class AgentChat {\n  constructor(tokenEndpoint) {\n    this.tokenEndpoint = tokenEndpoint;\n    this.conversationId = null;\n    this.watermark = null;\n  }\n\n  async startConversation() {\n    const { token } = await fetch(this.tokenEndpoint).then(r =&gt; r.json());\n\n    const response = await fetch('https://directline.botframework.com/v3/directline/conversations', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${token}`,\n        'Content-Type': 'application/json'\n      }\n    });\n\n    const { conversationId, streamUrl } = await response.json();\n    this.conversationId = conversationId;\n    this.token = token;\n\n    // Start polling or WebSocket for responses\n    this.startListening(streamUrl);\n  }\n\n  async sendMessage(text) {\n    await fetch(\n      `https://directline.botframework.com/v3/directline/conversations/${this.conversationId}/activities`,\n      {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${this.token}`,\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          type: 'message',\n          from: { id: 'user', name: 'Portal User' },\n          text: text\n        })\n      }\n    );\n  }\n\n  startListening(streamUrl) {\n    // Option 1: WebSocket (real-time)\n    const ws = new WebSocket(streamUrl);\n    ws.onmessage = (event) =&gt; {\n      const data = JSON.parse(event.data);\n      data.activities?.forEach(activity =&gt; {\n        if (activity.from.role === 'bot') {\n          this.onBotMessage(activity);\n        }\n      });\n    };\n  }\n\n  onBotMessage(activity) {\n    // Render in your custom UI\n    const chatContainer = document.getElementById('chat-messages');\n\n    if (activity.type === 'message') {\n      const messageEl = document.createElement('div');\n      messageEl.className = 'bot-message';\n      messageEl.innerHTML = this.renderMarkdown(activity.text);\n      chatContainer.appendChild(messageEl);\n    }\n\n    if (activity.attachments) {\n      activity.attachments.forEach(attachment =&gt; {\n        if (attachment.contentType === 'application/vnd.microsoft.card.adaptive') {\n          this.renderAdaptiveCard(attachment.content, chatContainer);\n        }\n      });\n    }\n\n    chatContainer.scrollTop = chatContainer.scrollHeight;\n  }\n}\n</code></pre> <p>Step 2: Build the custom UI</p> <pre><code>&lt;div id=\"agent-chat\" class=\"chat-panel\"&gt;\n  &lt;div class=\"chat-header\"&gt;\n    &lt;img src=\"/assets/agent-avatar.png\" alt=\"Agent\" class=\"avatar\" /&gt;\n    &lt;span class=\"agent-name\"&gt;Contoso Assistant&lt;/span&gt;\n    &lt;span class=\"status-indicator online\"&gt;Online&lt;/span&gt;\n  &lt;/div&gt;\n\n  &lt;div id=\"chat-messages\" class=\"chat-messages\"&gt;\n    &lt;!-- Messages rendered here by JavaScript --&gt;\n  &lt;/div&gt;\n\n  &lt;div class=\"chat-input\"&gt;\n    &lt;input type=\"text\" id=\"user-input\" placeholder=\"Type a message...\" \n           onkeydown=\"if(event.key==='Enter') sendMessage()\" /&gt;\n    &lt;button onclick=\"sendMessage()\"&gt;Send&lt;/button&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;style&gt;\n  .chat-panel {\n    display: flex;\n    flex-direction: column;\n    height: 100%;\n    font-family: 'Segoe UI', sans-serif;\n  }\n\n  .chat-header {\n    display: flex;\n    align-items: center;\n    padding: 16px;\n    background: #0078D4;\n    color: white;\n    gap: 12px;\n  }\n\n  .chat-messages {\n    flex: 1;\n    overflow-y: auto;\n    padding: 16px;\n  }\n\n  .bot-message {\n    background: #F3F2F1;\n    border-radius: 12px;\n    padding: 12px 16px;\n    margin-bottom: 8px;\n    max-width: 80%;\n  }\n\n  .user-message {\n    background: #0078D4;\n    color: white;\n    border-radius: 12px;\n    padding: 12px 16px;\n    margin-bottom: 8px;\n    max-width: 80%;\n    margin-left: auto;\n  }\n\n  .chat-input {\n    display: flex;\n    padding: 12px;\n    border-top: 1px solid #E0E0E0;\n    gap: 8px;\n  }\n\n  .chat-input input {\n    flex: 1;\n    padding: 10px 16px;\n    border: 1px solid #E0E0E0;\n    border-radius: 20px;\n    outline: none;\n  }\n&lt;/style&gt;\n</code></pre> <p>Step 3: Adaptive Card rendering</p> <pre><code>// Use the adaptivecards npm package for rendering\nimport * as AdaptiveCards from 'adaptivecards';\n\nrenderAdaptiveCard(cardPayload, container) {\n  const adaptiveCard = new AdaptiveCards.AdaptiveCard();\n  adaptiveCard.hostConfig = new AdaptiveCards.HostConfig({\n    // Match your site's design system\n    fontFamily: \"'Segoe UI', sans-serif\",\n    containerStyles: {\n      default: { backgroundColor: '#FFFFFF' }\n    }\n  });\n\n  adaptiveCard.parse(cardPayload);\n\n  adaptiveCard.onExecuteAction = (action) =&gt; {\n    if (action instanceof AdaptiveCards.SubmitAction) {\n      // Send card submission back to the agent\n      this.sendMessage(JSON.stringify(action.data));\n    }\n  };\n\n  const renderedCard = adaptiveCard.render();\n  container.appendChild(renderedCard);\n}\n</code></pre> <p>Step 4: Pass portal authentication context</p> <pre><code>async startConversation() {\n  // Get portal user's auth token\n  const portalToken = getPortalUserToken(); // Your auth system\n\n  // Start conversation with user context\n  const response = await fetch(\n    `https://directline.botframework.com/v3/directline/conversations`,\n    {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${this.directLineToken}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        user: {\n          id: portalUser.id,\n          name: portalUser.displayName,\n          // Custom properties available to the agent\n          properties: {\n            email: portalUser.email,\n            accountTier: portalUser.tier,\n            portalToken: portalToken\n          }\n        }\n      })\n    }\n  );\n}\n</code></pre>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 Significant frontend development. 2-5 days for a polished implementation. Maintainability \ud83d\udfe1 You own the entire UI. Direct Line API is stable, but Adaptive Card rendering and edge cases require ongoing maintenance. Brand Customization \ud83d\udfe2 Complete control. Every pixel, every animation, every interaction is yours. Layout Flexibility \ud83d\udfe2 Unlimited. Full-page, sidebar, modal, embedded in existing components \u2014 anything your framework supports. Auth Integration \ud83d\udfe2 Full control. Pass portal user identity directly to the agent. Analytics Hooks \ud83d\udfe2 You own the code. Fire analytics events at any point."},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#limitations_2","title":"Limitations","text":"<ul> <li>Significant development effort: Building a production-quality chat UI is not trivial. Typing indicators, message grouping, scroll behavior, mobile responsiveness, accessibility, error states \u2014 each requires thought and code.</li> <li>Adaptive Card rendering: You must handle Adaptive Card rendering yourself. The <code>adaptivecards</code> npm package helps, but styling cards to match your design system requires configuration.</li> <li>WebSocket management: Maintaining the WebSocket connection (reconnection, token refresh, network errors) adds complexity.</li> <li>Accessibility: The Bot Framework Web Chat component (Approach B) is WCAG 2.0 compliant out of the box. A custom UI must achieve accessibility compliance from scratch.</li> <li>Feature parity risk: New Copilot Studio features (new card types, new message formats) may not render correctly in your custom UI until you add support.</li> </ul>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Default Embed Approach B: Web Chat Component Approach C: Fully Custom Implementation Time \ud83d\udfe2 5 minutes \ud83d\udfe1 2-4 hours \ud83d\udd34 2-5 days Brand Customization \ud83d\udd34 None \ud83d\udfe2 Full (CSS + config) \ud83d\udfe2 Total (pixel-level) Layout Options \ud83d\udfe1 Fixed widget \ud83d\udfe2 Any CSS layout \ud83d\udfe2 Unlimited Auth Integration \ud83d\udd34 Separate context \ud83d\udfe1 Token exchange \ud83d\udfe2 Native integration Analytics \ud83d\udd34 None \ud83d\udfe2 Store middleware \ud83d\udfe2 Custom events Adaptive Cards \ud83d\udfe2 Automatic \ud83d\udfe2 Automatic \ud83d\udfe1 Manual rendering Accessibility \ud83d\udfe2 Built-in \ud83d\udfe2 Built-in (WCAG 2.0) \ud83d\udd34 Must build yourself Maintenance \ud83d\udfe2 Zero \ud83d\udfe2 Low (CDN updates) \ud83d\udfe1 Ongoing (your code) Best When... Prototype, internal tools Customer-facing with branding needs Deeply integrated product experience"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#recommended-approach","title":"Recommended Approach","text":"<p>For internal tools and prototypes: Approach A (Default Embed) \u2014 paste the code, ship it. The default experience is acceptable for employee-facing tools where branding doesn't matter.</p> <p>For customer-facing websites: Approach B (Web Chat Component) \u2014 the best balance. Full brand customization via <code>styleOptions</code>, analytics hooks via store middleware, and the rendering engine handles all the hard parts (Adaptive Cards, typing indicators, accessibility). 2-4 hours to production-ready.</p> <p>For product integration: Approach C (Fully Custom) \u2014 when the agent is a core feature of your product (not a support widget), and you need the chat to feel like a native part of your application. Worth the investment when the chat UI must integrate with existing product components (e.g., inline product recommendations, embedded data tables, custom file viewers).</p> <p>The evolution path:</p> <pre><code>Validate concept   \u2192  Approach A (5 min, prove value)\nLaunch to customers \u2192  Approach B (hours, branded, professional)\nIntegrate deeply    \u2192  Approach C (days, fully native)\n</code></pre>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Never expose your Direct Line secret in client-side code. The Direct Line secret can generate unlimited tokens. Always exchange it for a short-lived token via a server-side endpoint. Exposing the secret lets anyone impersonate your bot.</p> <p>Warning</p> <p>Web Chat CDN versions can break customizations. The <code>latest</code> CDN URL auto-updates. If a Web Chat release changes the HTML structure or class names, your CSS customizations may break. Consider pinning to a specific version: <code>webchat-4.x.x.js</code>.</p> <p>Warning</p> <p>Adaptive Card submit actions work differently in custom UIs. In Approach C, <code>Action.Submit</code> data arrives as a raw JSON string in the Direct Line activity. You must parse it and send it back to the agent as a message or event. The Web Chat component (Approach B) handles this automatically.</p> <p>Note</p> <p>The Web Chat component is open-source. Full source at github.com/microsoft/BotFramework-WebChat. Over 100 style customization options documented. Check the <code>styleOptions</code> reference for the complete list before building a custom UI from scratch.</p> <p>Note</p> <p>You can pass page context to the agent. Both Approach B (store dispatch) and Approach C (activity properties) support sending context from the host page to the agent \u2014 product ID, current page URL, user tier. The agent can use this for personalized responses without asking.</p>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Cards render differently in Web Chat vs Teams. Test your forms in the target embed.</li> <li>Gem 007: Role-Based Feature Gating \u2014 Portal authentication context can determine the user's role for the agent.</li> <li>Gem 016: Conversation Analytics \u2014 Web Chat store middleware enables custom analytics events alongside built-in platform analytics.</li> <li>Gem 014: Proactive Agent Messages \u2014 Proactive messages in custom Web Chat require WebSocket connection maintenance.</li> </ul>"},{"location":"gems/GEM-025-custom-canvas-and-embedded-agent-ux-patterns/#references","title":"References","text":"<ul> <li>Bot Framework Web Chat GitHub</li> <li>Web Chat Style Options Reference</li> <li>Direct Line API Reference</li> <li>Adaptive Cards JavaScript SDK</li> <li>Microsoft Learn: Publish agent to custom website</li> </ul> <p>Gem 025 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/","title":"Gem 026: Azure AI Search Advanced Integration","text":"<p>When SharePoint knowledge isn't enough \u2014 bring enterprise-scale search with vector indexes, semantic ranking, and custom schemas.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#classification","title":"Classification","text":"Attribute Value Category Performance Complexity \u2b50\u2b50\u2b50 to \u2b50\u2b50\u2b50\u2b50 (depends on index sophistication) Channels All Prerequisite Gems Gem 008 (knowledge source optimization \u2014 the foundational knowledge Gem)"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#the-problem","title":"The Problem","text":"<p>Gem 008 covers optimizing built-in knowledge sources \u2014 SharePoint sites, uploaded files, public websites. These work well for small-to-medium document collections (hundreds of files). But enterprise agents face scenarios where built-in sources hit their limits.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#when-to-use-azure-ai-search-vs-sharepoint-native-decision-guide","title":"When to Use Azure AI Search vs SharePoint Native \u2014 Decision Guide","text":"<p>Before diving into Azure AI Search approaches, understand whether you actually need it. SharePoint native knowledge is simpler and sufficient for many agents.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#how-each-works-internally","title":"How Each Works Internally","text":"Aspect SharePoint Native Knowledge Azure AI Search Knowledge Indexing Platform-managed \u2014 Copilot Studio ingests via Dataverse, chunks files, creates vector embeddings automatically You build the index externally \u2014 choose embedding model, chunking strategy, schema, and ranking profile Embedding model Platform-managed (you don't choose) You choose (text-embedding-ada-002, text-embedding-3-small, etc.) Chunking Platform-managed (no control over chunk size or overlap) You control: chunk size, overlap, boundaries (by paragraph, page, heading) Semantic ranking Built-in but opaque \u2014 no configuration Explicit semantic configuration \u2014 you choose which fields are title/content/keywords Vector search Automatic vector embeddings via Dataverse Configurable: hybrid (vector + keyword), pure vector, or keyword-only Metadata/filtering None \u2014 no field-level filtering available Full OData filters on custom fields (department, date, type, author, etc.) Index refresh Automatic scheduled sync (not manually triggerable) You control: push API, indexers on schedule, blob change detection Scale Max 500 knowledge objects per agent. Files \u22647 MB without M365 Copilot license. Up to 15 SharePoint lists / 2,048 rows per list Millions of documents. No practical file count limit. Full enterprise scale Permissions Live checks against SharePoint \u2014 user sees only what they can access Depends on auth type: user-delegated inherits Azure RBAC; API key gives full access Citations Automatic (links back to SharePoint file) Requires URL field in index (<code>metadata_storage_path</code> or equivalent)"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#the-decision-flow","title":"The Decision Flow","text":"<pre><code>flowchart TB\n    A{\"Is your content already in&lt;br/&gt;SharePoint and &lt; 500 files?\"} --&gt;|YES| B{\"Are you satisfied with search quality&lt;br/&gt;(after GEM-008 optimization)?\"}\n    A --&gt;|NO| F{\"Where IS the content?\"}\n    B --&gt;|YES| C[\"Use SharePoint Native \u2705&lt;br/&gt;(simplest path, done)\"]\n    B --&gt;|NO| D{\"Is the problem chunking,&lt;br/&gt;filtering, or scale?\"}\n    D --&gt;|\"Chunking/quality\"| E1[\"Azure AI Search&lt;br/&gt;(you control embeddings + chunks)\"]\n    D --&gt;|\"Filtering\"| E2[\"Azure AI Search&lt;br/&gt;(OData filters on custom fields)\"]\n    F --&gt;|\"Azure Blob / SQL / Cosmos DB\"| G1[\"Azure AI Search&lt;br/&gt;(indexers connect natively)\"]\n    F --&gt;|\"Multiple sources &gt; 500 files\"| G2[\"Azure AI Search&lt;br/&gt;(scales beyond limits)\"]\n    F --&gt;|\"Custom data sources / APIs\"| G3[\"Azure AI Search&lt;br/&gt;(custom indexing pipeline)\"]</code></pre>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#quick-decision-table","title":"Quick Decision Table","text":"Scenario SharePoint Native Azure AI Search &lt; 500 documents, all in SharePoint \u2705 Best choice Overkill Documents in Word/HTML formats \u2705 Works well with GEM-008 Not needed Need custom chunking (specific section patterns) \u274c Can't control \u2705 You define boundaries Need metadata filtering (\"Engineering docs from Q4\") \u274c Not exposed \u2705 Full OData on any field &gt; 500 documents or &gt; 7 MB files \u274c Platform limits \u2705 Scales to millions Content NOT in SharePoint (databases, APIs, repos) \u274c SharePoint only \u2705 Indexes any data source Need hybrid search (keyword + vector) \u274c Platform decides \u2705 You configure strategy Multi-language with language-specific analyzers \u274c Platform-managed \u2705 Per-field analyzers Existing Azure AI Search investment \u274c Would duplicate data \u2705 Reuse existing indexes Need scoring profiles or faceted search \u274c Not available \u2705 Custom scoring + facets Sensitive permissions (live SharePoint RLS) \u2705 Live permission checks \ud83d\udfe1 Depends on auth config"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#the-hybrid-pattern-recommended-for-production","title":"The Hybrid Pattern (Recommended for Production)","text":"<p>Most production agents benefit from both:</p> <ul> <li>SharePoint Native for general knowledge (policies, FAQs, guides) \u2014 automatic sync, live permissions, zero config</li> <li>Azure AI Search for specialized collections (product catalogs with metadata, support ticket archives, technical docs with custom chunking) \u2014 full control, scale, filtering</li> </ul> <p>Both coexist as separate knowledge sources in the same agent. The orchestrator routes to the right source based on the query.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#why-azure-ai-search-the-enterprise-scenarios","title":"Why Azure AI Search \u2014 The Enterprise Scenarios","text":"<p>Beyond the decision guide above, here are the specific scenarios that justify Azure AI Search:</p> <ul> <li>Scale: 50,000+ documents across multiple repositories. Built-in SharePoint indexing may be slow or inconsistent at this scale.</li> <li>Custom schemas: Your content isn't just \"documents\" \u2014 it's structured data with custom fields (product specs with SKU, price, category, availability), work items with complex metadata, or multi-language content requiring language-specific analyzers.</li> <li>Hybrid search: You need both keyword-based (BM25) AND vector-based (semantic) search for maximum recall. Built-in knowledge sources offer semantic ranking but limited control over the search strategy.</li> <li>Existing investment: Your org already has Azure AI Search indexes built by data engineers \u2014 indexing CRM data, product catalogs, support tickets, or wiki content. You don't want to rebuild these as SharePoint sites just for Copilot Studio.</li> <li>Precision: You need field-level filtering (\"show me only documents from the Engineering department updated in the last 90 days\"), scoring profiles, or faceted search. Built-in knowledge sources don't expose these controls.</li> </ul> <p>Azure AI Search as a Copilot Studio knowledge source bridges this gap. It reached GA in May 2025 \u2014 and it's specifically designed for consuming pre-built indexes that pro-developers have already created.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>Enterprise-grade search powering agent responses:</p> <ul> <li>[ ] Pre-built index reuse: Existing Azure AI Search indexes consumed directly \u2014 no data duplication</li> <li>[ ] Vector + semantic search: Integrated vectorization for high-quality semantic matching</li> <li>[ ] Citation quality: Responses cite specific documents with links to source content</li> <li>[ ] Custom filtering: Agent can filter by metadata fields (department, date, type, product line)</li> <li>[ ] Scalable: Handles 10K to 1M+ documents without degradation</li> </ul>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#approach-a-native-azure-ai-search-knowledge-source-ga","title":"Approach A: Native Azure AI Search Knowledge Source (GA)","text":"<p>Summary: Add your Azure AI Search vector index as a first-class knowledge source in Copilot Studio. The platform handles search, ranking, and context injection for generative answers \u2014 same as SharePoint or file upload knowledge, but backed by your custom index. Technique: Copilot Studio knowledge source configuration, Azure AI Search connection (API key or Entra ID), vector index reference, integrated vectorization.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User question\"] --&gt; B[\"Copilot Studio&lt;br/&gt;(generative answers)\"]\n    B --&gt; C[\"&lt;b&gt;Azure AI Search&lt;/b&gt;&lt;br/&gt;(vector + semantic search)\"]\n    C --&gt; C1[\"Vectorize the question&lt;br/&gt;(same model used for index)\"]\n    C --&gt; C2[\"Search across vector index\"]\n    C --&gt; C3[\"Apply semantic ranking\"]\n    C --&gt; C4[\"Return top-K relevant chunks\"]\n    C --&gt; D[\"LLM generates response&lt;br/&gt;grounded in search results\"]\n    D --&gt; E[\"Agent response with citations\"]</code></pre> <p>The key benefit: Copilot Studio uses the same embedded model that was used to vectorize your index data. This ensures query-document similarity is optimized \u2014 the same semantic space for both the question and the content.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#implementation","title":"Implementation","text":"<p>Step 1: Prepare your Azure AI Search index</p> <p>Your index must be configured for integrated vectorization. If you're starting from scratch:</p> <ol> <li>In Azure Portal \u2192 Azure AI Search service \u2192 Import and vectorize data</li> <li>Select your data source (Blob Storage, SQL, Cosmos DB, etc.)</li> <li>Choose your embedding model (e.g., <code>text-embedding-ada-002</code> or <code>text-embedding-3-small</code>)</li> <li>Azure creates a vector index with both text and vector fields</li> <li>Optionally enable semantic ranker for re-ranking (improves precision for top results)</li> </ol> <p>If you have an existing index, ensure it includes:</p> <ul> <li>A vector field with embeddings from a supported embedding model</li> <li>A text field containing the searchable content (must be <code>searchable</code>)</li> <li>A title/URL field for citations (see Step 4)</li> </ul> <p>Step 2: Add Azure AI Search as knowledge source in Copilot Studio</p> <ol> <li>Open your agent \u2192 Knowledge \u2192 Add knowledge</li> <li>Select Featured \u2192 Azure AI Search</li> <li>Select Create new connection</li> <li> <p>Choose authentication type:</p> Auth Type When to Use Access Key Simplest. Use the admin key from Azure portal. Good for dev/test. Service Principal (Entra ID) Production. No key rotation needed. Role-based access. Microsoft Entra ID Integrated When the agent runs as the signed-in user. Inherits user's search permissions. Client Certificate High-security environments requiring certificate-based auth. </li> <li> <p>Enter your Azure AI Search Endpoint URL and credentials</p> </li> <li>Click Create \u2192 Next</li> <li>Enter your vector index name (only one vector index per connection)</li> <li>Click Add to agent</li> </ol> <p>The status shows \"In progress\" while Copilot Studio indexes the metadata. Once \"Ready,\" you can test.</p> <p>Step 3: Configure semantic ranking (recommended)</p> <p>Semantic ranking re-ranks the initial search results using a deep learning model for improved precision:</p> <ol> <li>In Azure Portal \u2192 your AI Search service \u2192 Semantic configurations</li> <li>Create a semantic configuration specifying which fields contain the title, content, and keywords</li> <li>In Copilot Studio, the semantic ranker is automatically used if configured on the index</li> </ol> <p>Note: Semantic ranker requires the Standard tier or higher on your Azure AI Search service. It's not available on the Free tier.</p> <p>Step 4: Configure citations</p> <p>For responses to cite specific documents with clickable links:</p> <ul> <li>Include a <code>metadata_storage_path</code> field in your index \u2192 Copilot Studio interprets this as the citation URL</li> <li>OR include any field containing a complete URL \u2192 Copilot Studio uses it as the citation link</li> <li>Ensure citation URLs point to locations the user has access to (SharePoint, web app, etc.)</li> </ul> <pre><code>Index fields for citations:\n  metadata_storage_path: \"https://contoso.sharepoint.com/docs/HR-PTO-Policy.docx\"\n  \u2192 Copilot Studio shows: \"Source: HR-PTO-Policy.docx [link]\"\n</code></pre> <p>Step 5: Enhance with custom search instructions</p> <p>Use <code>customInstructions</code> in generative answers to guide how the LLM uses search results:</p> <pre><code>    - kind: SearchAndSummarizeContent\n      id: searchAISearch\n      variable: Topic.Answer\n      userInput: =System.Activity.Text\n      customInstructions: |\n        ## Search Result Usage Rules\n\n        1. ALWAYS cite the source document title and link\n        2. If multiple documents contain relevant info, synthesize across sources\n        3. If the search returns no results, say: \"I couldn't find that in our knowledge base\"\n        4. For numerical data (dates, amounts), quote exactly from the source\n        5. Indicate document recency: \"According to [title], last updated [date]...\"\n</code></pre> <p>Step 6: Test with targeted queries</p> <p>Test queries that exercise different search capabilities:</p> Test Query What It Validates \"What's the PTO policy?\" Basic text retrieval \"Compare PTO policies across regions\" Multi-document synthesis \"Engineering documents updated this quarter\" Metadata awareness (if in index) \"What does section 3.2 say about carryover?\" Specific document section retrieval \"[Query in French for English documents]\" Cross-lingual semantic search"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 UI-based connection. If index exists, takes 15 minutes. Maintainability \ud83d\udfe2 Index managed in Azure. Data pipeline updates content. Agent configuration is static. Channel Compatibility \ud83d\udfe2 All channels \u2014 knowledge source is backend-only. Search Quality \ud83d\udfe2 Vector + semantic ranking. Best search quality available in the platform. Citation Quality \ud83d\udfe2 Automatic citations from index URL fields. Scalability \ud83d\udfe2 Azure AI Search scales to millions of documents. Built for enterprise."},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#limitations","title":"Limitations","text":"<ul> <li>One vector index per connection: You can only add one vector index per Azure AI Search connection. For multiple indexes, create multiple connections \u2014 but only one is used per generative answers node.</li> <li>Index must use integrated vectorization: The index fields must align with what Copilot Studio expects \u2014 vector field, text field, and ideally a URL field for citations. Custom or legacy indexes may need restructuring.</li> <li>No direct query control: You can't specify OData filters, scoring profiles, or search modes from Copilot Studio. The platform manages the search query. If you need query-level control, use Approach B.</li> <li>Virtual networks not supported: Azure AI Search indexes configured for private endpoints / VNets are not accessible from Copilot Studio's cloud-hosted service.</li> <li>Cost: Azure AI Search has per-unit pricing. Semantic ranker adds cost. Vector storage adds cost. Factor these into your budget (Gem 012).</li> </ul>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#approach-b-http-node-to-azure-ai-search-rest-api","title":"Approach B: HTTP Node to Azure AI Search REST API","text":"<p>Summary: Call the Azure AI Search REST API directly from a topic using <code>HttpRequest</code> nodes. Full control over the search query \u2014 filters, scoring profiles, facets, search modes, and result transformation. Technique: <code>HttpRequest</code> node with Azure AI Search query API, OData filter expressions, custom result formatting, environment variables for keys.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#how-it-works_1","title":"How It Works","text":"<pre><code>User: \"Show me engineering docs about Kubernetes from the last 90 days\"\n    \u2502\n    \u25bc\nTopic extracts: department=Engineering, topic=Kubernetes, dateRange=90days\n    \u2502\n    \u25bc\nHttpRequest to Azure AI Search:\n  POST /indexes/{index}/docs/search\n  Body: {\n    \"search\": \"Kubernetes\",\n    \"filter\": \"department eq 'Engineering' and lastModified gt 2025-11-19\",\n    \"select\": \"title,summary,url,lastModified,department\",\n    \"top\": 5,\n    \"queryType\": \"semantic\",\n    \"semanticConfiguration\": \"default\"\n  }\n    \u2502\n    \u25bc\nParse results \u2192 format as table/list \u2192 display to user\n</code></pre> <p>This gives you full OData query power \u2014 something the native knowledge source (Approach A) doesn't expose.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#implementation_1","title":"Implementation","text":"<p>Step 1: Store search credentials in environment variables</p> <pre><code>&lt;environmentvariabledefinition schemaname=\"agent_SearchEndpoint\"&gt;\n  &lt;defaultvalue&gt;https://contoso-search.search.windows.net&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_SearchApiKey\"&gt;\n  &lt;defaultvalue&gt;[your-api-key]&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n\n&lt;environmentvariabledefinition schemaname=\"agent_SearchIndexName\"&gt;\n  &lt;defaultvalue&gt;enterprise-content&lt;/defaultvalue&gt;\n&lt;/environmentvariabledefinition&gt;\n</code></pre> <p>Step 2: Build the search query topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Advanced Document Search\n    triggerQueries:\n      - \"search documents\"\n      - \"find documents about\"\n      - \"show me docs\"\n      - \"search for\"\n  actions:\n    # Collect search parameters\n    - kind: Question\n      id: askQuery\n      variable: init:Topic.SearchQuery\n      prompt: \"What are you looking for?\"\n      entity: StringPrebuiltEntity\n\n    # Execute search via HTTP\n    - kind: HttpRequest\n      id: http_search\n      method: POST\n      url: =Concatenate(Env.agent_SearchEndpoint, \"/indexes/\", Env.agent_SearchIndexName, \"/docs/search?api-version=2024-07-01\")\n      headers:\n        - key: \"api-key\"\n          value: =Env.agent_SearchApiKey\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"search\": \"{Topic.SearchQuery}\",\n          \"queryType\": \"semantic\",\n          \"semanticConfiguration\": \"default\",\n          \"select\": \"title,summary,url,lastModified,department,content\",\n          \"top\": 5,\n          \"count\": true\n        }\n      responseType: json\n      responseVariable: Topic.SearchResults\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.SearchStatus\n      timeout: 10000\n\n    # Check results\n    - kind: ConditionGroup\n      id: checkSearchResults\n      conditions:\n        - id: hasResults\n          condition: =Topic.SearchStatus &gt;= 200 &amp;&amp; Topic.SearchStatus &lt; 300\n          actions:\n            - kind: SendActivity\n              id: showResults\n              activity:\n                text:\n                  - \"\ud83d\udd0d Found {Topic.SearchResults.@odata.count} results for \\\"{Topic.SearchQuery}\\\":\\n\\n{Topic.FormattedResults}\\n\\nWould you like me to search for something else?\"\n      elseActions:\n        - kind: SendActivity\n          id: searchError\n          activity:\n            text:\n              - \"I'm having trouble searching right now. Try again in a moment or browse directly: [Search Portal](https://search.contoso.com)\"\n</code></pre> <p>Step 3: Add filtered search (metadata-driven)</p> <pre><code>    # Advanced: filtered search with metadata\n    - kind: HttpRequest\n      id: http_filteredSearch\n      method: POST\n      url: =Concatenate(Env.agent_SearchEndpoint, \"/indexes/\", Env.agent_SearchIndexName, \"/docs/search?api-version=2024-07-01\")\n      headers:\n        - key: \"api-key\"\n          value: =Env.agent_SearchApiKey\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"search\": \"{Topic.SearchQuery}\",\n          \"filter\": \"department eq '{Topic.Department}' and lastModified gt {Topic.DateFilter}\",\n          \"orderby\": \"lastModified desc\",\n          \"select\": \"title,summary,url,lastModified,department\",\n          \"top\": 10,\n          \"facets\": [\"department,count:5\"],\n          \"queryType\": \"semantic\",\n          \"semanticConfiguration\": \"default\",\n          \"answers\": \"extractive|count-3\",\n          \"captions\": \"extractive|highlight-true\"\n        }\n      responseType: json\n      responseVariable: Topic.FilteredResults\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.FilterStatus\n      timeout: 10000\n</code></pre> <p>Step 4: Use LLM to synthesize results</p> <p>Instead of just listing results, use a Prompt Tool or the generative answers node to synthesize search results into a coherent answer:</p> <pre><code>kind: PromptTool\nid: prompt_synthesizeSearch\ndisplayName: \"Search Result Synthesizer\"\ndescription: \"Synthesizes Azure AI Search results into a coherent answer\"\ninstructions: |\n  You are a document analysis assistant. Given search results and a user question,\n  synthesize a clear, cited answer.\n\n  User Question: {userQuery}\n\n  Search Results:\n  {searchResults}\n\n  Rules:\n  1. Answer the question using ONLY the information in the search results\n  2. Cite each fact with the document title: \"According to [title]...\"\n  3. If results don't fully answer the question, say what's missing\n  4. Keep the answer under 200 words\n  5. Include links to source documents for further reading\n\nmodel:\n  provider: ManagedModel\n  modelNameHint: GPT4Mini\ninputs:\n  - name: userQuery\n    type: string\n    required: true\n  - name: searchResults\n    type: string\n    required: true\noutputs:\n  - name: answer\n    type: string\n</code></pre>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Requires OData query construction and response parsing. Pro-dev level. Maintainability \ud83d\udfe1 Queries embedded in YAML. Index schema changes require query updates. Channel Compatibility \ud83d\udfe2 All channels (HTTP backend). Search Quality \ud83d\udfe2 Full control: semantic, vector, hybrid, keyword-only. Best precision possible. Filter/Facet Support \ud83d\udfe2 Full OData filter, facet, and orderby support. Citation Quality \ud83d\udfe2 You control exactly how results are displayed and cited."},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#limitations_1","title":"Limitations","text":"<ul> <li>OData query complexity: Building filtered, semantic, faceted queries in JSON within YAML is verbose and error-prone. Test queries in the Azure Portal Search Explorer first, then port to YAML.</li> <li>No automatic context injection: Unlike Approach A (where Copilot Studio manages the search-to-LLM pipeline), you must manually pass search results to a Prompt Tool or generative answers node (Step 4).</li> <li>API key management: The search API key is in an environment variable. For production, consider Managed Identity or service principal authentication.</li> <li>Response parsing: Search results are deeply nested JSON. Extracting and formatting <code>@search.answers</code>, captions, and highlights requires careful Power Fx.</li> </ul>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#approach-c-power-automate-search-flow-as-agent-tool","title":"Approach C: Power Automate Search Flow as Agent Tool","text":"<p>Summary: Build a Power Automate flow that queries Azure AI Search, processes and formats results, and returns them to the agent. The flow handles the query complexity; the agent gets clean, formatted results. Technique: Power Automate cloud flow with HTTP action to AI Search REST API, result parsing and formatting, registered as Copilot Studio tool.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Agent Topic&lt;/b&gt;&lt;br/&gt;Find docs about X\"] -- \"search request\" --&gt; B[\"&lt;b&gt;Power Automate Flow&lt;/b&gt;&lt;br/&gt;SearchDocuments\"]\n    B --&gt; B1[\"Build query with filters\"]\n    B --&gt; B2[\"POST to AI Search API\"]\n    B --&gt; B3[\"Parse &amp; format results\"]\n    B -- \"API query\" --&gt; C[\"&lt;b&gt;Azure AI Search&lt;/b&gt;\"]\n    C --&gt; B\n    B -- \"Return formatted list\" --&gt; A</code></pre>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#implementation_2","title":"Implementation","text":"<p>Step 1: Create the search flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs:\n    searchQuery (Text)\n    department (Text, optional)\n    dateRange (Text, optional: \"7d\", \"30d\", \"90d\")\n    maxResults (Number, default: 5)\n\nAction: Compose \u2014 Build filter expression\n  Expression:\n    if(isBlank(department) &amp;&amp; isBlank(dateRange), '',\n    concat(\n      if(isBlank(department), '', concat(\"department eq '\", department, \"'\")),\n      if(isBlank(department) || isBlank(dateRange), '', ' and '),\n      if(isBlank(dateRange), '', concat(\"lastModified gt \", dateRangeToDate(dateRange)))\n    ))\n\nAction: HTTP \u2014 Query Azure AI Search\n  Method: POST\n  URI: {SearchEndpoint}/indexes/{IndexName}/docs/search?api-version=2024-07-01\n  Headers:\n    api-key: {SearchApiKey}\n    Content-Type: application/json\n  Body: {\n    \"search\": \"{searchQuery}\",\n    \"filter\": \"{filterExpression}\",\n    \"select\": \"title,summary,url,lastModified,department\",\n    \"top\": {maxResults},\n    \"queryType\": \"semantic\",\n    \"semanticConfiguration\": \"default\",\n    \"count\": true\n  }\n\nAction: Select \u2014 Format results\n  From: body('HTTP')?['value']\n  Map:\n    title: item()?['title']\n    summary: item()?['summary']\n    url: item()?['url']\n    modified: formatDateTime(item()?['lastModified'], 'MMM dd, yyyy')\n    department: item()?['department']\n\nAction: Create HTML table (or Join to Markdown)\n  Format results as readable list\n\nOutput:\n  resultCount (Number)\n  formattedResults (Text)\n  hasMore (Boolean)\n</code></pre> <p>Step 2: Register as agent tool</p> <p>In Copilot Studio \u2192 Tools \u2192 Add a tool \u2192 Select your search flow \u2192 Add to agent</p> <p>Ensure the flow description is clear for routing:</p> <p>\"Searches enterprise documents with optional filters for department and date range. Use when users ask to find, search, or locate specific documents or information.\"</p> <p>Step 3: Agent instructions for search usage</p> <pre><code>instructions: |+\n  ## Document Search\n\n  You have access to the \"SearchDocuments\" tool for finding enterprise content.\n\n  When users ask to find, search, or locate documents:\n  1. Extract the search query from their message\n  2. If they mention a department, pass it as a filter\n  3. If they mention a time period (\"recent\", \"this month\", \"last quarter\"), map to dateRange\n  4. Present results as a numbered list with titles, summaries, and links\n  5. If no results, suggest broader search terms\n\n  Mapping for dateRange:\n  - \"recent\" / \"this week\" \u2192 \"7d\"\n  - \"this month\" \u2192 \"30d\"\n  - \"this quarter\" / \"last 90 days\" \u2192 \"90d\"\n  - No mention \u2192 leave empty (all time)\n</code></pre>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Visual flow design. Easier than raw HTTP in YAML, but still requires API knowledge. Maintainability \ud83d\udfe2 Flow is visual, reusable. Query changes in one place. Channel Compatibility \ud83d\udfe2 All channels (flow is backend). Search Quality \ud83d\udfe2 Same API access as Approach B. Full query control. Filter/Facet Support \ud83d\udfe2 Full OData in the flow \u2014 easier to build/test than in YAML. Result Formatting \ud83d\udfe2 Flow handles complex JSON parsing and formatting before returning to agent."},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#limitations_2","title":"Limitations","text":"<ul> <li>Flow quota: Each search consumes a flow run. Heavy search usage will impact your Power Automate quota.</li> <li>Latency: Power Automate adds 1-3 seconds to each search. Over Approach B's direct HTTP call.</li> <li>Dual infrastructure: You're maintaining both a flow AND the Azure AI Search index. Two places for things to break.</li> <li>No automatic generative grounding: Like Approach B, results are returned as data. You must pass them to a Prompt Tool or generative answers for synthesis.</li> </ul>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Native Knowledge Approach B: HTTP Direct Approach C: PA Search Flow Implementation Effort \ud83d\udfe2 Low (15 min config) \ud83d\udfe1 Medium (YAML queries) \ud83d\udfe1 Medium (visual flow) Query Control \ud83d\udd34 None (platform-managed) \ud83d\udfe2 Full OData power \ud83d\udfe2 Full OData power Generative Grounding \ud83d\udfe2 Automatic (SearchAndSummarize) \ud83d\udfe1 Manual (Prompt Tool) \ud83d\udfe1 Manual (Prompt Tool) Filtering \ud83d\udd34 Not exposed \ud83d\udfe2 Full OData filters \ud83d\udfe2 Full OData filters Citation Quality \ud83d\udfe2 Automatic from URL fields \ud83d\udfe1 Manual formatting \ud83d\udfe1 Manual formatting Flow Quota Impact \ud83d\udfe2 None \ud83d\udfe2 None \ud83d\udd34 1 run per search Latency \ud83d\udfe2 Optimized by platform \ud83d\udfe2 Direct (~200-500ms) \ud83d\udfe1 +1-3s (PA overhead) Index Requirements \ud83d\udfe1 Vector index with integrated vectorization \ud83d\udfe2 Any index type \ud83d\udfe2 Any index type Best When... Standard search, same experience as SharePoint knowledge Custom filters, scoring profiles, pro-dev team Visual flow design, reusable search tool"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#recommended-approach","title":"Recommended Approach","text":"<p>Start with Approach A (Native Knowledge Source) \u2014 if your index uses integrated vectorization, this gives you generative answers grounded in Azure AI Search with zero code. The experience is identical to having a supercharged SharePoint knowledge source \u2014 but backed by a scalable Azure search index. For most agents, this is sufficient and dramatically better than built-in SharePoint knowledge.</p> <p>Add Approach B or C when you need query control \u2014 specifically when users need to filter by metadata (department, date, document type). The native knowledge source (Approach A) doesn't expose filter parameters. If your users say \"Show me Engineering documents from last quarter,\" you need Approach B or C.</p> <p>The hybrid pattern (recommended for production):</p> <pre><code>General knowledge questions  \u2192  Approach A (Native, automatic grounding)\n  \"What's our data retention policy?\"\n  \"How do I configure SSO?\"\n\nFiltered document search     \u2192  Approach B/C (HTTP or Flow, with filters)\n  \"Show me Engineering docs from Q4\"\n  \"Find compliance reports about GDPR\"\n  \"Latest updates from the Security team\"\n</code></pre> <p>Use Approach A as the primary knowledge source (always active, grounding every generative answer). Use Approach B or C as an explicit search tool for when users want to find specific documents with metadata filters.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Azure AI Search indexes on virtual networks are NOT supported. Copilot Studio's cloud service cannot access AI Search indexes configured with private endpoints or VNet restrictions. Your index must be publicly accessible (secured by API key or Entra ID). For private indexes, use Approach C (Power Automate flow) \u2014 the flow can run with a VNet connection.</p> <p>Warning</p> <p>Only ONE vector index per connection. You can add only one vector index name per AI Search connection in Copilot Studio. If you have multiple indexes (e.g., HR-policies, Engineering-docs, Product-catalog), you need separate connections \u2014 but only one is used per generative answers node. For multi-index search, use Approach B/C with multiple HTTP queries.</p> <p>Warning</p> <p>Semantic ranker requires Standard tier or higher. The semantic ranker (which dramatically improves search precision) is not available on the Free tier of Azure AI Search. If your index is on the Free tier, you get basic vector search only \u2014 no semantic re-ranking.</p> <p>Note</p> <p>Integrated vectorization is the recommended indexing approach. Use the Azure Portal's \"Import and vectorize data\" wizard to create your index. This ensures the same embedding model is used for both index vectorization and runtime query vectorization \u2014 critical for search quality.</p> <p>Note</p> <p>Citations require a URL field in the index. If your index doesn't include a <code>metadata_storage_path</code> or another field with a complete URL, Copilot Studio can't generate citation links. Add a URL field to your index schema that points to the source document's accessible location.</p> <p>Note</p> <p>Test queries in Search Explorer first. Before writing HTTP queries in YAML or Power Automate, test them in the Azure Portal's Search Explorer. This validates your query syntax, filters, and semantic configuration against live data \u2014 then port the working query to your agent.</p>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 008: Knowledge Source Optimization \u2014 Covers document format and chunking for built-in sources. This Gem is \"GEM-008 Level 2\" for enterprise-scale knowledge with Azure AI Search.</li> <li>Gem 028: Grounding in Enterprise Analytics \u2014 For structured data (warehouses, Power BI). This Gem covers unstructured/semi-structured document search.</li> <li>Gem 018: SharePoint Document Retrieval \u2014 For finding and listing SharePoint documents. Azure AI Search can index SharePoint content for more powerful search.</li> <li>Gem 012: Cost Estimation \u2014 Azure AI Search has per-unit and per-query costs. Factor into your token budget analysis.</li> <li>Gem 023: MCP Connector Integration \u2014 MCP is for tool integration; AI Search is for knowledge grounding. Different roles in the agent architecture.</li> </ul>"},{"location":"gems/GEM-026-azure-ai-search-advanced-integration/#references","title":"References","text":"<ul> <li>Microsoft Learn: Add Azure AI Search as knowledge source</li> <li>Microsoft Learn: Create a vector index (Azure AI Search)</li> <li>Microsoft Learn: Integrated vectorization in Azure AI Search</li> <li>Microsoft Learn: Semantic ranker overview</li> <li>Microsoft Learn: Azure AI Search REST API (query)</li> <li>Microsoft Learn: OData filter syntax for Azure AI Search</li> <li>Azure AI Search pricing</li> </ul> <p>Gem 026 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current (Azure AI Search knowledge source GA since May 2025)</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/","title":"Gem 027: Deterministic Conversation Flows for Regulated Workflows","text":"<p>When the LLM's creativity is a liability \u2014 build flows that MUST follow the script.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#classification","title":"Classification","text":"Attribute Value Category UX Complexity \u2b50\u2b50\u2b50\u2b50 (Complex \u2014 architecture decision with legal/compliance implications) Channels All Prerequisite Gems Gem 022 (secure data handling for regulated contexts)"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#the-problem","title":"The Problem","text":"<p>Every other Gem in this collection leverages generative AI \u2014 the LLM's ability to understand natural language, synthesize answers, and adapt to context. But some conversations must not be left to the LLM's judgment:</p> <ul> <li>KYC (Know Your Customer) verification: \"Please confirm your date of birth, government ID number, and address.\" \u2014 The agent MUST collect all three fields. It CANNOT decide to skip one because \"the user seems verified.\"</li> <li>GDPR consent collection: \"Do you consent to data processing as described in our privacy policy? [Yes/No]\" \u2014 The response MUST be logged with a timestamp. The agent CANNOT paraphrase the consent question or infer consent from context.</li> <li>Medical intake: \"Are you currently experiencing chest pain? [Yes/No]\" \u2014 The agent MUST ask this exact question in this exact order. It CANNOT reorder the triage questions based on \"what seems most relevant.\"</li> <li>Legal disclaimer acknowledgment: \"By proceeding, you acknowledge that this is not legal advice.\" \u2014 The agent MUST display this text verbatim before providing any legal-adjacent information.</li> <li>Audit procedures: \"Step 4 of 7: Verify that the backup script ran successfully.\" \u2014 The agent MUST NOT allow the user to skip to step 7.</li> </ul> <p>The fundamental tension: Copilot Studio's generative orchestration is designed to be flexible and adaptive. Regulated workflows require the opposite \u2014 rigid, deterministic, and auditable.</p> <p>When the LLM decides to \"helpfully\" skip a consent question because the user said \"yeah, sure, whatever,\" your organization faces legal liability. When the LLM paraphrases a legal disclaimer, the paraphrase may not be legally valid.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>A conversation flow that meets regulatory requirements:</p> <ul> <li>[ ] Deterministic sequencing: Steps execute in a fixed order. No step can be skipped.</li> <li>[ ] Verbatim messages: Regulatory text is displayed exactly as written \u2014 not paraphrased by the LLM.</li> <li>[ ] Complete audit trail: Every step, every user response, and every timestamp is logged.</li> <li>[ ] No LLM interpretation of regulated content: The LLM doesn't process, summarize, or modify regulated text.</li> <li>[ ] Graceful integration: Regulated flows coexist with generative features in the same agent.</li> </ul>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#approach-a-fully-manual-topic-authoring-no-generative-ai","title":"Approach A: Fully Manual Topic Authoring (No Generative AI)","text":"<p>Summary: Build the regulated flow as a 100% manually-authored topic. Every message is a <code>SendActivity</code> with static text. Every input is a <code>Question</code> with explicit validation. No <code>SearchAndSummarizeContent</code>, no Prompt Tools, no generative orchestration. Technique: Manual <code>AdaptiveDialog</code> with sequential nodes, hardcoded text, <code>LogCustomTelemetryEvent</code> for audit.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#how-it-works","title":"How It Works","text":"<pre><code>Step 1: Display disclaimer    \u2192 Static SendActivity (verbatim text)\nStep 2: Collect consent       \u2192 Question (Boolean, required)\nStep 3: Verify identity       \u2192 Question (text + validation)\nStep 4: Collect data field A  \u2192 Question (entity validation)\nStep 5: Collect data field B  \u2192 Question (entity validation)\nStep 6: Confirmation summary  \u2192 SendActivity (formatted summary)\nStep 7: Submit                \u2192 InvokeFlow (persist to Dataverse)\nStep 8: Audit log             \u2192 LogCustomTelemetryEvent\n\nNo LLM is involved at any point. Every message, every question, every response is explicit.\n</code></pre>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#implementation","title":"Implementation","text":"<p>Step 1: Create a deterministic intake topic</p> <p>Example: GDPR consent collection + data processing request.</p> <pre><code>kind: AdaptiveDialog\nstartBehavior: CancelOtherTopics\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Data Processing Request\n    includeInOnSelectIntent: true\n    triggerQueries:\n      - \"data processing request\"\n      - \"process my data\"\n      - \"GDPR request\"\n      - \"data subject request\"\n  actions:\n    # =============================================\n    # STEP 1: Legal Disclaimer (VERBATIM \u2014 do not modify)\n    # =============================================\n    - kind: SendActivity\n      id: step1_disclaimer\n      activity:\n        text:\n          - \"**Important Legal Notice**\\n\\nThis process collects personal data for the purpose of fulfilling your data subject request under the General Data Protection Regulation (GDPR), Article 15-22.\\n\\nBy proceeding, you acknowledge that:\\n1. You are requesting this action on your own behalf, or you have legal authority to do so.\\n2. We will verify your identity before processing.\\n3. Processing may take up to 30 calendar days.\\n4. Submitted requests cannot be modified after submission.\\n\\nFor questions about this process, contact privacy@contoso.com.\"\n\n    # Log: disclaimer displayed\n    - kind: LogCustomTelemetryEvent\n      id: audit_disclaimer\n      eventName: RegulatedFlowAudit\n      properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"1_DisclaimerDisplayed\\\", UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # =============================================\n    # STEP 2: Explicit Consent (required, no skip)\n    # =============================================\n    - kind: Question\n      id: step2_consent\n      variable: init:Topic.UserConsent\n      prompt: \"Do you acknowledge the above terms and wish to proceed?\\n\\n**You must select Yes or No to continue.**\"\n      entity: BooleanPrebuiltEntity\n      alwaysPrompt: true\n\n    # Gate: Must consent to continue\n    - kind: ConditionGroup\n      id: checkConsent\n      conditions:\n        - id: consentGiven\n          condition: =Topic.UserConsent = true\n          actions:\n            - kind: LogCustomTelemetryEvent\n              id: audit_consent\n              eventName: RegulatedFlowAudit\n              properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"2_ConsentGiven\\\", Consent: true, UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n      elseActions:\n        - kind: SendActivity\n          id: consentDeclined\n          activity:\n            text:\n              - \"Understood. Your request has been cancelled. No data has been collected or processed.\\n\\nIf you change your mind, you can start a new request at any time.\"\n        - kind: LogCustomTelemetryEvent\n          id: audit_declined\n          eventName: RegulatedFlowAudit\n          properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"2_ConsentDeclined\\\", Consent: false, UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n        - kind: EndDialog\n          id: endOnDecline\n          clearTopicQueue: true\n\n    # =============================================\n    # STEP 3: Identity Verification (required)\n    # =============================================\n    - kind: Question\n      id: step3_fullName\n      variable: init:Topic.FullName\n      prompt: \"**Step 1 of 3: Identity Verification**\\n\\nPlease provide your full legal name as it appears on your employment contract:\"\n      entity: PersonNamePrebuiltEntity\n      alwaysPrompt: true\n\n    - kind: Question\n      id: step3_email\n      variable: init:Topic.VerifyEmail\n      prompt: \"Please provide your company email address for verification:\"\n      entity: EmailPrebuiltEntity\n      alwaysPrompt: true\n\n    - kind: Question\n      id: step3_employeeId\n      variable: init:Topic.EmployeeId\n      prompt: \"Please provide your Employee ID (format: E-XXXXX):\"\n      entity: StringPrebuiltEntity\n      alwaysPrompt: true\n\n    - kind: LogCustomTelemetryEvent\n      id: audit_identity\n      eventName: RegulatedFlowAudit\n      properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"3_IdentityCollected\\\", EmailProvided: !IsBlank(Topic.VerifyEmail), UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # =============================================\n    # STEP 4: Request Details (required)\n    # =============================================\n    - kind: Question\n      id: step4_requestType\n      variable: init:Topic.RequestType\n      prompt: \"**Step 2 of 3: Request Type**\\n\\nWhat type of data request would you like to make?\"\n      entity: ChoicePrebuiltEntity\n      alwaysPrompt: true\n      choiceOptions:\n        - value: \"Access\"\n          synonyms: [\"view my data\", \"see my data\", \"Article 15\"]\n        - value: \"Rectification\"\n          synonyms: [\"correct my data\", \"fix my data\", \"Article 16\"]\n        - value: \"Erasure\"\n          synonyms: [\"delete my data\", \"right to be forgotten\", \"Article 17\"]\n        - value: \"Portability\"\n          synonyms: [\"export my data\", \"download my data\", \"Article 20\"]\n\n    - kind: Question\n      id: step4_details\n      variable: init:Topic.RequestDetails\n      prompt: \"Please describe what specific data or records this request pertains to:\"\n      entity: StringPrebuiltEntity\n      alwaysPrompt: true\n\n    - kind: LogCustomTelemetryEvent\n      id: audit_requestDetails\n      eventName: RegulatedFlowAudit\n      properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"4_RequestDetailsCollected\\\", RequestType: Topic.RequestType, UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    # =============================================\n    # STEP 5: Confirmation Summary (all fields displayed)\n    # =============================================\n    - kind: SendActivity\n      id: step5_summary\n      activity:\n        text:\n          - \"**Step 3 of 3: Review and Submit**\\n\\nPlease review your request:\\n\\n| Field | Value |\\n|---|---|\\n| **Name** | {Topic.FullName} |\\n| **Email** | {Topic.VerifyEmail} |\\n| **Employee ID** | {Topic.EmployeeId} |\\n| **Request Type** | {Topic.RequestType} |\\n| **Details** | {Topic.RequestDetails} |\\n\\n\u26a0\ufe0f **Once submitted, this request cannot be modified.**\"\n\n    - kind: Question\n      id: step5_confirm\n      variable: init:Topic.FinalConfirm\n      prompt: \"Submit this request?\"\n      entity: BooleanPrebuiltEntity\n      alwaysPrompt: true\n\n    - kind: ConditionGroup\n      id: checkFinalConfirm\n      conditions:\n        - id: confirmed\n          condition: =Topic.FinalConfirm = true\n          actions:\n            # Submit via Power Automate\n            - kind: InvokeFlow\n              id: submitRequest\n              flowId: \"@environmentVariables('SubmitGDPRRequestFlowId')\"\n              inputs:\n                fullName: =Topic.FullName\n                email: =Topic.VerifyEmail\n                employeeId: =Topic.EmployeeId\n                requestType: =Topic.RequestType\n                details: =Topic.RequestDetails\n                consentTimestamp: =Text(Now(), DateTimeFormat.UTC)\n              outputVariable: Topic.SubmitResult\n\n            - kind: SendActivity\n              id: submitConfirmation\n              activity:\n                text:\n                  - \"\u2705 **Request Submitted**\\n\\n**Reference Number**: {Topic.SubmitResult.referenceNumber}\\n**Expected Completion**: Within 30 calendar days\\n**Status Updates**: You will receive email updates at {Topic.VerifyEmail}\\n\\nFor questions, contact privacy@contoso.com and reference **{Topic.SubmitResult.referenceNumber}**.\"\n\n            - kind: LogCustomTelemetryEvent\n              id: audit_submitted\n              eventName: RegulatedFlowAudit\n              properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"5_Submitted\\\", ReferenceNumber: Topic.SubmitResult.referenceNumber, RequestType: Topic.RequestType, UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n      elseActions:\n        - kind: SendActivity\n          id: cancelSubmit\n          activity:\n            text:\n              - \"Your request has been cancelled. No data has been submitted.\\n\\nYou can start a new request anytime.\"\n        - kind: LogCustomTelemetryEvent\n          id: audit_cancelled\n          eventName: RegulatedFlowAudit\n          properties: \"={FlowName: \\\"GDPRDataRequest\\\", Step: \\\"5_Cancelled\\\", UserId: System.User.Id, ConversationId: System.Conversation.Id, Timestamp: Text(Now(), DateTimeFormat.UTC)}\"\n\n    - kind: EndDialog\n      id: endFlow\n      clearTopicQueue: true\n</code></pre> <p>Step 2: Prevent generative AI override</p> <p>Use <code>startBehavior: CancelOtherTopics</code> (shown above) to ensure the regulated topic takes full control once triggered. The orchestrator cannot interrupt or reroute.</p> <p>Also add to agent instructions:</p> <pre><code>instructions: |+\n  ## Regulated Workflows\n\n  When the user triggers a \"Data Processing Request\" or any GDPR-related topic:\n  - DO NOT attempt to answer their data request yourself\n  - DO NOT skip, summarize, or paraphrase any step in the regulated flow\n  - Let the dedicated topic handle EVERY step exactly as authored\n  - NEVER intervene or \"helpfully\" complete steps for the user\n</code></pre>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 Standard topic authoring. No advanced components. Maintainability \ud83d\udfe1 Verbose YAML. Every message is hardcoded. Changes require editing and redeploying. Channel Compatibility \ud83d\udfe2 Works in all channels (plain text + choice questions). Determinism \ud83d\udfe2 100% deterministic. No LLM involvement. Every step executes exactly as authored. Audit Trail \ud83d\udfe2 LogCustomTelemetryEvent at every step. Complete, timestamped trail. Regulatory Compliance \ud83d\udfe2 Verbatim text, mandatory steps, explicit consent logging."},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#limitations","title":"Limitations","text":"<ul> <li>Rigid UX: The conversation feels robotic. No natural language understanding within the regulated flow \u2014 the user can't say \"skip to the consent part.\"</li> <li>Verbose implementation: A 7-step flow with audit logging at every step creates very long YAML files.</li> <li>No clarification: If the user's input to a Question doesn't match the expected entity, the re-prompt is generic. No LLM-powered \"Did you mean...?\" assistance.</li> <li>All or nothing: The entire flow is deterministic. You can't mix in generative elements for non-regulated parts of the same flow.</li> </ul>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#approach-b-hybrid-deterministic-steps-generative-clarification","title":"Approach B: Hybrid \u2014 Deterministic Steps + Generative Clarification","text":"<p>Summary: The regulated steps (consent, data collection, audit) are fully manual and deterministic. But within those steps, the LLM can provide clarification and explanation on request. Technique: Manual topic for the regulated flow structure, <code>SearchAndSummarizeContent</code> or Prompt Tool available for \"explain this\" side queries, clear boundary between regulated steps and optional explanations.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#how-it-works_1","title":"How It Works","text":"<pre><code>STEP 1: Display disclaimer (static, verbatim)\n  User: \"What does Article 15 mean?\"        \u2190 Optional clarification\n  Agent: [Generative answer about GDPR Art 15] \u2190 LLM-powered explanation\n  Agent: \"Now, back to the process...\"       \u2190 Returns to deterministic flow\n\nSTEP 2: Collect consent (static question, mandatory)\n  User: \"Yes\"\n  \u2192 Logged, proceed to Step 3\n\nSTEP 3: Identity verification (static questions)\n  User: \"What format should my Employee ID be in?\"  \u2190 Clarification\n  Agent: \"Your Employee ID is in the format E-XXXXX, found on your payslip.\"\n  Agent: \"Please provide your Employee ID:\"  \u2190 Back to the step\n</code></pre> <p>The regulated flow is a deterministic backbone. Generative AI is available as a side channel for explanations, but never controls the flow progression.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#implementation_1","title":"Implementation","text":"<p>Step 1: Build the deterministic backbone (same as Approach A)</p> <p>Use the same <code>AdaptiveDialog</code> structure from Approach A for all mandatory steps.</p> <p>Step 2: Add optional clarification at each step</p> <p>After each mandatory message, offer a clarification option:</p> <pre><code>    # STEP 1: Disclaimer\n    - kind: SendActivity\n      id: step1_disclaimer\n      activity:\n        text:\n          - \"**Important Legal Notice**\\n\\n[...verbatim disclaimer text...]\\n\\n\ud83d\udca1 _If you have questions about any of these terms, just ask before proceeding._\"\n\n    # Wait for user: either consent answer OR clarification question\n    - kind: Question\n      id: step1_response\n      variable: init:Topic.Step1Response\n      prompt: \"Do you acknowledge the above terms? (Yes / No)\\n\\nOr ask any question about the terms:\"\n      entity: StringPrebuiltEntity\n\n    # Check: is it a consent answer or a clarification?\n    - kind: ConditionGroup\n      id: routeStep1\n      conditions:\n        - id: isYes\n          condition: =Lower(Topic.Step1Response) = \"yes\"\n          actions:\n            # Proceed to Step 2 (consent logged)\n            - kind: SetVariable\n              id: setConsent\n              variable: Topic.UserConsent\n              value: =true\n        - id: isNo\n          condition: =Lower(Topic.Step1Response) = \"no\"\n          actions:\n            # Cancel flow\n            - kind: SendActivity\n              id: cancelFlow\n              activity:\n                text:\n                  - \"Understood. Your request has been cancelled.\"\n            - kind: EndDialog\n              id: endOnNo\n              clearTopicQueue: true\n      elseActions:\n        # Clarification requested \u2014 use generative AI\n        - kind: SearchAndSummarizeContent\n          id: clarifyTerms\n          variable: Topic.Clarification\n          userInput: =Topic.Step1Response\n          customInstructions: |\n            The user is asking about terms in our GDPR data processing request form.\n            Answer their question about the legal terms, GDPR articles, or process.\n            Keep the explanation simple and under 100 words.\n            After explaining, remind them to respond Yes or No to the consent question.\n\n        - kind: SendActivity\n          id: sendClarification\n          activity:\n            text:\n              - \"{Topic.Clarification}\\n\\n---\\n\\n\u21a9\ufe0f **Back to the form**: Do you acknowledge the terms? (Yes / No)\"\n\n        # Re-ask the consent question\n        - kind: Question\n          id: reaskConsent\n          variable: Topic.UserConsent\n          prompt: \"Do you acknowledge the above terms?\"\n          entity: BooleanPrebuiltEntity\n          alwaysPrompt: true\n</code></pre> <p>Step 3: Ensure generative AI never modifies the flow</p> <p>Key rules for the hybrid pattern:</p> <pre><code>instructions: |+\n  ## Hybrid Regulated Flow Rules\n\n  When a regulated workflow (GDPR, KYC, medical intake) is active:\n\n  1. NEVER skip, reorder, or summarize mandatory steps\n  2. You MAY answer clarification questions about terms, process, or requirements\n  3. After answering a clarification, ALWAYS return to the current step\n  4. NEVER use the user's clarification question as a substitute for their actual answer\n  5. Clarification answers are NOT logged as official responses\n  6. Only explicit Yes/No or data field answers are logged to the audit trail\n</code></pre>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 Approach A complexity + clarification routing logic. Maintainability \ud83d\udfe1 More complex branching per step (consent vs clarification). Channel Compatibility \ud83d\udfe2 Works in all channels. Determinism \ud83d\udfe2 Flow backbone is 100% deterministic. Clarification is a non-destructive side channel. Audit Trail \ud83d\udfe2 Only mandatory step responses are logged. Clarifications are labeled separately. User Experience \ud83d\udfe2 Users can ask questions without leaving the flow. Much less robotic than Approach A."},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#limitations_1","title":"Limitations","text":"<ul> <li>Complex per-step routing: Each step needs: mandatory answer detection, clarification detection, generative answer, return-to-step logic. This multiplies the YAML per step.</li> <li>Clarification scope risk: The generative AI answering a clarification question may inadvertently provide information that contradicts or modifies the mandatory text. Strict <code>customInstructions</code> mitigate this but don't eliminate it.</li> <li>User confusion: \"I asked a question and the bot answered, but now it's asking me the same consent question again\" \u2014 the UX of returning to the step after clarification can feel repetitive.</li> </ul>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#approach-c-state-machine-with-power-automate","title":"Approach C: State Machine with Power Automate","text":"<p>Summary: Externalize the flow logic to a Power Automate flow that manages state (current step, completed steps, audit log). The agent topic is thin \u2014 it calls the flow at each turn, and the flow tells it what to display and ask next. Technique: Power Automate flow as state machine, Dataverse records for ongoing request state, agent topic as I/O interface.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#how-it-works_2","title":"How It Works","text":"<pre><code>flowchart LR\n    A[\"&lt;b&gt;Agent Topic&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;User triggers flow&lt;br/&gt;User provides answers&lt;br/&gt;All steps complete\"] -- \"User input\" --&gt; B[\"&lt;b&gt;Power Automate&lt;br/&gt;State Machine&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;Create request record&lt;br/&gt;Validate answer&lt;br/&gt;Update record (Step N \u2713)&lt;br/&gt;Determine next step&lt;br/&gt;Finalize request&lt;br/&gt;Generate reference number\"]\n    B -- \"Step instructions /&lt;br/&gt;Confirmation + ref#\" --&gt; A\n    B -- \"Create / Update\" --&gt; C[\"&lt;b&gt;Dataverse&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;Request record&lt;br/&gt;with state tracking\"]\n    C -- \"Current state\" --&gt; B</code></pre> <p>The flow is the brain. The topic is just the mouth and ears. All state, validation, sequencing, and audit logic lives in the flow.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#implementation_2","title":"Implementation","text":"<p>Step 1: Design the Dataverse state table</p> Column Type Description <code>RequestId</code> Auto-number Unique request reference <code>UserId</code> Single line text Requesting user <code>CurrentStep</code> Integer Current step number (1-7) <code>Status</code> Choice (InProgress/Completed/Cancelled) Overall status <code>ConsentGiven</code> Boolean Step 2 result <code>ConsentTimestamp</code> DateTime When consent was given <code>FullName</code> Single line text Step 3 result <code>Email</code> Single line text Step 3 result <code>EmployeeId</code> Single line text Step 3 result <code>RequestType</code> Choice Step 4 result <code>RequestDetails</code> Multi-line text Step 4 result <code>AuditLog</code> Multi-line text JSON array of all step events <p>Step 2: Create the state machine flow</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: requestId (Text, optional), userInput (Text), userId (Text)\n\n# If no requestId \u2014 create new request\nCondition: IsBlank(requestId)\n  Yes \u2192 Create Row (Dataverse): new request, CurrentStep = 1\n        Set requestId = new row ID\n  No  \u2192 Get Row (Dataverse): load existing request\n\n# State machine switch on CurrentStep\nSwitch: CurrentStep\n  Case 1 (Disclaimer):\n    Output:\n      message: \"[verbatim disclaimer text]\"\n      question: \"Do you acknowledge? (Yes/No)\"\n      type: \"boolean\"\n      nextStep: 2\n\n  Case 2 (Consent):\n    Validate: userInput is \"yes\" or \"no\"\n    If \"yes\":\n      Update row: ConsentGiven=true, ConsentTimestamp=utcNow(), CurrentStep=3\n      Append to AuditLog: {step: 2, action: \"consent\", value: true, timestamp: utcNow()}\n      Output: next step instructions\n    If \"no\":\n      Update row: Status=Cancelled\n      Output: cancellation message\n\n  Case 3 (Identity - Name):\n    Update row: FullName=userInput, CurrentStep=4\n    Append to AuditLog: {step: 3, action: \"name_collected\", timestamp: utcNow()}\n    Output: email question\n\n  Case 4 (Identity - Email):\n    Validate: email format\n    Update row: Email=userInput, CurrentStep=5\n    Output: employee ID question\n\n  # ... cases 5-7 ...\n\n  Case 7 (Submit):\n    Update row: Status=Completed\n    Generate reference number\n    Output: confirmation with reference\n</code></pre> <p>Step 3: Thin agent topic</p> <pre><code>kind: AdaptiveDialog\nbeginDialog:\n  kind: OnRecognizedIntent\n  id: main\n  intent:\n    displayName: Regulated Request\n    triggerQueries:\n      - \"data request\"\n      - \"GDPR request\"\n  actions:\n    # Start or resume the flow\n    - kind: InvokeFlow\n      id: processStep\n      flowId: \"@environmentVariables('RegulatedFlowId')\"\n      inputs:\n        requestId: =Global.CurrentRequestId\n        userInput: =System.Activity.Text\n        userId: =System.User.Id\n      outputVariable: Topic.FlowResponse\n\n    # Display what the flow tells us\n    - kind: SendActivity\n      id: showStep\n      activity:\n        text:\n          - \"{Topic.FlowResponse.message}\"\n\n    # Save the request ID for next turn\n    - kind: SetVariable\n      id: saveRequestId\n      variable: Global.CurrentRequestId\n      value: =Topic.FlowResponse.requestId\n\n    # Ask the question the flow specified\n    - kind: ConditionGroup\n      id: checkFlowStatus\n      conditions:\n        - id: isComplete\n          condition: =Topic.FlowResponse.status = \"Completed\" || Topic.FlowResponse.status = \"Cancelled\"\n          actions:\n            - kind: SetVariable\n              id: clearRequest\n              variable: Global.CurrentRequestId\n              value: =\"\"\n            - kind: EndDialog\n              id: endRegulated\n              clearTopicQueue: true\n      elseActions:\n        - kind: Question\n          id: collectInput\n          variable: init:Topic.UserInput\n          prompt: =Topic.FlowResponse.question\n          entity: StringPrebuiltEntity\n</code></pre>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 Complex flow logic + Dataverse state table + thin topic. Most architecture of all approaches. Maintainability \ud83d\udfe2 Flow is visual (Power Automate designer). Business logic separate from presentation. Channel Compatibility \ud83d\udfe2 Agent topic is minimal \u2014 works in all channels. Determinism \ud83d\udfe2 Flow controls sequencing absolutely. Agent can't skip steps. Audit Trail \ud83d\udfe2 Dataverse row IS the audit trail. Every step recorded with timestamps. Queryable, exportable. Resumability \ud83d\udfe2 If conversation drops, user can resume from the last completed step (state persisted in Dataverse)."},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#limitations_2","title":"Limitations","text":"<ul> <li>Highest implementation complexity: The state machine flow, Dataverse table, and thin topic pattern require significant design and development.</li> <li>Power Automate latency: Every step round-trips through Power Automate (1-3 seconds). A 7-step flow has 7 round-trips.</li> <li>Flow quota impact: Every step consumes a flow run. A 7-step process = 7 flow runs per request.</li> <li>Debugging difficulty: When something goes wrong, you need to trace through flow run history, Dataverse records, and conversation logs \u2014 three different places.</li> <li>Overkill for simple flows: A 3-step consent collection doesn't need a state machine. Approach A suffices.</li> </ul>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Fully Manual Approach B: Hybrid Approach C: State Machine Implementation Effort \ud83d\udfe2 Low (2-3 hours) \ud83d\udfe1 Medium (4-6 hours) \ud83d\udd34 High (1-2 days) Determinism \ud83d\udfe2 100% \ud83d\udfe2 100% (backbone) \ud83d\udfe2 100% User Experience \ud83d\udd34 Robotic \ud83d\udfe2 Natural (clarification) \ud83d\udfe1 Step-by-step (functional) Audit Trail \ud83d\udfe2 Telemetry events \ud83d\udfe2 Telemetry events \ud83d\udfe2 Dataverse records Resumability \ud83d\udd34 Must restart if drops \ud83d\udd34 Must restart if drops \ud83d\udfe2 Resume from last step Clarification Support \ud83d\udd34 None \ud83d\udfe2 Generative side channel \ud83d\udd34 None (unless added) Logic Separation \ud83d\udd34 All in topic YAML \ud83d\udfe1 Mixed \ud83d\udfe2 Logic in flow, UI in topic Best When... Simple regulated flows (3-5 steps) User needs to understand terms Long flows, resumability, audit emphasis"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#recommended-approach","title":"Recommended Approach","text":"<p>For simple regulated flows (3-5 steps): Approach A (Fully Manual) \u2014 the simplest path to compliance. Verbatim text, mandatory questions, audit logging. Quick to implement, easy to audit.</p> <p>For user-friendly regulated flows: Approach B (Hybrid) \u2014 when users need to understand what they're consenting to, generative clarification within a deterministic backbone is the best UX. It's the \"explain this clause to me\" pattern that real users need.</p> <p>For complex, long, or resumable regulated flows: Approach C (State Machine) \u2014 when the flow has 7+ steps, may take multiple sessions to complete, or when the audit trail must be a permanent, queryable Dataverse record. Worth the investment for high-compliance scenarios.</p> <p>Decision guide:</p> <pre><code>3-5 steps, simple consent     \u2192  Approach A (manual, 2 hours)\n5-7 steps, user needs help    \u2192  Approach B (hybrid, 4-6 hours)\n7+ steps, multi-session       \u2192  Approach C (state machine, 1-2 days)\n</code></pre>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p><code>startBehavior: CancelOtherTopics</code> is essential for regulated flows. Without it, generative orchestration may interrupt your regulated topic with a different topic match mid-flow. Always set this for any regulated topic.</p> <p>Warning</p> <p>Generative orchestration can \"helpfully\" answer before the regulated topic fires. If a user says \"I want to submit a GDPR request,\" the orchestrator may try to answer with generative content about GDPR rather than triggering your deterministic topic. Add agent instructions: \"NEVER answer GDPR-related questions directly. ALWAYS route to the 'Data Processing Request' topic.\"</p> <p>Warning</p> <p><code>alwaysPrompt: true</code> is required for mandatory questions. Without <code>alwaysPrompt</code>, Copilot Studio may skip a question if it thinks the user already answered it (from conversation context). For regulated flows, EVERY question must be explicitly asked and answered in sequence.</p> <p>Note</p> <p>LogCustomTelemetryEvent is your audit trail. For Approach A and B, telemetry events with step names, timestamps, and consent values create a queryable audit trail in Application Insights. Use KQL to generate compliance reports.</p> <p>Note</p> <p>These flows coexist with generative features. Your agent can be 90% generative (FAQ, knowledge search, natural conversation) and 10% deterministic (regulated flows). The regulated topics only take over when their trigger phrases fire. The rest of the agent behaves normally.</p>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 022: Secure Data Handling \u2014 Regulated flows often collect sensitive data. Apply Gem 022's redaction patterns to audit logs.</li> <li>Gem 006: Adaptive Cards as Multi-Field Forms \u2014 Use cards within regulated flows for multi-field collection in fewer turns.</li> <li>Gem 004: Debug Mode \u2014 Telemetry pipeline from Gem 004 is the same infrastructure used for compliance audit logging.</li> <li>Gem 015: Dataverse CRUD \u2014 State Machine (Approach C) uses Dataverse patterns from Gem 015 for request state management.</li> <li>Gem 021: Disambiguation \u2014 Regulated topics need unique trigger phrases that don't overlap with generative topics.</li> </ul>"},{"location":"gems/GEM-027-deterministic-conversation-flows-for-regulated-workflows/#references","title":"References","text":"<ul> <li>GDPR Article 15-22: Data Subject Rights</li> <li>Microsoft Learn: Topic authoring in Copilot Studio</li> <li>Microsoft Learn: Question nodes</li> <li>Microsoft Learn: Application Insights custom events</li> <li>PCI-DSS requirements for conversational AI</li> </ul> <p>Gem 027 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/","title":"Gem 028: Grounding Agents in Enterprise Analytics Data","text":"<p>Your agent answers questions from documents. Now make it answer from warehouses, lakehouses, and Power BI too.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#classification","title":"Classification","text":"Attribute Value Category Integration Complexity \u2b50\u2b50\u2b50 to \u2b50\u2b50\u2b50\u2b50 (depends on data source and approach) Channels Teams, Web Chat (M365 Copilot not currently supported for Fabric Data Agent) Prerequisite Gems Gem 008 (knowledge source optimization \u2014 the document-grounding counterpart)"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#the-problem","title":"The Problem","text":"<p>Gems 008 and 018 cover grounding agents in unstructured content \u2014 documents, wikis, SharePoint files. But enterprise users also ask questions that require structured data:</p> <ul> <li>\"What were our Q4 revenue numbers by region?\" \u2014 The answer is in a data warehouse, not a Word document.</li> <li>\"Show me the top 10 customers by order volume this month.\" \u2014 The answer is in a lakehouse table.</li> <li>\"What's the trend for support ticket resolution time over the last 6 months?\" \u2014 The answer is in a Power BI semantic model.</li> <li>\"How many active IoT devices are reporting errors right now?\" \u2014 The answer is in a KQL database.</li> </ul> <p>These questions can't be answered by searching documents. They require querying structured data sources \u2014 SQL against warehouses, DAX against semantic models, KQL against analytics databases. The data exists in Microsoft Fabric, but the agent doesn't know how to reach it.</p> <p>The traditional approach \u2014 build Power Automate flows that run specific queries and return results \u2014 works for predictable questions. But it fails for ad-hoc analytics: the user asks a question nobody anticipated, and there's no pre-built flow for it.</p> <p>Microsoft Fabric Data Agents solve this by translating natural language into data queries dynamically. Copilot Studio can now consume Fabric Data Agents as connected agents \u2014 enabling your agent to answer both document questions (GEM-008) AND data questions in a single conversation.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#the-ideal-outcome","title":"The Ideal Outcome","text":"<p>An agent that seamlessly handles both document-grounded and data-grounded questions:</p> <ul> <li>[ ] Structured data access: Agent can query warehouses, lakehouses, semantic models, and KQL databases</li> <li>[ ] Natural language queries: Users ask in plain language; the system translates to SQL/DAX/KQL</li> <li>[ ] Ad-hoc analysis: Not limited to pre-built queries \u2014 handles questions nobody anticipated</li> <li>[ ] Combined grounding: One agent answers \"What's the PTO policy?\" (document) AND \"How many tickets were opened this week?\" (data) in the same conversation</li> <li>[ ] Data security: Users only see data they're authorized to access</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#approaches","title":"Approaches","text":""},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#approach-a-fabric-data-agent-as-connected-agent-preview","title":"Approach A: Fabric Data Agent as Connected Agent (Preview)","text":"<p>Summary: Create a Fabric Data Agent in Microsoft Fabric that connects to your enterprise data sources (warehouses, lakehouses, semantic models, KQL databases). Add it to your Copilot Studio agent as a connected agent. The orchestrator routes data questions to the Fabric agent automatically. Technique: Microsoft Fabric Data Agent (published), Copilot Studio connected agent configuration, generative orchestration for routing.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#how-it-works","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: What were Q4 revenue numbers by region?\"] --&gt; B[\"&lt;b&gt;Copilot Studio Orchestrator&lt;/b&gt;\"]\n    B --&gt;|\"Document question\"| C[\"Knowledge Sources (GEM-008)\"]\n    B --&gt;|\"Data/analytics question\"| D[\"&lt;b&gt;Fabric Data Agent&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;NL \u2192 SQL/DAX/KQL&lt;br/&gt;Query \u2192 Results&lt;br/&gt;Results \u2192 Response\"]\n    D --&gt; E[\"Q4 Revenue by Region:&lt;br/&gt;EMEA: $2.4M | NA: $3.1M | APAC: $1.8M\"]</code></pre> <p>The Fabric Data Agent handles the hard part: translating natural language into the right query language (SQL for warehouses, DAX for semantic models, KQL for analytics databases), executing the query, and formatting the results.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#implementation","title":"Implementation","text":"<p>Step 1: Create and configure the Fabric Data Agent</p> <p>In Microsoft Fabric:</p> <ol> <li>Navigate to your Fabric workspace</li> <li>Create a new Data Agent</li> <li>Connect it to your data sources:</li> <li>Warehouse: SQL-queryable structured data</li> <li>Lakehouse: Delta tables for big data</li> <li>Power BI Semantic Models: Pre-modeled business metrics (via XMLA endpoints)</li> <li>KQL Database: Real-time analytics and telemetry</li> <li>Ontology: Business domain definitions</li> <li>Write a rich, detailed description for the data agent \u2014 this is what Copilot Studio uses for routing</li> <li>Test the data agent in Fabric: ask sample questions, verify SQL/DAX generation</li> <li>Publish the data agent</li> </ol> <p>Step 2: Add the Fabric Data Agent to your Copilot Studio agent</p> <ol> <li>In Copilot Studio \u2192 Agents tab \u2192 + Add</li> <li>Under Connect to an external agent, select Microsoft Fabric</li> <li>Create or select a Fabric connection</li> <li>Select your published Fabric Data Agent from the list</li> <li>Adjust the description to be specific for routing:</li> <li>\u274c \"Data Agent\" (too vague)</li> <li>\u2705 \"Enterprise analytics specialist. Handles questions about revenue, sales, customer metrics, ticket volumes, and operational KPIs from our data warehouse and Power BI reports.\"</li> <li>Click Add agent</li> </ol> <p>Step 3: Configure authentication</p> <p>Under the connected Fabric Data Agent's settings, choose:</p> Auth Type When to Use User authentication Users query with their own Fabric permissions. They only see data they're authorized to access. Best for row-level security. Agent author authentication All queries run with the agent author's permissions. Users see the same data regardless of their access level. Simpler but less secure. <p>For most enterprise scenarios, User authentication is recommended \u2014 it inherits existing Fabric security models.</p> <p>Step 4: Enable generative orchestration</p> <p>In Copilot Studio \u2192 Settings \u2192 Orchestration \u2192 Select generative orchestration (first option). This is required for the orchestrator to route between knowledge sources and connected agents.</p> <p>Step 5: Add routing guidance in agent instructions</p> <pre><code>kind: GptComponentMetadata\ndisplayName: Enterprise Assistant\ninstructions: |+\n  # Enterprise Assistant\n\n  You serve two types of questions:\n\n  ## Document Questions\n  Questions about policies, procedures, guides, and reference materials.\n  Examples: \"What's the PTO policy?\", \"How do I submit an expense report?\"\n  \u2192 Answer from your knowledge sources (SharePoint, uploaded documents)\n\n  ## Data/Analytics Questions\n  Questions about numbers, metrics, trends, comparisons, and business data.\n  Examples: \"What was Q4 revenue?\", \"How many tickets this week?\", \"Top customers by volume\"\n  \u2192 Route to the Fabric Data Agent for live data queries\n\n  ## Routing Rules\n  - If the question asks for a NUMBER, TREND, COMPARISON, or METRIC \u2192 Fabric Data Agent\n  - If the question asks for a POLICY, PROCESS, or GUIDE \u2192 Knowledge Sources\n  - If unclear, ask: \"Are you looking for a policy/document, or for data/numbers?\"\n</code></pre> <p>Step 6: Test combined grounding</p> <p>In the Test panel:</p> <ul> <li>\"What's our PTO policy?\" \u2192 Should route to knowledge sources</li> <li>\"How many PTO days were used across the company this year?\" \u2192 Should route to Fabric Data Agent</li> <li>\"Show me Q4 revenue by region\" \u2192 Fabric Data Agent</li> <li>\"Where's the Q4 financial report document?\" \u2192 Knowledge sources</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#evaluation","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe2 UI-based: create Fabric agent, publish, add to Copilot Studio. No code. Maintainability \ud83d\udfe2 Data agent maintained in Fabric. Schema changes handled by Fabric. Channel Compatibility \ud83d\udfe1 Teams and Web Chat. M365 Copilot not currently supported for Fabric connected agents. Ad-hoc Queries \ud83d\udfe2 Natural language \u2192 SQL/DAX/KQL translation. Handles unpredictable questions. Data Security \ud83d\udfe2 User authentication inherits Fabric RLS. Users see only their authorized data. Combined Grounding \ud83d\udfe2 Orchestrator routes between documents and data automatically."},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#limitations","title":"Limitations","text":"<ul> <li>Preview status: Fabric Data Agent integration with Copilot Studio is in preview. Behavior and availability may change.</li> <li>Fabric capacity required: Requires F2 or higher Fabric capacity, or Power BI Premium P1+. Not available on free tiers.</li> <li>Same tenant: Fabric Data Agent and Copilot Studio must be on the same tenant.</li> <li>M365 Copilot not supported: The connected agent with Fabric Data Agent doesn't currently work in the M365 Copilot channel.</li> <li>Query accuracy: Natural language \u2192 SQL translation isn't perfect. Complex joins, subqueries, or ambiguous column names may produce incorrect results. Always validate with known queries first.</li> <li>Not for transactional writes: Fabric Data Agents are read-only analytics. For creating/updating records, use GEM-015 (Dataverse CRUD).</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#approach-b-power-automate-flows-with-pre-built-queries","title":"Approach B: Power Automate Flows with Pre-Built Queries","text":"<p>Summary: Build Power Automate flows that execute specific, pre-defined SQL/KQL queries against Fabric data sources. Register flows as agent tools for specific data questions. Technique: Power Automate cloud flows with SQL/KQL connector actions, parameterized queries, registered as Copilot Studio tools.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#how-it-works_1","title":"How It Works","text":"<pre><code>flowchart TB\n    A[\"User: What were Q4 revenue numbers?\"] --&gt; B[\"Agent selects tool:&lt;br/&gt;GetQuarterlyRevenue\"]\n    B --&gt; C[\"&lt;b&gt;Power Automate Flow&lt;/b&gt;&lt;br/&gt;SQL query: SELECT region, SUM(revenue)&lt;br/&gt;FROM sales WHERE quarter='Q4'&lt;br/&gt;GROUP BY region&lt;br/&gt;Format results as table&lt;br/&gt;Return to agent\"]\n    C --&gt; D[\"Agent: Q4 Revenue by Region:&lt;br/&gt;EMEA $2.4M, NA $3.1M, APAC $1.8M\"]</code></pre> <p>Each data question maps to a pre-built flow with a specific query. The agent triggers the right flow based on the question.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#implementation_1","title":"Implementation","text":"<p>Step 1: Create parameterized query flows</p> <pre><code>Trigger: Run a flow from Copilot\n  Inputs: quarter (Text), groupBy (Text, optional)\n\nAction: Execute SQL Query (Azure SQL / Synapse / Fabric)\n  Query: \n    SELECT {groupBy}, SUM(revenue) as total_revenue\n    FROM dbo.sales_fact\n    WHERE fiscal_quarter = '@{quarter}'\n    GROUP BY {groupBy}\n    ORDER BY total_revenue DESC\n\nAction: Create HTML Table\n  From: outputs('Execute_SQL_Query')\n\nOutput: formattedTable (Text), totalRevenue (Number)\n</code></pre> <p>Step 2: Register flows as agent tools</p> <p>Each flow becomes a named tool with a clear description:</p> <pre><code>tools:\n  - name: GetQuarterlyRevenue\n    description: \"Get revenue figures for a specific quarter, optionally grouped by region, product, or team. Use when users ask about revenue, sales numbers, or financial performance.\"\n    inputs: [quarter, groupBy]\n\n  - name: GetTicketMetrics\n    description: \"Get support ticket statistics \u2014 counts, resolution times, SLA compliance. Use when users ask about ticket volumes, support performance, or SLA metrics.\"\n    inputs: [dateRange, status, team]\n\n  - name: GetCustomerInsights\n    description: \"Get customer analytics \u2014 top customers, churn risk, engagement scores. Use when users ask about customer performance or account health.\"\n    inputs: [metric, topN, segment]\n</code></pre> <p>Step 3: Add flows to the agent</p> <p>In Copilot Studio \u2192 Tools \u2192 Add a tool \u2192 Select each Power Automate flow \u2192 Add to agent</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#evaluation_1","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udfe1 One flow per query type. Straightforward but proliferates. Maintainability \ud83d\udfe1 Schema changes require flow updates. Each new question type needs a new flow. Channel Compatibility \ud83d\udfe2 All channels. Ad-hoc Queries \ud83d\udd34 Only answers questions you've pre-built flows for. No flexibility for novel queries. Data Security \ud83d\udfe1 Flow runs with connection's credentials. RLS depends on connector configuration. Combined Grounding \ud83d\udfe2 Works alongside knowledge sources in the same agent."},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#limitations_1","title":"Limitations","text":"<ul> <li>No ad-hoc queries: Every question type needs a pre-built flow. \"What were Q4 revenues?\" works because you built that flow. \"What was the average deal size in EMEA for new customers acquired in Q3?\" fails unless you anticipated it.</li> <li>Flow proliferation: 10 data question types = 10 flows. 50 question types = 50 flows. Unscalable for analytics.</li> <li>SQL/KQL expertise required: You must write the queries yourself. No natural language \u2192 SQL translation.</li> <li>Flow quota: Each data query consumes a flow run against your quota (GEM-012 consideration).</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#approach-c-http-node-with-fabric-sql-endpoint","title":"Approach C: HTTP Node with Fabric SQL Endpoint","text":"<p>Summary: Call Fabric's SQL endpoint directly from Copilot Studio topics using <code>HttpRequest</code> nodes. Execute parameterized SQL queries against warehouses and lakehouses. Technique: <code>HttpRequest</code> node to Fabric SQL endpoint, bearer token authentication, SQL query in request body, response parsing.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#how-it-works_2","title":"How It Works","text":"<pre><code>Topic YAML \u2192 HttpRequest \u2192 Fabric SQL Endpoint \u2192 Query results \u2192 Parse \u2192 Display\n</code></pre> <p>Direct SQL execution without Power Automate in the loop. Fastest performance but requires SQL query construction in YAML.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#implementation_2","title":"Implementation","text":"<p>Step 1: Get Fabric SQL endpoint</p> <p>From your Fabric workspace \u2192 Warehouse or Lakehouse \u2192 Settings \u2192 SQL connection string.</p> <p>Step 2: Execute a query via HTTP</p> <pre><code>    - kind: HttpRequest\n      id: http_fabricQuery\n      method: POST\n      url: =Concatenate(Env.agent_FabricSqlEndpoint, \"/query\")\n      headers:\n        - key: \"Authorization\"\n          value: =Concatenate(\"Bearer \", Env.agent_FabricToken)\n        - key: \"Content-Type\"\n          value: \"application/json\"\n      body: |\n        {\n          \"query\": \"SELECT region, SUM(revenue) as total FROM sales_fact WHERE fiscal_quarter = '{Topic.Quarter}' GROUP BY region ORDER BY total DESC\",\n          \"maxRows\": 20\n        }\n      responseType: json\n      responseVariable: Topic.QueryResults\n      errorHandling:\n        continueOnError: true\n        statusCodeVariable: Topic.HttpStatus\n      timeout: 15000\n</code></pre>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#evaluation_2","title":"Evaluation","text":"Criterion Rating Notes Ease of Implementation \ud83d\udd34 SQL in YAML, auth management, response parsing. Pro-dev level. Maintainability \ud83d\udd34 SQL queries embedded in topic YAML. Hard to read, test, and update. Channel Compatibility \ud83d\udfe2 All channels. Ad-hoc Queries \ud83d\udd34 Queries are hardcoded. Same limitation as Approach B but without flow visualization. Data Security \ud83d\udfe1 Token-based auth. Must manage token lifecycle. Combined Grounding \ud83d\udfe2 Works in any topic alongside knowledge sources."},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#limitations_2","title":"Limitations","text":"<ul> <li>All limitations of Approach B (no ad-hoc queries, SQL expertise required) plus harder to maintain (SQL in YAML vs SQL in a flow's visual editor).</li> <li>Auth token management: Fabric SQL endpoints require Azure AD bearer tokens. Token acquisition and refresh in Copilot Studio topics is complex.</li> <li>Only justified when: Sub-second latency matters and you want to eliminate Power Automate overhead.</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Approach A: Fabric Data Agent Approach B: PA + SQL Flows Approach C: HTTP + SQL Implementation Effort \ud83d\udfe2 Low (UI-based) \ud83d\udfe1 Medium (per-flow) \ud83d\udd34 High (SQL in YAML) Ad-hoc Queries \ud83d\udfe2 Natural language \u2192 SQL/DAX/KQL \ud83d\udd34 Pre-built only \ud83d\udd34 Pre-built only Data Sources \ud83d\udfe2 Warehouse, Lakehouse, PBI, KQL, Ontology \ud83d\udfe1 Per connector type \ud83d\udfe1 SQL endpoints only Maintenance \ud83d\udfe2 Fabric-managed \ud83d\udfe1 Flow per query type \ud83d\udd34 SQL in YAML Data Security (RLS) \ud83d\udfe2 User auth inherits Fabric security \ud83d\udfe1 Connection-level \ud83d\udfe1 Token-level Channel Support \ud83d\udfe1 Teams + Web Chat (no M365 Copilot) \ud83d\udfe2 All channels \ud83d\udfe2 All channels Platform Maturity \ud83d\udfe1 Preview \ud83d\udfe2 GA \ud83d\udfe2 GA Best When... Analytics agent, ad-hoc data questions, Fabric-native org Known queries, stable schema, PA skills Max performance, pro-dev, simple queries"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#recommended-approach","title":"Recommended Approach","text":"<p>For analytics-heavy agents: Approach A (Fabric Data Agent) \u2014 the only approach that handles ad-hoc natural language data queries. If your users ask unpredictable data questions (\"What was the average deal size for EMEA enterprise customers acquired in Q3?\"), pre-built flows can't keep up. The Fabric Data Agent translates to SQL/DAX dynamically.</p> <p>For predictable, known data queries: Approach B (Power Automate Flows) \u2014 when you know the 5-10 data questions your users will ask and the schemas are stable. Build a flow for each. More predictable, GA, and works in all channels.</p> <p>Practical hybrid: Use Approach A for analytics exploration and Approach B for mission-critical data (where query accuracy must be guaranteed). The Fabric Data Agent handles the long tail of ad-hoc questions; pre-built flows handle the top 5 data questions with validated SQL.</p> <pre><code>Ad-hoc analytics questions  \u2192  Approach A (Fabric Data Agent \u2014 natural language SQL)\nTop 5 predictable queries   \u2192  Approach B (PA Flows \u2014 validated, guaranteed correct)\nDocument questions           \u2192  GEM-008 (Knowledge sources \u2014 SharePoint, files)\n</code></pre>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#platform-gotchas","title":"Platform Gotchas","text":"<p>Warning</p> <p>Fabric Data Agent integration is in preview. Behavior, availability, and configuration may change. Test thoroughly and have fallback plans for production deployments.</p> <p>Warning</p> <p>M365 Copilot channel does NOT support Fabric connected agents. The connected agent with Fabric Data Agent only works in Teams and Web Chat. Do not rely on this integration for M365 Copilot deployments.</p> <p>Warning</p> <p>Natural language \u2192 SQL translation is not 100% accurate. The Fabric Data Agent generates SQL/DAX/KQL from natural language. Complex queries with ambiguous column names, implicit joins, or business logic may produce incorrect results. Always validate with known questions before launching. Consider adding a \"\u26a0\ufe0f Data generated by AI query \u2014 verify for critical decisions\" disclaimer.</p> <p>Warning</p> <p>Same-tenant requirement. The Fabric Data Agent and Copilot Studio agent must be on the same Microsoft tenant. Cross-tenant scenarios are not supported.</p> <p>Note</p> <p>Write a rich description for the Fabric Data Agent. The orchestrator routes based on the connected agent's description. A vague description (\"Data agent\") leads to poor routing. Be specific: \"Handles questions about sales revenue, customer metrics, ticket volumes, and operational KPIs from our enterprise data warehouse.\"</p> <p>Note</p> <p>User authentication is recommended for RLS. When you choose \"User authentication\" for the Fabric Data Agent, queries run with the signed-in user's Fabric permissions. Users with row-level security (RLS) defined in Power BI semantic models only see their authorized data. This is the most secure option for multi-user agents.</p> <p>Note</p> <p>Fabric Data Agents also support Agent2Agent (A2A) and Foundry agents. Copilot Studio can also connect to Azure AI Foundry agents and agents supporting the A2A open protocol. If your structured data is in a non-Fabric system (e.g., a custom Python agent querying MongoDB), you can expose it via A2A and connect it to Copilot Studio the same way.</p>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#related-gems","title":"Related Gems","text":"<ul> <li>Gem 008: Knowledge Source Optimization \u2014 The document-grounding counterpart. GEM-008 covers unstructured content; this Gem covers structured data. Same agent, two complementary grounding strategies.</li> <li>Gem 015: Dataverse CRUD Operations \u2014 For writing data (create, update, delete records). This Gem is read-only analytics. GEM-015 is read-write operations.</li> <li>Gem 023: MCP Connector Integration \u2014 MCP is another way to connect external tools. Fabric Data Agents are a specific connected agent type, not MCP-based.</li> <li>Gem 021: Disambiguation \u2014 When a query could be either a document question or a data question, the disambiguation pattern helps route correctly.</li> <li>Gem 007: Role-Based Feature Gating \u2014 Data access control ties to user authentication. Admins may see all data; regular users see only their segment.</li> </ul>"},{"location":"gems/GEM-028-grounding-agents-in-enterprise-analytics-data/#references","title":"References","text":"<ul> <li>Microsoft Learn: Consume a Fabric Data Agent in Copilot Studio (preview)</li> <li>Microsoft Learn: Connect to a Microsoft Foundry agent</li> <li>Microsoft Learn: Connect an A2A protocol agent</li> <li>Microsoft Learn: Connect to a Copilot Studio agent</li> <li>Microsoft Learn: Fabric Data Agent overview</li> <li>Microsoft Learn: Agent2Agent (A2A) protocol</li> </ul> <p>Gem 028 | Author: S\u00e9bastien Brochet | Created: 2026-02-17 | Last Validated: 2026-02-17 | Platform Version: current (Fabric Data Agent in preview)</p>"},{"location":"parts/part-1/","title":"Part I \u2014 Foundations: State &amp; Context","text":"<p>Every agent in this book builds on one assumption: the agent knows something about the user and the conversation. This Part establishes the patterns for making that happen.</p>"},{"location":"parts/part-1/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-001 Persisting User Context Across Sessions How does the agent remember who you are after the conversation ends? GEM-011 Conversation Memory Within a Session How does the agent remember what was said 5 turns ago? GEM-017 Multi-Tenant Agent Configuration How does one agent serve multiple clients with different settings?"},{"location":"parts/part-1/#why-start-here","title":"Why Start Here","text":"<p>State management is the most referenced pattern in the entire collection. Out of 26 Gems:</p> <ul> <li>GEM-002 (persona) needs persisted user context from GEM-001</li> <li>GEM-004 (debug mode) can persist debug preferences via GEM-001</li> <li>GEM-005 (language) persists language choice via GEM-001</li> <li>GEM-007 (roles) caches detected roles via GEM-001</li> <li>GEM-017 (multi-tenant) extends GEM-001's persistence to configuration</li> </ul> <p>If you skip Part I, you'll see \"link to Gem 001\" in almost every other Gem.</p>"},{"location":"parts/part-1/#the-core-challenge","title":"The Core Challenge","text":"<p>Copilot Studio conversations are stateless by default. Global variables reset between conversations. Conversation history vanishes when the session ends. The platform has no built-in persistence mechanism.</p> <p>Everything in this Part addresses: How do you give the agent memory?</p>"},{"location":"parts/part-2/","title":"Part II \u2014 Personalization","text":"<p>Your agent works. Now make it adapt to who it's talking to \u2014 their role, language, expertise level, and preferences.</p>"},{"location":"parts/part-2/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-002 Persona-Adaptive Agent Instructions How does the agent adjust tone and depth per user? GEM-005 Multi-Language Agent Response How does the agent detect and respond in the user's language? GEM-020 Agent Instructions as Living Documents How do you version, modularize, and A/B test instructions?"},{"location":"parts/part-2/#prerequisites","title":"Prerequisites","text":"<ul> <li>GEM-001 (Part I) \u2014 most personalization patterns persist user preferences across sessions</li> </ul>"},{"location":"parts/part-2/#the-core-challenge","title":"The Core Challenge","text":"<p>Agent instructions are static by default \u2014 one set of instructions for all users. This Part shows three dimensions of adaptation: persona (GEM-002), language (GEM-005), and instruction lifecycle (GEM-020).</p>"},{"location":"parts/part-3/","title":"Part III \u2014 Conversation UX","text":"<p>The largest Part in the book \u2014 because conversation design determines whether users love or abandon your agent.</p>"},{"location":"parts/part-3/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-006 Adaptive Cards as Multi-Field Forms How do you collect 5 inputs without 10 messages? GEM-010 Agent-to-Human Handoff with Context When the agent can't help, how do you transfer to a human without losing context? GEM-021 Conversation Branching and Disambiguation When the user's intent is ambiguous, how does the agent clarify? GEM-025 Custom Canvas and Embedded Agent UX How do you embed the agent on your website with your branding? GEM-027 Deterministic Flows for Regulated Workflows When must the agent follow a script instead of using AI?"},{"location":"parts/part-3/#the-core-challenge","title":"The Core Challenge","text":"<p>Copilot Studio makes it easy to build an agent that works. Making it feel natural, efficient, and trustworthy requires deliberate UX design. This Part covers the five most impactful UX patterns \u2014 from data collection to compliance flows.</p>"},{"location":"parts/part-4/","title":"Part IV \u2014 Security","text":"<p>Two Gems, two critical questions: who can do what (GEM-007) and how is sensitive data protected (GEM-022).</p>"},{"location":"parts/part-4/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-007 Role-Based Feature Gating How do you show admin features to admins and hide them from everyone else? GEM-022 Secure Data Handling in Conversations What happens when users type passwords and SSNs into the chat?"},{"location":"parts/part-4/#prerequisites","title":"Prerequisites","text":"<ul> <li>GEM-001 (Part I) \u2014 role caching across sessions</li> <li>GEM-002 (Part II) \u2014 persona detection mechanisms (reused for role detection)</li> </ul>"},{"location":"parts/part-4/#the-core-challenge","title":"The Core Challenge","text":"<p>LLM-based agents are probabilistic \u2014 the model usually follows instructions, but instruction-based security is not a guarantee. This Part shows how to combine LLM instructions with hard-coded gates for defense-in-depth. GEM-022 is essential reading for any agent handling regulated data (GDPR, HIPAA, PCI-DSS).</p>"},{"location":"parts/part-5/","title":"Part V \u2014 Integration","text":"<p>The largest technical Part \u2014 connecting your agent to the world beyond Copilot Studio.</p>"},{"location":"parts/part-5/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-009 Graceful Degradation and Fallback Chains What happens when your API is down? GEM-014 Proactive Agent Messages How does the agent reach out to users first? GEM-015 Dataverse CRUD Operations How does the agent create, read, update, and delete records? GEM-018 SharePoint Document Retrieval How does the agent find and link to specific documents? GEM-023 MCP Connector Integration Patterns MCP, custom connector, or HTTP node \u2014 which should you use? GEM-028 Grounding in Enterprise Analytics Data How does the agent answer from warehouses and Power BI?"},{"location":"parts/part-5/#the-core-challenge","title":"The Core Challenge","text":"<p>Every agent eventually needs to talk to external systems. The challenge isn't whether to integrate, but how \u2014 and each integration method (MCP, flows, HTTP, connectors) has different trade-offs. GEM-023's decision framework is the essential reference for connector selection.</p>"},{"location":"parts/part-6/","title":"Part VI \u2014 Knowledge &amp; Performance","text":"<p>The agent's intelligence is only as good as its knowledge sources \u2014 and only as sustainable as its cost model.</p>"},{"location":"parts/part-6/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-008 Knowledge Source Optimization Why can't the agent find answers that are clearly in the documents? GEM-012 Cost Estimation and Token Budget Management How much does each conversation cost, and how do you control it? GEM-026 Azure AI Search Advanced Integration When do you need enterprise search instead of SharePoint?"},{"location":"parts/part-6/#the-core-challenge","title":"The Core Challenge","text":"<p>Two sides of the same coin: quality (does the agent find the right answer?) and cost (how much does it cost to find it?). GEM-008 is the starting point for every knowledge problem. GEM-026 is the escalation path when built-in knowledge sources aren't enough. GEM-012 ensures you can afford it all.</p>"},{"location":"parts/part-7/","title":"Part VII \u2014 Observability &amp; Operations","text":"<p>You built and deployed the agent. Now: is it working? Is it helping? How do you know?</p>"},{"location":"parts/part-7/#what-youll-learn","title":"What You'll Learn","text":"Gem Pattern Key Question GEM-003 Tracing Agent Progress Before Response How do you show users what the agent is doing while it thinks? GEM-004 Debug Mode for M365 Copilot Channel How do you debug in channels where the Test Canvas doesn't exist? GEM-013 Testing Strategies for Multi-Agent Architectures How do you systematically test an orchestrator + specialist agents? GEM-016 Conversation Analytics and Quality Measurement Is the agent actually helping people? How do you measure it?"},{"location":"parts/part-7/#the-core-challenge","title":"The Core Challenge","text":"<p>The agent is a black box once deployed. This Part makes it transparent \u2014 from real-time progress indicators (GEM-003) to production analytics (GEM-016). Read GEM-004 first if you're debugging a deployed agent. Read GEM-013 before deploying a multi-agent architecture. Read GEM-016 after deployment to measure real-world impact.</p>"}]}